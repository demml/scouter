{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Quality Control for Machine Learning Monitoring"},{"location":"#what-is-it","title":"What is it?","text":"<p><code>Scouter</code> is a developer-first monitoring toolkit for machine learning workflows (data, models, genai workflows and more). It is designed to be easy to use, flexible, performant, and extensible, allowing you to customize it to fit your specific needs. It's built on top of the <code>Rust</code> programming language and uses <code>Postgres</code> as its primary data store.</p>"},{"location":"#why-use-it","title":"Why Use It?","text":"<p>Because you deploy services that need to be monitored, and you want to be alerted when something is wrong.</p>"},{"location":"#developer-first-experience","title":"Developer-First Experience","text":"<ul> <li>Zero-friction Integration - Drop into existing ML workflows in minutes</li> <li>Type-safe by Design - Rust in the back, Python in the front<sup>*</sup>. Catch errors before they hit production</li> <li>Dependency Overhead - One dependency for monitoring. No need to install multiple libraries</li> <li>Standardized Patterns - Out of the box and easy to use patterns for common monitoring tasks</li> <li>Integrations - Works out of the box with any python api framework. Integrations for event-driven workflows (<code>Kafka</code> and <code>RabbitMQ</code>)</li> </ul>"},{"location":"#production-ready","title":"Production Ready","text":"<ul> <li>High-Performance Server - Built with Rust and Axum for speed, reliability and concurrency</li> <li>Cloud-Ready - Native support for AWS, GCP, Azure</li> <li>Modular Design - Use what you need, leave what you don't</li> <li>Alerting and Monitoring - Built-in alerting integrations with <code>Slack</code> and <code>OpsGenie</code> to notify you and your team when an alert is triggered</li> <li>Data Retention - Built-in data retention policies to keep your database clean and performant</li> </ul> <p><sup> Scouter is written in Rust and is exposed via a Python API built with PyO3. </sup></p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Scouter follows a client and server architecture whereby the client is a lightweight library that can be dropped into any Python application and the server is a Rust-based service that handles the heavy lifting of data collection, storage, and querying (setup separately).</p>"},{"location":"#install-scouter","title":"Install Scouter","text":"<pre><code>pip install scouter-ml\n</code></pre>"},{"location":"#population-stability-index-psi-example-client","title":"Population Stability Index (PSI) Example - Client","text":"<pre><code>import numpy as np\nimport pandas as pd\n\nfrom scouter.client import ScouterClient # Get the scouter client in order to interact with the server\nfrom scouter.drift import Drifter, PsiDriftConfig\n\ndef generate_data() -&gt; pd.DataFrame:\n    \"\"\"Create a fake data frame for testing\"\"\"\n    n = 10_000\n    X_train = np.random.normal(-4, 2.0, size=(n, 4))\n    col_names = []\n    for i in range(0, X_train.shape[1]):\n        col_names.append(f\"col_{i}\")\n    X = pd.DataFrame(X_train, columns=col_names)\n    return X\n\nif __name__ == \"__main__\":\n  # Drfter class for creating drift profiles\n  drifter = Drifter()\n\n  client = ScouterClient()\n\n  # get fake data\n  data = generate_data()\n\n``# Create a psi config\n  psi_config = PsiDriftConfig(\n      name=\"test\",\n      space=\"test\",\n      version=\"0.0.1\",\n      features_to_monitor=[\"feature_1\"],\n  )\n\n  # Create drift profile\n  psi_profile = drifter.create_drift_profile(data, psi_config)\n\n  # register drift profile\n  client.register_profile(psi_profile)\n</code></pre>"},{"location":"#custom-metric-example-client","title":"Custom Metric Example - Client","text":"<pre><code>import numpy as np\nimport pandas as pd\n\nfrom scouter.client import ScouterClient # Get the scouter client in order to interact with the server\nfrom scouter.drift import (\n    CustomDriftProfile,\n    CustomMetric,\n    CustomMetricDriftConfig,\n    Drifter,\n    PsiDriftConfig,\n    SpcDriftConfig,\n)\n\ndef generate_data() -&gt; pd.DataFrame:\n    \"\"\"Create a fake data frame for testing\"\"\"\n    n = 10_000\n    X_train = np.random.normal(-4, 2.0, size=(n, 4))\n    col_names = []\n    for i in range(0, X_train.shape[1]):\n        col_names.append(f\"col_{i}\")\n    X = pd.DataFrame(X_train, columns=col_names)\n    return X\n\nif __name__ == \"__main__\":\n  # Drfter class for creating drift profiles\n  drifter = Drifter()\n\n  client = ScouterClient()\n\n  # get fake data\n  data = generate_data()\n\n``# Create a custom config\n  custom_config = CustomMetricDriftConfig(\n      name=\"test\",\n      space=\"test\",\n      version=\"0.0.1\",\n  )\n\n  # Create drift profile\n  custom_profile = CustomDriftProfile(\n    config=custom_config,\n    metrics=[\n        CustomMetric(\n            name=\"mae\",\n            value=10,\n            alert_threshold=AlertThreshold.Above, # any value above 10 will trigger an alert\n        ),\n    ],\n  )\n\n  # register drift profile\n  client.register_profile(custom_profile)\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>You can install Scouter from any python package manager</p> uvpip <pre><code>uv add scouter-ml\n</code></pre> <pre><code>pip install scouter-ml\n</code></pre>"},{"location":"installation/#importing","title":"Importing","text":"<p>To use Scouter, simply import it in your Python script:</p> <pre><code>import scouter\n\nfrom scouter import Drifter\n</code></pre>"},{"location":"installation/#connect-to-scouter-server","title":"Connect to Scouter Server","text":"<p>The Scouter python client is a client-side library that is meant to be used in conjunction with the Scouter server. To use the Scouter client, you need to set the <code>SCOUTER_SERVER_URI</code> environment variable to point to your Scouter server. This can be done in your terminal or in your Python script.</p> <pre><code>export SCOUTER_SERVER_URI=your_SCOUTER_SERVER_URI\n</code></pre> <p>For more information on how to setup the Scouter server, refer to the Server documentation.</p>"},{"location":"server/","title":"Server","text":"<p>The Scouter server is a rust-based server that is designed to be run independent of the python client. The server is responsible for handling the event system (via Kafka, RabbitMQ or the default queue system), database CRUD operations, and alerting.</p> <p>Features:</p> <ul> <li>Event System - Scouter supports various third-party event systems such as Kafka and RabbitMQ. The event system is used to send events to the Scouter server for processing</li> <li>Database Storage - The Scouter server leverages Postgres (sqlx) for short-term data storage and DataFusion for long-term data storage</li> <li>Alerting - Integrates with OpsGenie and Slack for alerting</li> <li>Data Retention and Partitioning - Built-in data retention and partitioning strategies to keep your database clean and performant</li> <li>Authentication - Built-in authentication system for users</li> </ul>"},{"location":"server/#getting-started","title":"Getting Started","text":"<p>There are a few different ways to get up an running with the Scouter server.</p>"},{"location":"server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Scouter relies on a Postgres database for storing and retrieving data. You will need to have a Postgres database up and running before you can use Scouter. Scouter currently supports Postgres 16.3 and above.</li> </ul> <p>Once you have a Postgres database up and running, set the following environment variable before starting the Scouter server:</p> <pre><code>export DATABASE_URI={your_postgres_uri}\n</code></pre> <p>The default database URI is <code>postgresql://postgres:postgres@localhost:5432/postgres</code>. You can change this to point to your own Postgres database.</p>"},{"location":"server/#docker","title":"Docker","text":"<p>It is recommended to use one of our pre-built Docker images to get up and running quickly. New docker images are built and tagged on every version release and currently build for the following platforms:</p> <p>Amd64 (x86_64-unknown-linux-gnu)</p> Image Tag Suffix Features ubuntu ubuntu (kafka, RabbitMQ) alpine alpine (kafka, RabbitMQ) scratch scratch (kafka, RabbitMQ) debian debian (kafka, RabbitMQ) distroless distroless (kafka, RabbitMQ) <p>Arm64 (aarch64-unknown-linux-gnu)</p> Image Tag Suffix Features ubuntu ubuntu (kafka, RabbitMQ) alpine alpine (kafka, RabbitMQ) scratch scratch (kafka, RabbitMQ) debian debian (kafka, RabbitMQ) distroless distroless (kafka, RabbitMQ)"},{"location":"server/#pull-your-image","title":"Pull your image","text":"<pre><code>docker pull demml/scouter:ubuntu-amd64-kafka-latest\n</code></pre>"},{"location":"server/#run-your-image","title":"Run your image","text":"<pre><code>docker run -d --name scouter -p 8080:8080 demml/scouter:ubuntu-amd64-kafka-latest\n</code></pre>"},{"location":"server/#execute-prebuilt-binary","title":"Execute prebuilt binary","text":"<p>Binaries for various architectures are published on every release. You can find them on the github release page, download and execute the binary.</p> <p>Binaries can be found here</p>"},{"location":"server/#build-from-source","title":"Build from source","text":"<p>To build the Scouter server from source, you will need to have the following dependencies installed:</p> <ul> <li>Rust (with Cargo) link</li> </ul> <p>Then you can build the server using the following command:</p> <pre><code>cargo build scouter-server --release\n</code></pre>"},{"location":"server/#feature-flags","title":"Feature Flags","text":"<p>Scouter server is built with a few feature flags that can be enabled or disabled at build time. The following feature flags are available:</p> <ul> <li><code>kafka</code> - Installs the necessary dependencies to use Kafka as the event system (<code>rdkafka</code> crate)</li> </ul> <pre><code>cargo build scouter-server --release --features \"kafka\"\n</code></pre> <ul> <li><code>rabbitmq</code> - Installs the necessary dependencies to use RabbitMQ as the event system (<code>lapin</code> crate)</li> </ul> <pre><code>cargo build scouter-server --release --features \"rabbitmq\"\n</code></pre>"},{"location":"server/#environment-variables","title":"Environment Variables","text":"<p>You can set a variety of environment variables to configure the Scouter server to your needs.</p>"},{"location":"server/#database-variables","title":"Database Variables","text":"Variable Description Feature Default <code>DATABASE_URI</code> Database connection URL <code>All</code> <code>postgresql://postgres:postgres@localhost:5432/postgres</code> <code>MAX_POOL_SIZE</code> Maximum number of database connections in the pool <code>All</code> <code>30</code> <code>DATA_RETENTION_PERIOD</code> Number of days to retain data in the database. After this time, data will be pushed to long-term storage via <code>DataFusion</code> <code>All</code> <code>30</code>"},{"location":"server/#polling-variables-for-background-drift-detection","title":"Polling Variables (For background drift detection)","text":"Variable Description Feature Default <code>POLLING_WORKER_COUNT</code> Number of polling workers for processing scheduled tasks and alerting <code>All</code> <code>4</code>"},{"location":"server/#kafka-variables-if-enabled-for-record-consumption","title":"Kafka Variables (if enabled, for record consumption)","text":"Variable Description Feature Default <code>KAFKA_BROKERS</code> Comma-separated list of Kafka broker addresses <code>Kafka</code> <code>localhost:9092</code> <code>KAFKA_TOPIC</code> Kafka topic for sending data <code>Kafka</code> <code>scouter_monitoring</code> <code>KAFKA_GROUP</code> Kafka consumer group ID <code>Kafka</code> <code>scouter</code> <code>KAFKA_OFFSET_RESET</code> Kafka offset reset policy <code>Kafka</code> <code>earliest</code> <code>KAFKA_USERNAME</code> Kafka username for authentication <code>Kafka</code> <code>None</code> <code>KAFKA_PASSWORD</code> Kafka password for authentication <code>Kafka</code> <code>None</code> <code>KAFKA_SECURITY_PROTOCOL</code> Kafka security protocol (e.g., <code>PLAINTEXT</code>, <code>SSL</code>, <code>SASL_PLAINTEXT</code>, <code>SASL_SSL</code>) <code>Kafka</code> <code>SASL_SSL</code> <code>KAFKA_SASL_MECHANISM</code> Kafka SASL mechanism <code>Kafka</code> <code>PLAIN</code> <code>KAFKA_CERT_LOCATION</code> Path to the Kafka CA certificate file <code>Kafka</code> <code>None</code>"},{"location":"server/#rabbitmq-variables-if-enabled-for-record-consumption","title":"RabbitMQ Variables (if enabled, for record consumption)","text":"Variable Description Feature Default <code>RABBITMQ_CONSUMER_COUNT</code> Number of RabbitMQ consumers <code>RabbitMQ</code> <code>3</code> <code>RABBITMQ_PREFETCH_COUNT</code> Number of messages to prefetch per consumer <code>RabbitMQ</code> <code>10</code> <code>RABBITMQ_ADDR</code> RabbitMQ server address <code>RabbitMQ</code> <code>amqp://guest:guest@127.0.0.1:5672/%2f</code> <code>RABBITMQ_QUEUE</code> RabbitMQ queue name <code>RabbitMQ</code> <code>scouter_monitoring</code> <code>RABBITMQ_CONSUMER_TAG</code> RabbitMQ consumer tag <code>RabbitMQ</code> <code>scouter</code>"},{"location":"server/#authentication","title":"Authentication","text":"<p>Scouter has built-in authentication support for JWT tokens. You can set the following environment variables to enable authentication:</p> <ul> <li><code>SCOUTER_ENCRYPT_SECRET</code>: Secret key used to sign JWT tokens. If not set, scouter will use a default deterministic key. This is not recommended for production use cases. Scouter requires a pbdkdf2::HmacSha256 key with a length of 32 bytes.</li> <li><code>SCOUTER_REFRESH_SECRET</code>: Secret key used to sign refresh tokens. If not set, scouter will use a default deterministic key. This is not recommended for production use cases. Scouter requires a pbdkdf2::HmacSha256 key with a length of 32 bytes.</li> <li><code>SCOUTER_BOOTSTRAP_KEY</code>: Secret key used to bootstrap the server. This is used to create the initial admin user and should be set to a strong random value. If not set, scouter will use a default. This is also a pbdkdf2::HmacSha256 key with a length of 32 bytes. This can be used as a shared key for integration work as well. For example, when setting up an opsml server, you can user this key to sync user accounts between the two servers.</li> </ul>"},{"location":"server/#objectstore-variables-for-long-term-storage","title":"ObjectStore Variables (For long-term storage)","text":"Variable Description Feature Default <code>SCOUTER_STORAGE_URI</code> The URI of the object store to use for long-term storage. The default is <code>./scouter_storage</code>. Currently, gcs, s3, azure and local storage are supported. If using cloud storage, provide the appropriate prefix and bucket (e.g. gs://scouter, s3://scouter, az://scouter) <code>ObjectStore</code> <code>./scouter_storage</code> <code>AWS_REGION</code> The AWS region to use for S3 storage. The default is <code>us-east-1</code> <code>ObjectStore</code> <code>us-east-1</code> <code>GOOGLE_ACCOUNT_JSON_BASE64</code> The base64 encoded JSON key file to use for GCS storage. This is an optional environment variable that can be used in addition to how the <code>object-store</code> GoogleCloudStorageBuilder retrieves credentials <code>ObjectStore</code> <code>None</code>"},{"location":"server/#object-store-providers","title":"Object Store Providers","text":"<p>Scouter leverage's the object-store crate for writing to object stores. The following object stores are supported. Please refer to the object-store crate for more information on how to configure each object store.</p> <p>Providers:</p> <ul> <li><code>google_cloud_storage</code> - link</li> <li><code>aws_s3</code> - link</li> <li><code>azure</code> - link</li> </ul>"},{"location":"docs/api/alert/","title":"Alert","text":""},{"location":"docs/api/alert/#scouter.alert._alert.AlertDispatchType","title":"<code>AlertDispatchType</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class AlertDispatchType:\n    Slack: \"AlertDispatchType\"\n    OpsGenie: \"AlertDispatchType\"\n    Console: \"AlertDispatchType\"\n\n    @staticmethod\n    def to_string() -&gt; str:\n        \"\"\"Return the string representation of the alert dispatch type\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.AlertDispatchType.to_string","title":"<code>to_string()</code>  <code>staticmethod</code>","text":"<p>Return the string representation of the alert dispatch type</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>@staticmethod\ndef to_string() -&gt; str:\n    \"\"\"Return the string representation of the alert dispatch type\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.AlertThreshold","title":"<code>AlertThreshold</code>","text":"<p>Enum representing different alert conditions for monitoring metrics.</p> <p>Attributes:</p> Name Type Description <code>Below</code> <code>AlertThreshold</code> <p>Indicates that an alert should be triggered when the metric is below a threshold.</p> <code>Above</code> <code>AlertThreshold</code> <p>Indicates that an alert should be triggered when the metric is above a threshold.</p> <code>Outside</code> <code>AlertThreshold</code> <p>Indicates that an alert should be triggered when the metric is outside a specified range.</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class AlertThreshold:\n    \"\"\"\n    Enum representing different alert conditions for monitoring metrics.\n\n    Attributes:\n        Below: Indicates that an alert should be triggered when the metric is below a threshold.\n        Above: Indicates that an alert should be triggered when the metric is above a threshold.\n        Outside: Indicates that an alert should be triggered when the metric is outside a specified range.\n    \"\"\"\n\n    Below: \"AlertThreshold\"\n    Above: \"AlertThreshold\"\n    Outside: \"AlertThreshold\"\n\n    @staticmethod\n    def from_value(value: str) -&gt; \"AlertThreshold\":\n        \"\"\"\n        Creates an AlertThreshold enum member from a string value.\n\n        Args:\n            value (str): The string representation of the alert condition.\n\n        Returns:\n            AlertThreshold: The corresponding AlertThreshold enum member.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.AlertThreshold.from_value","title":"<code>from_value(value)</code>  <code>staticmethod</code>","text":"<p>Creates an AlertThreshold enum member from a string value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The string representation of the alert condition.</p> required <p>Returns:</p> Name Type Description <code>AlertThreshold</code> <code>AlertThreshold</code> <p>The corresponding AlertThreshold enum member.</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>@staticmethod\ndef from_value(value: str) -&gt; \"AlertThreshold\":\n    \"\"\"\n    Creates an AlertThreshold enum member from a string value.\n\n    Args:\n        value (str): The string representation of the alert condition.\n\n    Returns:\n        AlertThreshold: The corresponding AlertThreshold enum member.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.ConsoleDispatchConfig","title":"<code>ConsoleDispatchConfig</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class ConsoleDispatchConfig:\n    def __init__(self):\n        \"\"\"Initialize alert config\"\"\"\n\n    @property\n    def enabled(self) -&gt; bool:\n        \"\"\"Return the alert dispatch type\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.ConsoleDispatchConfig.enabled","title":"<code>enabled</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/alert/#scouter.alert._alert.ConsoleDispatchConfig.__init__","title":"<code>__init__()</code>","text":"<p>Initialize alert config</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self):\n    \"\"\"Initialize alert config\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertCondition","title":"<code>CustomMetricAlertCondition</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class CustomMetricAlertCondition:\n    def __init__(\n        self,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float],\n    ):\n        \"\"\"Initialize a CustomMetricAlertCondition instance.\n        Args:\n            alert_threshold (AlertThreshold): The condition that determines when an alert\n                should be triggered. This could be comparisons like 'greater than',\n                'less than', 'equal to', etc.\n            alert_threshold_value (Optional[float], optional): A numerical boundary used in\n                conjunction with the alert_threshold. This can be None for certain\n                types of comparisons that don't require a fixed boundary.\n        Example:\n            alert_threshold = CustomMetricAlertCondition(AlertCondition.BELOW, 2.0)\n        \"\"\"\n\n    @property\n    def alert_threshold(self) -&gt; AlertThreshold:\n        \"\"\"Return the alert_threshold\"\"\"\n\n    @alert_threshold.setter\n    def alert_threshold(self, alert_threshold: AlertThreshold) -&gt; None:\n        \"\"\"Set the alert_threshold\"\"\"\n\n    @property\n    def alert_threshold_value(self) -&gt; float:\n        \"\"\"Return the alert_threshold_value\"\"\"\n\n    @alert_threshold_value.setter\n    def alert_threshold_value(self, alert_threshold_value: float) -&gt; None:\n        \"\"\"Set the alert_threshold_value\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertCondition.alert_threshold","title":"<code>alert_threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_threshold</p>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertCondition.alert_threshold_value","title":"<code>alert_threshold_value</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_threshold_value</p>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertCondition.__init__","title":"<code>__init__(alert_threshold, alert_threshold_value)</code>","text":"<p>Initialize a CustomMetricAlertCondition instance. Args:     alert_threshold (AlertThreshold): The condition that determines when an alert         should be triggered. This could be comparisons like 'greater than',         'less than', 'equal to', etc.     alert_threshold_value (Optional[float], optional): A numerical boundary used in         conjunction with the alert_threshold. This can be None for certain         types of comparisons that don't require a fixed boundary. Example:     alert_threshold = CustomMetricAlertCondition(AlertCondition.BELOW, 2.0)</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float],\n):\n    \"\"\"Initialize a CustomMetricAlertCondition instance.\n    Args:\n        alert_threshold (AlertThreshold): The condition that determines when an alert\n            should be triggered. This could be comparisons like 'greater than',\n            'less than', 'equal to', etc.\n        alert_threshold_value (Optional[float], optional): A numerical boundary used in\n            conjunction with the alert_threshold. This can be None for certain\n            types of comparisons that don't require a fixed boundary.\n    Example:\n        alert_threshold = CustomMetricAlertCondition(AlertCondition.BELOW, 2.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertConfig","title":"<code>CustomMetricAlertConfig</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class CustomMetricAlertConfig:\n    def __init__(\n        self,\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            dispatch_config:\n                Alert dispatch config. Defaults to console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def alert_conditions(self) -&gt; dict[str, CustomMetricAlertCondition]:\n        \"\"\"Return the alert_condition that were set during metric definition\"\"\"\n\n    @alert_conditions.setter\n    def alert_conditions(self, alert_conditions: dict[str, CustomMetricAlertCondition]) -&gt; None:\n        \"\"\"Update the alert_condition that were set during metric definition\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertConfig.alert_conditions","title":"<code>alert_conditions</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_condition that were set during metric definition</p>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/alert/#scouter.alert._alert.CustomMetricAlertConfig.__init__","title":"<code>__init__(dispatch_config=None, schedule=None)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch config. Defaults to console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        dispatch_config:\n            Alert dispatch config. Defaults to console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMAlertConfig","title":"<code>LLMAlertConfig</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class LLMAlertConfig:\n    def __init__(\n        self,\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            dispatch_config:\n                Alert dispatch config. Defaults to console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def alert_conditions(self) -&gt; Optional[Dict[str, LLMMetricAlertCondition]]:\n        \"\"\"Return the alert conditions\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMAlertConfig.alert_conditions","title":"<code>alert_conditions</code>  <code>property</code>","text":"<p>Return the alert conditions</p>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMAlertConfig.__init__","title":"<code>__init__(dispatch_config=None, schedule=None)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch config. Defaults to console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        dispatch_config:\n            Alert dispatch config. Defaults to console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMMetricAlertCondition","title":"<code>LLMMetricAlertCondition</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class LLMMetricAlertCondition:\n    def __init__(\n        self,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float],\n    ):\n        \"\"\"Initialize a LLMMetricAlertCondition instance.\n        Args:\n            alert_threshold (AlertThreshold):\n                The condition that determines when an alert should be triggered.\n                Must be one of the AlertThreshold enum members like Below, Above, or Outside.\n            alert_threshold_value (Optional[float], optional):\n                A numerical boundary used in conjunction with the alert_threshold.\n                This can be None for certain types of comparisons that don't require a fixed boundary.\n        Example:\n            alert_threshold = LLMMetricAlertCondition(AlertCondition.BELOW, 2.0)\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of LLMMetricAlertCondition.\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMMetricAlertCondition.__init__","title":"<code>__init__(alert_threshold, alert_threshold_value)</code>","text":"<p>Initialize a LLMMetricAlertCondition instance. Args:     alert_threshold (AlertThreshold):         The condition that determines when an alert should be triggered.         Must be one of the AlertThreshold enum members like Below, Above, or Outside.     alert_threshold_value (Optional[float], optional):         A numerical boundary used in conjunction with the alert_threshold.         This can be None for certain types of comparisons that don't require a fixed boundary. Example:     alert_threshold = LLMMetricAlertCondition(AlertCondition.BELOW, 2.0)</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float],\n):\n    \"\"\"Initialize a LLMMetricAlertCondition instance.\n    Args:\n        alert_threshold (AlertThreshold):\n            The condition that determines when an alert should be triggered.\n            Must be one of the AlertThreshold enum members like Below, Above, or Outside.\n        alert_threshold_value (Optional[float], optional):\n            A numerical boundary used in conjunction with the alert_threshold.\n            This can be None for certain types of comparisons that don't require a fixed boundary.\n    Example:\n        alert_threshold = LLMMetricAlertCondition(AlertCondition.BELOW, 2.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.LLMMetricAlertCondition.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of LLMMetricAlertCondition.</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of LLMMetricAlertCondition.\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.OpsGenieDispatchConfig","title":"<code>OpsGenieDispatchConfig</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class OpsGenieDispatchConfig:\n    def __init__(self, team: str):\n        \"\"\"Initialize alert config\n\n        Args:\n            team:\n                Opsegenie team to be notified in the event of drift\n        \"\"\"\n\n    @property\n    def team(self) -&gt; str:\n        \"\"\"Return the opesgenie team name\"\"\"\n\n    @team.setter\n    def team(self, team: str) -&gt; None:\n        \"\"\"Set the opesgenie team name\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.OpsGenieDispatchConfig.team","title":"<code>team</code>  <code>property</code> <code>writable</code>","text":"<p>Return the opesgenie team name</p>"},{"location":"docs/api/alert/#scouter.alert._alert.OpsGenieDispatchConfig.__init__","title":"<code>__init__(team)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>team</code> <code>str</code> <p>Opsegenie team to be notified in the event of drift</p> required Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, team: str):\n    \"\"\"Initialize alert config\n\n    Args:\n        team:\n            Opsegenie team to be notified in the event of drift\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiAlertConfig","title":"<code>PsiAlertConfig</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class PsiAlertConfig:\n    def __init__(\n        self,\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n        features_to_monitor: List[str] = [],\n        threshold: Optional[PsiThresholdType] = PsiChiSquareThreshold(),\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            dispatch_config:\n                Alert dispatch configuration to use. Defaults to an internal \"Console\" type where\n                the alerts will be logged to the console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n            features_to_monitor:\n                List of features to monitor. Defaults to empty list, which means all features\n            threshold:\n                Configuration that helps determine how to calculate PSI critical values.\n                Defaults to PsiChiSquareThreshold, which uses the chi-square distribution.\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def threshold(self) -&gt; PsiThresholdType:\n        \"\"\"Return the threshold config\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def features_to_monitor(self) -&gt; List[str]:\n        \"\"\"Return the features to monitor\"\"\"\n\n    @features_to_monitor.setter\n    def features_to_monitor(self, features_to_monitor: List[str]) -&gt; None:\n        \"\"\"Set the features to monitor\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiAlertConfig.features_to_monitor","title":"<code>features_to_monitor</code>  <code>property</code> <code>writable</code>","text":"<p>Return the features to monitor</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiAlertConfig.threshold","title":"<code>threshold</code>  <code>property</code>","text":"<p>Return the threshold config</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiAlertConfig.__init__","title":"<code>__init__(dispatch_config=None, schedule=None, features_to_monitor=[], threshold=PsiChiSquareThreshold())</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch configuration to use. Defaults to an internal \"Console\" type where the alerts will be logged to the console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> <code>features_to_monitor</code> <code>List[str]</code> <p>List of features to monitor. Defaults to empty list, which means all features</p> <code>[]</code> <code>threshold</code> <code>Optional[PsiThresholdType]</code> <p>Configuration that helps determine how to calculate PSI critical values. Defaults to PsiChiSquareThreshold, which uses the chi-square distribution.</p> <code>PsiChiSquareThreshold()</code> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n    features_to_monitor: List[str] = [],\n    threshold: Optional[PsiThresholdType] = PsiChiSquareThreshold(),\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        dispatch_config:\n            Alert dispatch configuration to use. Defaults to an internal \"Console\" type where\n            the alerts will be logged to the console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n        features_to_monitor:\n            List of features to monitor. Defaults to empty list, which means all features\n        threshold:\n            Configuration that helps determine how to calculate PSI critical values.\n            Defaults to PsiChiSquareThreshold, which uses the chi-square distribution.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiChiSquareThreshold","title":"<code>PsiChiSquareThreshold</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class PsiChiSquareThreshold:\n    def __init__(self, alpha: float = 0.05):\n        \"\"\"Initialize PSI threshold using chi-square approximation.\n\n        Uses the asymptotic chi-square distribution of PSI.\n\n        The chi-square method is generally more statistically rigorous than\n        normal approximation, especially for smaller sample sizes.\n\n        Args:\n            alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n                   0.05 (95% confidence), 0.01 (99% confidence)\n\n        Raises:\n            ValueError: If alpha not in range (0.0, 1.0)\n        \"\"\"\n\n    @property\n    def alpha(self) -&gt; float:\n        \"\"\"Statistical significance level for drift detection.\"\"\"\n\n    @alpha.setter\n    def alpha(self, alpha: float) -&gt; None:\n        \"\"\"Set significance level (must be between 0.0 and 1.0, exclusive).\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiChiSquareThreshold.alpha","title":"<code>alpha</code>  <code>property</code> <code>writable</code>","text":"<p>Statistical significance level for drift detection.</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiChiSquareThreshold.__init__","title":"<code>__init__(alpha=0.05)</code>","text":"<p>Initialize PSI threshold using chi-square approximation.</p> <p>Uses the asymptotic chi-square distribution of PSI.</p> <p>The chi-square method is generally more statistically rigorous than normal approximation, especially for smaller sample sizes.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level (0.0 to 1.0, exclusive). Common values:    0.05 (95% confidence), 0.01 (99% confidence)</p> <code>0.05</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alpha not in range (0.0, 1.0)</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, alpha: float = 0.05):\n    \"\"\"Initialize PSI threshold using chi-square approximation.\n\n    Uses the asymptotic chi-square distribution of PSI.\n\n    The chi-square method is generally more statistically rigorous than\n    normal approximation, especially for smaller sample sizes.\n\n    Args:\n        alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n               0.05 (95% confidence), 0.01 (99% confidence)\n\n    Raises:\n        ValueError: If alpha not in range (0.0, 1.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiFixedThreshold","title":"<code>PsiFixedThreshold</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class PsiFixedThreshold:\n    def __init__(self, threshold: float = 0.25):\n        \"\"\"Initialize PSI threshold using a fixed value.\n\n        Uses a predetermined PSI threshold value, similar to traditional\n        \"rule of thumb\" approaches (e.g., 0.10 for moderate drift, 0.25\n        for significant drift).\n\n        Args:\n            threshold: Fixed PSI threshold value (must be positive).\n                      Common industry values: 0.10, 0.25\n\n        Raises:\n            ValueError: If threshold is not positive\n        \"\"\"\n\n    @property\n    def threshold(self) -&gt; float:\n        \"\"\"Fixed PSI threshold value for drift detection.\"\"\"\n\n    @threshold.setter\n    def threshold(self, threshold: float) -&gt; None:\n        \"\"\"Set threshold value (must be positive).\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiFixedThreshold.threshold","title":"<code>threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Fixed PSI threshold value for drift detection.</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiFixedThreshold.__init__","title":"<code>__init__(threshold=0.25)</code>","text":"<p>Initialize PSI threshold using a fixed value.</p> <p>Uses a predetermined PSI threshold value, similar to traditional \"rule of thumb\" approaches (e.g., 0.10 for moderate drift, 0.25 for significant drift).</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Fixed PSI threshold value (must be positive).       Common industry values: 0.10, 0.25</p> <code>0.25</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If threshold is not positive</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, threshold: float = 0.25):\n    \"\"\"Initialize PSI threshold using a fixed value.\n\n    Uses a predetermined PSI threshold value, similar to traditional\n    \"rule of thumb\" approaches (e.g., 0.10 for moderate drift, 0.25\n    for significant drift).\n\n    Args:\n        threshold: Fixed PSI threshold value (must be positive).\n                  Common industry values: 0.10, 0.25\n\n    Raises:\n        ValueError: If threshold is not positive\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiNormalThreshold","title":"<code>PsiNormalThreshold</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class PsiNormalThreshold:\n    def __init__(self, alpha: float = 0.05):\n        \"\"\"Initialize PSI threshold using normal approximation.\n\n        Uses the asymptotic normal distribution of PSI to calculate critical values\n        for population drift detection.\n\n        Args:\n            alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n                   0.05 (95% confidence), 0.01 (99% confidence)\n\n        Raises:\n            ValueError: If alpha not in range (0.0, 1.0)\n        \"\"\"\n\n    @property\n    def alpha(self) -&gt; float:\n        \"\"\"Statistical significance level for drift detection.\"\"\"\n\n    @alpha.setter\n    def alpha(self, alpha: float) -&gt; None:\n        \"\"\"Set significance level (must be between 0.0 and 1.0, exclusive).\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiNormalThreshold.alpha","title":"<code>alpha</code>  <code>property</code> <code>writable</code>","text":"<p>Statistical significance level for drift detection.</p>"},{"location":"docs/api/alert/#scouter.alert._alert.PsiNormalThreshold.__init__","title":"<code>__init__(alpha=0.05)</code>","text":"<p>Initialize PSI threshold using normal approximation.</p> <p>Uses the asymptotic normal distribution of PSI to calculate critical values for population drift detection.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level (0.0 to 1.0, exclusive). Common values:    0.05 (95% confidence), 0.01 (99% confidence)</p> <code>0.05</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alpha not in range (0.0, 1.0)</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, alpha: float = 0.05):\n    \"\"\"Initialize PSI threshold using normal approximation.\n\n    Uses the asymptotic normal distribution of PSI to calculate critical values\n    for population drift detection.\n\n    Args:\n        alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n               0.05 (95% confidence), 0.01 (99% confidence)\n\n    Raises:\n        ValueError: If alpha not in range (0.0, 1.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SlackDispatchConfig","title":"<code>SlackDispatchConfig</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class SlackDispatchConfig:\n    def __init__(self, channel: str):\n        \"\"\"Initialize alert config\n\n        Args:\n            channel:\n                Slack channel name for where alerts will be reported\n        \"\"\"\n\n    @property\n    def channel(self) -&gt; str:\n        \"\"\"Return the slack channel name\"\"\"\n\n    @channel.setter\n    def channel(self, channel: str) -&gt; None:\n        \"\"\"Set the slack channel name for where alerts will be reported\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SlackDispatchConfig.channel","title":"<code>channel</code>  <code>property</code> <code>writable</code>","text":"<p>Return the slack channel name</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SlackDispatchConfig.__init__","title":"<code>__init__(channel)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>Slack channel name for where alerts will be reported</p> required Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, channel: str):\n    \"\"\"Initialize alert config\n\n    Args:\n        channel:\n            Slack channel name for where alerts will be reported\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlert","title":"<code>SpcAlert</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class SpcAlert:\n    def __init__(self, kind: SpcAlertType, zone: AlertZone):\n        \"\"\"Initialize alert\"\"\"\n\n    @property\n    def kind(self) -&gt; SpcAlertType:\n        \"\"\"Alert kind\"\"\"\n\n    @property\n    def zone(self) -&gt; AlertZone:\n        \"\"\"Zone associated with alert\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the alert.\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlert.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>Alert kind</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlert.zone","title":"<code>zone</code>  <code>property</code>","text":"<p>Zone associated with alert</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlert.__init__","title":"<code>__init__(kind, zone)</code>","text":"<p>Initialize alert</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, kind: SpcAlertType, zone: AlertZone):\n    \"\"\"Initialize alert\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlert.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the alert.</p> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the alert.\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertConfig","title":"<code>SpcAlertConfig</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class SpcAlertConfig:\n    def __init__(\n        self,\n        rule: SpcAlertRule = SpcAlertRule(),\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n        features_to_monitor: List[str] = [],\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            rule:\n                Alert rule to use. Defaults to Standard\n            dispatch_config:\n                Alert dispatch config. Defaults to console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n            features_to_monitor:\n                List of features to monitor. Defaults to empty list, which means all features\n\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def rule(self) -&gt; SpcAlertRule:\n        \"\"\"Return the alert rule\"\"\"\n\n    @rule.setter\n    def rule(self, rule: SpcAlertRule) -&gt; None:\n        \"\"\"Set the alert rule\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def features_to_monitor(self) -&gt; List[str]:\n        \"\"\"Return the features to monitor\"\"\"\n\n    @features_to_monitor.setter\n    def features_to_monitor(self, features_to_monitor: List[str]) -&gt; None:\n        \"\"\"Set the features to monitor\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertConfig.features_to_monitor","title":"<code>features_to_monitor</code>  <code>property</code> <code>writable</code>","text":"<p>Return the features to monitor</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertConfig.rule","title":"<code>rule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert rule</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertConfig.__init__","title":"<code>__init__(rule=SpcAlertRule(), dispatch_config=None, schedule=None, features_to_monitor=[])</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>rule</code> <code>SpcAlertRule</code> <p>Alert rule to use. Defaults to Standard</p> <code>SpcAlertRule()</code> <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch config. Defaults to console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> <code>features_to_monitor</code> <code>List[str]</code> <p>List of features to monitor. Defaults to empty list, which means all features</p> <code>[]</code> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    rule: SpcAlertRule = SpcAlertRule(),\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n    features_to_monitor: List[str] = [],\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        rule:\n            Alert rule to use. Defaults to Standard\n        dispatch_config:\n            Alert dispatch config. Defaults to console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n        features_to_monitor:\n            List of features to monitor. Defaults to empty list, which means all features\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertRule","title":"<code>SpcAlertRule</code>","text":"Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>class SpcAlertRule:\n    def __init__(\n        self,\n        rule: str = \"8 16 4 8 2 4 1 1\",\n        zones_to_monitor: List[AlertZone] = [\n            AlertZone.Zone1,\n            AlertZone.Zone2,\n            AlertZone.Zone3,\n            AlertZone.Zone4,\n        ],\n    ) -&gt; None:\n        \"\"\"Initialize alert rule\n\n        Args:\n            rule:\n                Rule to use for alerting. Eight digit integer string.\n                Defaults to '8 16 4 8 2 4 1 1'\n            zones_to_monitor:\n                List of zones to monitor. Defaults to all zones.\n        \"\"\"\n\n    @property\n    def rule(self) -&gt; str:\n        \"\"\"Return the alert rule\"\"\"\n\n    @rule.setter\n    def rule(self, rule: str) -&gt; None:\n        \"\"\"Set the alert rule\"\"\"\n\n    @property\n    def zones_to_monitor(self) -&gt; List[AlertZone]:\n        \"\"\"Return the zones to monitor\"\"\"\n\n    @zones_to_monitor.setter\n    def zones_to_monitor(self, zones_to_monitor: List[AlertZone]) -&gt; None:\n        \"\"\"Set the zones to monitor\"\"\"\n</code></pre>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertRule.rule","title":"<code>rule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert rule</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertRule.zones_to_monitor","title":"<code>zones_to_monitor</code>  <code>property</code> <code>writable</code>","text":"<p>Return the zones to monitor</p>"},{"location":"docs/api/alert/#scouter.alert._alert.SpcAlertRule.__init__","title":"<code>__init__(rule='8 16 4 8 2 4 1 1', zones_to_monitor=[AlertZone.Zone1, AlertZone.Zone2, AlertZone.Zone3, AlertZone.Zone4])</code>","text":"<p>Initialize alert rule</p> <p>Parameters:</p> Name Type Description Default <code>rule</code> <code>str</code> <p>Rule to use for alerting. Eight digit integer string. Defaults to '8 16 4 8 2 4 1 1'</p> <code>'8 16 4 8 2 4 1 1'</code> <code>zones_to_monitor</code> <code>List[AlertZone]</code> <p>List of zones to monitor. Defaults to all zones.</p> <code>[Zone1, Zone2, Zone3, Zone4]</code> Source code in <code>python/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    rule: str = \"8 16 4 8 2 4 1 1\",\n    zones_to_monitor: List[AlertZone] = [\n        AlertZone.Zone1,\n        AlertZone.Zone2,\n        AlertZone.Zone3,\n        AlertZone.Zone4,\n    ],\n) -&gt; None:\n    \"\"\"Initialize alert rule\n\n    Args:\n        rule:\n            Rule to use for alerting. Eight digit integer string.\n            Defaults to '8 16 4 8 2 4 1 1'\n        zones_to_monitor:\n            List of zones to monitor. Defaults to all zones.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/","title":"Client","text":""},{"location":"docs/api/client/#scouter.client._client.DriftAlertRequest","title":"<code>DriftAlertRequest</code>","text":"Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>class DriftAlertRequest:\n    def __init__(\n        self,\n        name: str,\n        space: str,\n        version: str,\n        active: bool = False,\n        limit_datetime: Optional[datetime.datetime] = None,\n        limit: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Initialize drift alert request\n\n        Args:\n            name:\n                Name\n            space:\n                Space\n            version:\n                Version\n            active:\n                Whether to get active alerts only\n            limit_datetime:\n                Limit datetime for alerts\n            limit:\n                Limit for number of alerts to return\n        \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.DriftAlertRequest.__init__","title":"<code>__init__(name, space, version, active=False, limit_datetime=None, limit=None)</code>","text":"<p>Initialize drift alert request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name</p> required <code>space</code> <code>str</code> <p>Space</p> required <code>version</code> <code>str</code> <p>Version</p> required <code>active</code> <code>bool</code> <p>Whether to get active alerts only</p> <code>False</code> <code>limit_datetime</code> <code>Optional[datetime]</code> <p>Limit datetime for alerts</p> <code>None</code> <code>limit</code> <code>Optional[int]</code> <p>Limit for number of alerts to return</p> <code>None</code> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    space: str,\n    version: str,\n    active: bool = False,\n    limit_datetime: Optional[datetime.datetime] = None,\n    limit: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Initialize drift alert request\n\n    Args:\n        name:\n            Name\n        space:\n            Space\n        version:\n            Version\n        active:\n            Whether to get active alerts only\n        limit_datetime:\n            Limit datetime for alerts\n        limit:\n            Limit for number of alerts to return\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.DriftRequest","title":"<code>DriftRequest</code>","text":"Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>class DriftRequest:\n    def __init__(\n        self,\n        name: str,\n        space: str,\n        version: str,\n        time_interval: TimeInterval,\n        max_data_points: int,\n        drift_type: DriftType,\n    ) -&gt; None:\n        \"\"\"Initialize drift request\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            time_interval:\n                Time window for drift request\n            max_data_points:\n                Maximum data points to return\n            drift_type:\n                Drift type for request\n        \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.DriftRequest.__init__","title":"<code>__init__(name, space, version, time_interval, max_data_points, drift_type)</code>","text":"<p>Initialize drift request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name</p> required <code>space</code> <code>str</code> <p>Model space</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>time_interval</code> <code>TimeInterval</code> <p>Time window for drift request</p> required <code>max_data_points</code> <code>int</code> <p>Maximum data points to return</p> required <code>drift_type</code> <code>DriftType</code> <p>Drift type for request</p> required Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    space: str,\n    version: str,\n    time_interval: TimeInterval,\n    max_data_points: int,\n    drift_type: DriftType,\n) -&gt; None:\n    \"\"\"Initialize drift request\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        time_interval:\n            Time window for drift request\n        max_data_points:\n            Maximum data points to return\n        drift_type:\n            Drift type for request\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.GetProfileRequest","title":"<code>GetProfileRequest</code>","text":"Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>class GetProfileRequest:\n    def __init__(self, name: str, space: str, version: str, drift_type: DriftType) -&gt; None:\n        \"\"\"Initialize get profile request\n\n        Args:\n            name:\n                Profile name\n            space:\n                Profile space\n            version:\n                Profile version\n            drift_type:\n                Profile drift type. A (repo/name/version can be associated with more than one drift type)\n        \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.GetProfileRequest.__init__","title":"<code>__init__(name, space, version, drift_type)</code>","text":"<p>Initialize get profile request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Profile name</p> required <code>space</code> <code>str</code> <p>Profile space</p> required <code>version</code> <code>str</code> <p>Profile version</p> required <code>drift_type</code> <code>DriftType</code> <p>Profile drift type. A (repo/name/version can be associated with more than one drift type)</p> required Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def __init__(self, name: str, space: str, version: str, drift_type: DriftType) -&gt; None:\n    \"\"\"Initialize get profile request\n\n    Args:\n        name:\n            Profile name\n        space:\n            Profile space\n        version:\n            Profile version\n        drift_type:\n            Profile drift type. A (repo/name/version can be associated with more than one drift type)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.HTTPConfig","title":"<code>HTTPConfig</code>","text":"Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>class HTTPConfig:\n    server_uri: str\n    username: str\n    password: str\n    auth_token: str\n\n    def __init__(\n        self,\n        server_uri: Optional[str] = None,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        auth_token: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"HTTP configuration to use with the HTTPProducer.\n\n        Args:\n            server_uri:\n                URL of the HTTP server to publish messages to.\n                If not provided, the value of the HTTP_server_uri environment variable is used.\n\n            username:\n                Username for basic authentication.\n\n            password:\n                Password for basic authentication.\n\n            auth_token:\n                Authorization token to use for authentication.\n\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.HTTPConfig.__init__","title":"<code>__init__(server_uri=None, username=None, password=None, auth_token=None)</code>","text":"<p>HTTP configuration to use with the HTTPProducer.</p> <p>Parameters:</p> Name Type Description Default <code>server_uri</code> <code>Optional[str]</code> <p>URL of the HTTP server to publish messages to. If not provided, the value of the HTTP_server_uri environment variable is used.</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>Username for basic authentication.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>Password for basic authentication.</p> <code>None</code> <code>auth_token</code> <code>Optional[str]</code> <p>Authorization token to use for authentication.</p> <code>None</code> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def __init__(\n    self,\n    server_uri: Optional[str] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    auth_token: Optional[str] = None,\n) -&gt; None:\n    \"\"\"HTTP configuration to use with the HTTPProducer.\n\n    Args:\n        server_uri:\n            URL of the HTTP server to publish messages to.\n            If not provided, the value of the HTTP_server_uri environment variable is used.\n\n        username:\n            Username for basic authentication.\n\n        password:\n            Password for basic authentication.\n\n        auth_token:\n            Authorization token to use for authentication.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ProfileStatusRequest","title":"<code>ProfileStatusRequest</code>","text":"Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>class ProfileStatusRequest:\n    def __init__(self, name: str, space: str, version: str, drift_type: DriftType, active: bool) -&gt; None:\n        \"\"\"Initialize profile status request\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            drift_type:\n                Profile drift type. A (repo/name/version can be associated with more than one drift type)\n            active:\n                Whether to set the profile as active or inactive\n        \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ProfileStatusRequest.__init__","title":"<code>__init__(name, space, version, drift_type, active)</code>","text":"<p>Initialize profile status request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name</p> required <code>space</code> <code>str</code> <p>Model space</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>drift_type</code> <code>DriftType</code> <p>Profile drift type. A (repo/name/version can be associated with more than one drift type)</p> required <code>active</code> <code>bool</code> <p>Whether to set the profile as active or inactive</p> required Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def __init__(self, name: str, space: str, version: str, drift_type: DriftType, active: bool) -&gt; None:\n    \"\"\"Initialize profile status request\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        drift_type:\n            Profile drift type. A (repo/name/version can be associated with more than one drift type)\n        active:\n            Whether to set the profile as active or inactive\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ScouterClient","title":"<code>ScouterClient</code>","text":"<p>Helper client for interacting with Scouter Server</p> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>class ScouterClient:\n    \"\"\"Helper client for interacting with Scouter Server\"\"\"\n\n    def __init__(self, config: Optional[HTTPConfig] = None) -&gt; None:\n        \"\"\"Initialize ScouterClient\n\n        Args:\n            config:\n                HTTP configuration for interacting with the server.\n        \"\"\"\n\n    def get_binned_drift(self, drift_request: DriftRequest) -&gt; Any:\n        \"\"\"Get drift map from server\n\n        Args:\n            drift_request:\n                DriftRequest object\n\n        Returns:\n            Drift map of type BinnedMetrics | BinnedPsiFeatureMetrics | BinnedSpcFeatureMetrics\n        \"\"\"\n\n    def register_profile(self, profile: Any, set_active: bool = False) -&gt; bool:\n        \"\"\"Registers a drift profile with the server\n\n        Args:\n            profile:\n                Drift profile\n            set_active:\n                Whether to set the profile as active or inactive\n\n        Returns:\n            boolean\n        \"\"\"\n\n    def update_profile_status(self, request: ProfileStatusRequest) -&gt; bool:\n        \"\"\"Update profile status\n\n        Args:\n            request:\n                ProfileStatusRequest\n\n        Returns:\n            boolean\n        \"\"\"\n\n    def get_alerts(self, request: DriftAlertRequest) -&gt; List[Alert]:\n        \"\"\"Get alerts\n\n        Args:\n            request:\n                DriftAlertRequest\n\n        Returns:\n            List[Alert]\n        \"\"\"\n\n    def download_profile(self, request: GetProfileRequest, path: Optional[Path]) -&gt; str:\n        \"\"\"Download profile\n\n        Args:\n            request:\n                GetProfileRequest\n            path:\n                Path to save profile\n\n        Returns:\n            Path to downloaded profile\n        \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ScouterClient.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Initialize ScouterClient</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional[HTTPConfig]</code> <p>HTTP configuration for interacting with the server.</p> <code>None</code> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def __init__(self, config: Optional[HTTPConfig] = None) -&gt; None:\n    \"\"\"Initialize ScouterClient\n\n    Args:\n        config:\n            HTTP configuration for interacting with the server.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ScouterClient.download_profile","title":"<code>download_profile(request, path)</code>","text":"<p>Download profile</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>GetProfileRequest</code> <p>GetProfileRequest</p> required <code>path</code> <code>Optional[Path]</code> <p>Path to save profile</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to downloaded profile</p> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def download_profile(self, request: GetProfileRequest, path: Optional[Path]) -&gt; str:\n    \"\"\"Download profile\n\n    Args:\n        request:\n            GetProfileRequest\n        path:\n            Path to save profile\n\n    Returns:\n        Path to downloaded profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ScouterClient.get_alerts","title":"<code>get_alerts(request)</code>","text":"<p>Get alerts</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>DriftAlertRequest</code> <p>DriftAlertRequest</p> required <p>Returns:</p> Type Description <code>List[Alert]</code> <p>List[Alert]</p> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def get_alerts(self, request: DriftAlertRequest) -&gt; List[Alert]:\n    \"\"\"Get alerts\n\n    Args:\n        request:\n            DriftAlertRequest\n\n    Returns:\n        List[Alert]\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ScouterClient.get_binned_drift","title":"<code>get_binned_drift(drift_request)</code>","text":"<p>Get drift map from server</p> <p>Parameters:</p> Name Type Description Default <code>drift_request</code> <code>DriftRequest</code> <p>DriftRequest object</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Drift map of type BinnedMetrics | BinnedPsiFeatureMetrics | BinnedSpcFeatureMetrics</p> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def get_binned_drift(self, drift_request: DriftRequest) -&gt; Any:\n    \"\"\"Get drift map from server\n\n    Args:\n        drift_request:\n            DriftRequest object\n\n    Returns:\n        Drift map of type BinnedMetrics | BinnedPsiFeatureMetrics | BinnedSpcFeatureMetrics\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ScouterClient.register_profile","title":"<code>register_profile(profile, set_active=False)</code>","text":"<p>Registers a drift profile with the server</p> <p>Parameters:</p> Name Type Description Default <code>profile</code> <code>Any</code> <p>Drift profile</p> required <code>set_active</code> <code>bool</code> <p>Whether to set the profile as active or inactive</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>boolean</p> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def register_profile(self, profile: Any, set_active: bool = False) -&gt; bool:\n    \"\"\"Registers a drift profile with the server\n\n    Args:\n        profile:\n            Drift profile\n        set_active:\n            Whether to set the profile as active or inactive\n\n    Returns:\n        boolean\n    \"\"\"\n</code></pre>"},{"location":"docs/api/client/#scouter.client._client.ScouterClient.update_profile_status","title":"<code>update_profile_status(request)</code>","text":"<p>Update profile status</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>ProfileStatusRequest</code> <p>ProfileStatusRequest</p> required <p>Returns:</p> Type Description <code>bool</code> <p>boolean</p> Source code in <code>python/scouter/client/_client.pyi</code> <pre><code>def update_profile_status(self, request: ProfileStatusRequest) -&gt; bool:\n    \"\"\"Update profile status\n\n    Args:\n        request:\n            ProfileStatusRequest\n\n    Returns:\n        boolean\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/","title":"Drift","text":""},{"location":"docs/api/drift/#scouter.drift._drift.Bin","title":"<code>Bin</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class Bin:\n    @property\n    def id(self) -&gt; int:\n        \"\"\"Return the bin id.\"\"\"\n\n    @property\n    def lower_limit(self) -&gt; float:\n        \"\"\"Return the lower limit of the bin.\"\"\"\n\n    @property\n    def upper_limit(self) -&gt; Optional[float]:\n        \"\"\"Return the upper limit of the bin.\"\"\"\n\n    @property\n    def proportion(self) -&gt; float:\n        \"\"\"Return the proportion of data found in the bin.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.Bin.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the bin id.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.Bin.lower_limit","title":"<code>lower_limit</code>  <code>property</code>","text":"<p>Return the lower limit of the bin.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.Bin.proportion","title":"<code>proportion</code>  <code>property</code>","text":"<p>Return the proportion of data found in the bin.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.Bin.upper_limit","title":"<code>upper_limit</code>  <code>property</code>","text":"<p>Return the upper limit of the bin.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile","title":"<code>CustomDriftProfile</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class CustomDriftProfile:\n    def __init__(\n        self,\n        config: CustomMetricDriftConfig,\n        metrics: list[CustomMetric],\n    ):\n        \"\"\"Initialize a CustomDriftProfile instance.\n\n        Args:\n            config (CustomMetricDriftConfig):\n                The configuration for custom metric drift detection.\n            metrics (list[CustomMetric]):\n                A list of CustomMetric objects representing the metrics to be monitored.\n\n        Example:\n            config = CustomMetricDriftConfig(...)\n            metrics = [CustomMetric(\"accuracy\", 0.95), CustomMetric(\"f1_score\", 0.88)]\n            profile = CustomDriftProfile(config, metrics, \"1.0.0\")\n        \"\"\"\n\n    @property\n    def config(self) -&gt; CustomMetricDriftConfig:\n        \"\"\"Return the drift config\"\"\"\n\n    @property\n    def metrics(self) -&gt; dict[str, float]:\n        \"\"\"Return custom metrics and their corresponding values\"\"\"\n\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    @property\n    def custom_metrics(self) -&gt; list[CustomMetric]:\n        \"\"\"Return custom metric objects that were used to create the drift profile\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Sting representation of DriftProfile\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path:\n                Optional path to save the drift profile. If None, outputs to `custom_drift_profile.json`\n\n        Returns:\n            Path to the saved json file\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"CustomDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"CustomDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"CustomDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the file\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[CustomMetricAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            space (Optional[str]):\n                Model space\n            name (Optional[str]):\n                Model name\n            version (Optional[str]):\n                Model version\n            alert_config (Optional[CustomMetricAlertConfig]):\n                Custom metric alert configuration\n\n        Returns:\n            None\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the drift config</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.custom_metrics","title":"<code>custom_metrics</code>  <code>property</code>","text":"<p>Return custom metric objects that were used to create the drift profile</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Return custom metrics and their corresponding values</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.__init__","title":"<code>__init__(config, metrics)</code>","text":"<p>Initialize a CustomDriftProfile instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>CustomMetricDriftConfig</code> <p>The configuration for custom metric drift detection.</p> required <code>metrics</code> <code>list[CustomMetric]</code> <p>A list of CustomMetric objects representing the metrics to be monitored.</p> required Example <p>config = CustomMetricDriftConfig(...) metrics = [CustomMetric(\"accuracy\", 0.95), CustomMetric(\"f1_score\", 0.88)] profile = CustomDriftProfile(config, metrics, \"1.0.0\")</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    config: CustomMetricDriftConfig,\n    metrics: list[CustomMetric],\n):\n    \"\"\"Initialize a CustomDriftProfile instance.\n\n    Args:\n        config (CustomMetricDriftConfig):\n            The configuration for custom metric drift detection.\n        metrics (list[CustomMetric]):\n            A list of CustomMetric objects representing the metrics to be monitored.\n\n    Example:\n        config = CustomMetricDriftConfig(...)\n        metrics = [CustomMetric(\"accuracy\", 0.95), CustomMetric(\"f1_score\", 0.88)]\n        profile = CustomDriftProfile(config, metrics, \"1.0.0\")\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>Sting representation of DriftProfile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the file</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"CustomDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"CustomDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"CustomDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift profile. If None, outputs to <code>custom_drift_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path:\n            Optional path to save the drift profile. If None, outputs to `custom_drift_profile.json`\n\n    Returns:\n        Path to the saved json file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>alert_config</code> <code>Optional[CustomMetricAlertConfig]</code> <p>Custom metric alert configuration</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[CustomMetricAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        space (Optional[str]):\n            Model space\n        name (Optional[str]):\n            Model name\n        version (Optional[str]):\n            Model version\n        alert_config (Optional[CustomMetricAlertConfig]):\n            Custom metric alert configuration\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric","title":"<code>CustomMetric</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class CustomMetric:\n    def __init__(\n        self,\n        name: str,\n        value: float,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float] = None,\n    ):\n        \"\"\"\n        Initialize a custom metric for alerting.\n\n        This class represents a custom metric that uses comparison-based alerting. It applies\n        an alert condition to a single metric value.\n\n        Args:\n            name (str): The name of the metric being monitored. This should be a\n                descriptive identifier for the metric.\n            value (float): The current value of the metric.\n            alert_threshold (AlertThreshold):\n                The condition used to determine when an alert should be triggered.\n            alert_threshold_value (Optional[float]):\n                The threshold or boundary value used in conjunction with the alert_threshold.\n                If supplied, this value will be added or subtracted from the provided metric value to\n                determine if an alert should be triggered.\n\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the metric name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the metric name\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the metric value\"\"\"\n\n    @value.setter\n    def value(self, value: float) -&gt; None:\n        \"\"\"Set the metric value\"\"\"\n\n    @property\n    def alert_condition(self) -&gt; CustomMetricAlertCondition:\n        \"\"\"Return the alert_condition\"\"\"\n\n    @alert_condition.setter\n    def alert_condition(self, alert_condition: CustomMetricAlertCondition) -&gt; None:\n        \"\"\"Set the alert_condition\"\"\"\n\n    @property\n    def alert_threshold(self) -&gt; AlertThreshold:\n        \"\"\"Return the alert_threshold\"\"\"\n\n    @property\n    def alert_threshold_value(self) -&gt; Optional[float]:\n        \"\"\"Return the alert_threshold_value\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric.alert_condition","title":"<code>alert_condition</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_condition</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric.alert_threshold","title":"<code>alert_threshold</code>  <code>property</code>","text":"<p>Return the alert_threshold</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric.alert_threshold_value","title":"<code>alert_threshold_value</code>  <code>property</code>","text":"<p>Return the alert_threshold_value</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Return the metric name</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric.value","title":"<code>value</code>  <code>property</code> <code>writable</code>","text":"<p>Return the metric value</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric.__init__","title":"<code>__init__(name, value, alert_threshold, alert_threshold_value=None)</code>","text":"<p>Initialize a custom metric for alerting.</p> <p>This class represents a custom metric that uses comparison-based alerting. It applies an alert condition to a single metric value.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric being monitored. This should be a descriptive identifier for the metric.</p> required <code>value</code> <code>float</code> <p>The current value of the metric.</p> required <code>alert_threshold</code> <code>AlertThreshold</code> <p>The condition used to determine when an alert should be triggered.</p> required <code>alert_threshold_value</code> <code>Optional[float]</code> <p>The threshold or boundary value used in conjunction with the alert_threshold. If supplied, this value will be added or subtracted from the provided metric value to determine if an alert should be triggered.</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    value: float,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float] = None,\n):\n    \"\"\"\n    Initialize a custom metric for alerting.\n\n    This class represents a custom metric that uses comparison-based alerting. It applies\n    an alert condition to a single metric value.\n\n    Args:\n        name (str): The name of the metric being monitored. This should be a\n            descriptive identifier for the metric.\n        value (float): The current value of the metric.\n        alert_threshold (AlertThreshold):\n            The condition used to determine when an alert should be triggered.\n        alert_threshold_value (Optional[float]):\n            The threshold or boundary value used in conjunction with the alert_threshold.\n            If supplied, this value will be added or subtracted from the provided metric value to\n            determine if an alert should be triggered.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetric.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig","title":"<code>CustomMetricDriftConfig</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class CustomMetricDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        sample_size: int = 25,\n        alert_config: CustomMetricAlertConfig = CustomMetricAlertConfig(),\n    ):\n        \"\"\"Initialize drift config\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version. Defaults to 0.1.0\n            sample_size:\n                Sample size\n            alert_config:\n                Custom metric alert configuration\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @property\n    def alert_config(self) -&gt; CustomMetricAlertConfig:\n        \"\"\"get alert_config\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: CustomMetricAlertConfig) -&gt; None:\n        \"\"\"Set alert_config\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"CustomMetricDriftConfig\":\n        \"\"\"Load config from json file\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[CustomMetricAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            alert_config:\n                Custom metric alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>get alert_config</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', sample_size=25, alert_config=CustomMetricAlertConfig())</code>","text":"<p>Initialize drift config Args:     space:         Model space     name:         Model name     version:         Model version. Defaults to 0.1.0     sample_size:         Sample size     alert_config:         Custom metric alert configuration</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    sample_size: int = 25,\n    alert_config: CustomMetricAlertConfig = CustomMetricAlertConfig(),\n):\n    \"\"\"Initialize drift config\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version. Defaults to 0.1.0\n        sample_size:\n            Sample size\n        alert_config:\n            Custom metric alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file Args:     path:         Path to json file to load config from.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"CustomMetricDriftConfig\":\n    \"\"\"Load config from json file\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.CustomMetricDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args Args:     space:         Model space     name:         Model name     version:         Model version     alert_config:         Custom metric alert configuration</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[CustomMetricAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        alert_config:\n            Custom metric alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.Drifter","title":"<code>Drifter</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class Drifter:\n    def __init__(self) -&gt; None:\n        \"\"\"Instantiate Rust Drifter class that is\n        used to create monitoring profiles and compute drifts.\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Any,\n        config: SpcDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile:\n        \"\"\"Create a SPC (Statistical process control) drift profile from the provided data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                SpcDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftProfile\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Any,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile:\n        \"\"\"Create a SPC (Statistical process control) drift profile from the provided data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                SpcDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftProfile\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Any,\n        config: PsiDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; PsiDriftProfile:\n        \"\"\"Create a PSI (population stability index) drift profile from the provided data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                PsiDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            PsiDriftProfile\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Union[CustomMetric, List[CustomMetric]],\n        config: CustomMetricDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; CustomDriftProfile:\n        \"\"\"Create a custom drift profile from data.\n\n        Args:\n            data:\n                CustomMetric or list of CustomMetric.\n            config:\n                CustomMetricDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            CustomDriftProfile\n        \"\"\"\n\n    def create_drift_profile(  # type: ignore\n        self,\n        data: Any,\n        config: Optional[Union[SpcDriftConfig, PsiDriftConfig, CustomMetricDriftConfig]] = None,\n        data_type: Optional[DataType] = None,\n    ) -&gt; Union[SpcDriftProfile, PsiDriftProfile, CustomDriftProfile]:\n        \"\"\"Create a drift profile from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe, pandas dataframe or a list of CustomMetric if creating\n                a custom metric profile.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                Drift config that will be used for monitoring\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    def create_llm_drift_profile(\n        self,\n        config: LLMDriftConfig,\n        metrics: List[LLMDriftMetric],\n        workflow: Optional[Workflow] = None,\n    ) -&gt; LLMDriftProfile:\n        \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n        LLM evaluations are run asynchronously on the scouter server.\n\n        Logic flow:\n            1. If only metrics are provided, a workflow will be created automatically\n               from the metrics. In this case a prompt is required for each metric.\n            2. If a workflow is provided, it will be parsed and validated for compatibility:\n               - A list of metrics to evaluate workflow output must be provided\n               - Metric names must correspond to the final task names in the workflow\n\n        Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n        Args:\n            config (LLMDriftConfig):\n                The configuration for the LLM drift profile containing space, name,\n                version, and alert settings.\n            metrics (list[LLMDriftMetric]):\n                A list of LLMDriftMetric objects representing the metrics to be monitored.\n                Each metric defines evaluation criteria and alert thresholds.\n            workflow (Optional[Workflow]):\n                Optional custom workflow for advanced evaluation scenarios. If provided,\n                the workflow will be validated to ensure proper parameter and response\n                type configuration.\n\n        Returns:\n            LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n        Raises:\n            ProfileError: If workflow validation fails, metrics are empty when no\n                workflow is provided, or if workflow tasks don't match metric names.\n\n        Examples:\n            Basic usage with metrics only:\n\n            &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n            &gt;&gt;&gt; metrics = [\n            ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n            ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n            ... ]\n            &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n\n            Advanced usage with custom workflow:\n\n            &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n            &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n            &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n\n        Note:\n            - When using custom workflows, ensure final tasks have Score response types\n            - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n            - All metric names must match corresponding workflow task names\n        \"\"\"\n\n    @overload\n    def compute_drift(\n        self,\n        data: Any,\n        drift_profile: SpcDriftProfile,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftMap:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftMap\n        \"\"\"\n\n    @overload\n    def compute_drift(\n        self,\n        data: Any,\n        drift_profile: PsiDriftProfile,\n        data_type: Optional[DataType] = None,\n    ) -&gt; PsiDriftMap:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            PsiDriftMap\n        \"\"\"\n\n    @overload\n    def compute_drift(\n        self,\n        data: Union[LLMRecord, List[LLMRecord]],\n        drift_profile: LLMDriftProfile,\n        data_type: Optional[DataType] = None,\n    ) -&gt; LLMDriftMap:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            LLMDriftMap\n        \"\"\"\n\n    def compute_drift(  # type: ignore\n        self,\n        data: Any,\n        drift_profile: Union[SpcDriftProfile, PsiDriftProfile, LLMDriftProfile],\n        data_type: Optional[DataType] = None,\n    ) -&gt; Union[SpcDriftMap, PsiDriftMap, LLMDriftMap]:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftMap, PsiDriftMap or LLMDriftMap\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.Drifter.__init__","title":"<code>__init__()</code>","text":"<p>Instantiate Rust Drifter class that is used to create monitoring profiles and compute drifts.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Instantiate Rust Drifter class that is\n    used to create monitoring profiles and compute drifts.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.Drifter.compute_drift","title":"<code>compute_drift(data, drift_profile, data_type=None)</code>","text":"<pre><code>compute_drift(\n    data: Any,\n    drift_profile: SpcDriftProfile,\n    data_type: Optional[DataType] = None,\n) -&gt; SpcDriftMap\n</code></pre><pre><code>compute_drift(\n    data: Any,\n    drift_profile: PsiDriftProfile,\n    data_type: Optional[DataType] = None,\n) -&gt; PsiDriftMap\n</code></pre><pre><code>compute_drift(\n    data: Union[LLMRecord, List[LLMRecord]],\n    drift_profile: LLMDriftProfile,\n    data_type: Optional[DataType] = None,\n) -&gt; LLMDriftMap\n</code></pre> <p>Create a drift map from data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to create a data profile from. Data can be a numpy array, a polars dataframe or a pandas dataframe.</p> required <code>drift_profile</code> <code>Union[SpcDriftProfile, PsiDriftProfile, LLMDriftProfile]</code> <p>Drift profile to use to compute drift map</p> required <code>data_type</code> <code>Optional[DataType]</code> <p>Optional data type. Inferred from data if not provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[SpcDriftMap, PsiDriftMap, LLMDriftMap]</code> <p>SpcDriftMap, PsiDriftMap or LLMDriftMap</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def compute_drift(  # type: ignore\n    self,\n    data: Any,\n    drift_profile: Union[SpcDriftProfile, PsiDriftProfile, LLMDriftProfile],\n    data_type: Optional[DataType] = None,\n) -&gt; Union[SpcDriftMap, PsiDriftMap, LLMDriftMap]:\n    \"\"\"Create a drift map from data.\n\n    Args:\n        data:\n            Data to create a data profile from. Data can be a numpy array,\n            a polars dataframe or a pandas dataframe.\n        drift_profile:\n            Drift profile to use to compute drift map\n        data_type:\n            Optional data type. Inferred from data if not provided.\n\n    Returns:\n        SpcDriftMap, PsiDriftMap or LLMDriftMap\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.Drifter.create_drift_profile","title":"<code>create_drift_profile(data, config=None, data_type=None)</code>","text":"<pre><code>create_drift_profile(\n    data: Any,\n    config: SpcDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; SpcDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    data: Any, data_type: Optional[DataType] = None\n) -&gt; SpcDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    data: Any,\n    config: PsiDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; PsiDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    data: Union[CustomMetric, List[CustomMetric]],\n    config: CustomMetricDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; CustomDriftProfile\n</code></pre> <p>Create a drift profile from data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to create a data profile from. Data can be a numpy array, a polars dataframe, pandas dataframe or a list of CustomMetric if creating a custom metric profile.</p> <p>Data is expected to not contain any missing values, NaNs or infinities</p> required <code>config</code> <code>Optional[Union[SpcDriftConfig, PsiDriftConfig, CustomMetricDriftConfig]]</code> <p>Drift config that will be used for monitoring</p> <code>None</code> <code>data_type</code> <code>Optional[DataType]</code> <p>Optional data type. Inferred from data if not provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[SpcDriftProfile, PsiDriftProfile, CustomDriftProfile]</code> <p>SpcDriftProfile, PsiDriftProfile or CustomDriftProfile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def create_drift_profile(  # type: ignore\n    self,\n    data: Any,\n    config: Optional[Union[SpcDriftConfig, PsiDriftConfig, CustomMetricDriftConfig]] = None,\n    data_type: Optional[DataType] = None,\n) -&gt; Union[SpcDriftProfile, PsiDriftProfile, CustomDriftProfile]:\n    \"\"\"Create a drift profile from data.\n\n    Args:\n        data:\n            Data to create a data profile from. Data can be a numpy array,\n            a polars dataframe, pandas dataframe or a list of CustomMetric if creating\n            a custom metric profile.\n\n            **Data is expected to not contain any missing values, NaNs or infinities**\n\n        config:\n            Drift config that will be used for monitoring\n        data_type:\n            Optional data type. Inferred from data if not provided.\n\n    Returns:\n        SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.Drifter.create_llm_drift_profile","title":"<code>create_llm_drift_profile(config, metrics, workflow=None)</code>","text":"<p>Initialize a LLMDriftProfile for LLM evaluation and drift detection.</p> <p>LLM evaluations are run asynchronously on the scouter server.</p> Logic flow <ol> <li>If only metrics are provided, a workflow will be created automatically    from the metrics. In this case a prompt is required for each metric.</li> <li>If a workflow is provided, it will be parsed and validated for compatibility:</li> <li>A list of metrics to evaluate workflow output must be provided</li> <li>Metric names must correspond to the final task names in the workflow</li> </ol> <p>Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LLMDriftConfig</code> <p>The configuration for the LLM drift profile containing space, name, version, and alert settings.</p> required <code>metrics</code> <code>list[LLMDriftMetric]</code> <p>A list of LLMDriftMetric objects representing the metrics to be monitored. Each metric defines evaluation criteria and alert thresholds.</p> required <code>workflow</code> <code>Optional[Workflow]</code> <p>Optional custom workflow for advanced evaluation scenarios. If provided, the workflow will be validated to ensure proper parameter and response type configuration.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LLMDriftProfile</code> <code>LLMDriftProfile</code> <p>Configured profile ready for LLM drift monitoring.</p> <p>Raises:</p> Type Description <code>ProfileError</code> <p>If workflow validation fails, metrics are empty when no workflow is provided, or if workflow tasks don't match metric names.</p> <p>Examples:</p> <p>Basic usage with metrics only:</p> <pre><code>&gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n&gt;&gt;&gt; metrics = [\n...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n... ]\n&gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n</code></pre> <p>Advanced usage with custom workflow:</p> <pre><code>&gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n&gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n&gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n</code></pre> Note <ul> <li>When using custom workflows, ensure final tasks have Score response types</li> <li>Initial workflow tasks must include \"input\" and/or \"response\" parameters</li> <li>All metric names must match corresponding workflow task names</li> </ul> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def create_llm_drift_profile(\n    self,\n    config: LLMDriftConfig,\n    metrics: List[LLMDriftMetric],\n    workflow: Optional[Workflow] = None,\n) -&gt; LLMDriftProfile:\n    \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n    LLM evaluations are run asynchronously on the scouter server.\n\n    Logic flow:\n        1. If only metrics are provided, a workflow will be created automatically\n           from the metrics. In this case a prompt is required for each metric.\n        2. If a workflow is provided, it will be parsed and validated for compatibility:\n           - A list of metrics to evaluate workflow output must be provided\n           - Metric names must correspond to the final task names in the workflow\n\n    Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n    Args:\n        config (LLMDriftConfig):\n            The configuration for the LLM drift profile containing space, name,\n            version, and alert settings.\n        metrics (list[LLMDriftMetric]):\n            A list of LLMDriftMetric objects representing the metrics to be monitored.\n            Each metric defines evaluation criteria and alert thresholds.\n        workflow (Optional[Workflow]):\n            Optional custom workflow for advanced evaluation scenarios. If provided,\n            the workflow will be validated to ensure proper parameter and response\n            type configuration.\n\n    Returns:\n        LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n    Raises:\n        ProfileError: If workflow validation fails, metrics are empty when no\n            workflow is provided, or if workflow tasks don't match metric names.\n\n    Examples:\n        Basic usage with metrics only:\n\n        &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n        &gt;&gt;&gt; metrics = [\n        ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n        ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n        ... ]\n        &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n\n        Advanced usage with custom workflow:\n\n        &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n        &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n        &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n\n    Note:\n        - When using custom workflows, ensure final tasks have Score response types\n        - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n        - All metric names must match corresponding workflow task names\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.FeatureDrift","title":"<code>FeatureDrift</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class FeatureDrift:\n    @property\n    def samples(self) -&gt; List[float]:\n        \"\"\"Return list of samples\"\"\"\n\n    @property\n    def drift(self) -&gt; List[float]:\n        \"\"\"Return list of drift values\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of feature drift\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.FeatureDrift.drift","title":"<code>drift</code>  <code>property</code>","text":"<p>Return list of drift values</p>"},{"location":"docs/api/drift/#scouter.drift._drift.FeatureDrift.samples","title":"<code>samples</code>  <code>property</code>","text":"<p>Return list of samples</p>"},{"location":"docs/api/drift/#scouter.drift._drift.FeatureDrift.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of feature drift</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of feature drift\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.FeatureMap","title":"<code>FeatureMap</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class FeatureMap:\n    @property\n    def features(self) -&gt; Dict[str, Dict[str, int]]:\n        \"\"\"Return the feature map.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the feature map.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.FeatureMap.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the feature map.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.FeatureMap.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the feature map.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the feature map.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig","title":"<code>LLMDriftConfig</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        sample_rate: int = 5,\n        alert_config: LLMAlertConfig = LLMAlertConfig(),\n    ):\n        \"\"\"Initialize drift config\n        Args:\n            space:\n                Space to associate with the config\n            name:\n                Name to associate with the config\n            version:\n                Version to associate with the config. Defaults to 0.1.0\n            sample_rate:\n                Sample rate for LLM drift detection. Defaults to 5.\n            alert_config:\n                Custom metric alert configuration\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @property\n    def alert_config(self) -&gt; LLMAlertConfig:\n        \"\"\"get alert_config\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: LLMAlertConfig) -&gt; None:\n        \"\"\"Set alert_config\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"LLMDriftConfig\":\n        \"\"\"Load config from json file\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[LLMAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n        Args:\n            space:\n                Space to associate with the config\n            name:\n                Name to associate with the config\n            version:\n                Version to associate with the config\n            alert_config:\n                LLM alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>get alert_config</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', sample_rate=5, alert_config=LLMAlertConfig())</code>","text":"<p>Initialize drift config Args:     space:         Space to associate with the config     name:         Name to associate with the config     version:         Version to associate with the config. Defaults to 0.1.0     sample_rate:         Sample rate for LLM drift detection. Defaults to 5.     alert_config:         Custom metric alert configuration</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    sample_rate: int = 5,\n    alert_config: LLMAlertConfig = LLMAlertConfig(),\n):\n    \"\"\"Initialize drift config\n    Args:\n        space:\n            Space to associate with the config\n        name:\n            Name to associate with the config\n        version:\n            Version to associate with the config. Defaults to 0.1.0\n        sample_rate:\n            Sample rate for LLM drift detection. Defaults to 5.\n        alert_config:\n            Custom metric alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file Args:     path:         Path to json file to load config from.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"LLMDriftConfig\":\n    \"\"\"Load config from json file\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args Args:     space:         Space to associate with the config     name:         Name to associate with the config     version:         Version to associate with the config     alert_config:         LLM alert configuration</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[LLMAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n    Args:\n        space:\n            Space to associate with the config\n        name:\n            Name to associate with the config\n        version:\n            Version to associate with the config\n        alert_config:\n            LLM alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMap","title":"<code>LLMDriftMap</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftMap:\n    @property\n    def records(self) -&gt; List[LLMMetricRecord]:\n        \"\"\"Return the list of LLM records.\"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMap.records","title":"<code>records</code>  <code>property</code>","text":"<p>Return the list of LLM records.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMetric","title":"<code>LLMDriftMetric</code>","text":"<p>Metric for monitoring LLM performance.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftMetric:\n    \"\"\"Metric for monitoring LLM performance.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        value: float,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float] = None,\n        prompt: Optional[Prompt] = None,\n    ):\n        \"\"\"\n        Initialize a metric for monitoring LLM performance.\n\n        Args:\n            name (str):\n                The name of the metric being monitored. This should be a\n                descriptive identifier for the metric.\n            value (float):\n                The current value of the metric.\n            alert_threshold (AlertThreshold):\n                The condition used to determine when an alert should be triggered.\n            alert_threshold_value (Optional[float]):\n                The threshold or boundary value used in conjunction with the alert_threshold.\n                If supplied, this value will be added or subtracted from the provided metric value to\n                determine if an alert should be triggered.\n            prompt (Optional[Prompt]):\n                Optional prompt associated with the metric. This can be used to provide context or\n                additional information about the metric being monitored. If creating an LLM drift profile\n                from a pre-defined workflow, this can be none.\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the metric name\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the metric value\"\"\"\n\n    @property\n    def prompt(self) -&gt; Optional[Prompt]:\n        \"\"\"Return the prompt associated with the metric\"\"\"\n\n    @property\n    def alert_threshold(self) -&gt; AlertThreshold:\n        \"\"\"Return the alert_threshold\"\"\"\n\n    @property\n    def alert_threshold_value(self) -&gt; Optional[float]:\n        \"\"\"Return the alert_threshold_value\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMetric.alert_threshold","title":"<code>alert_threshold</code>  <code>property</code>","text":"<p>Return the alert_threshold</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMetric.alert_threshold_value","title":"<code>alert_threshold_value</code>  <code>property</code>","text":"<p>Return the alert_threshold_value</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMetric.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the metric name</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMetric.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>Return the prompt associated with the metric</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMetric.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the metric value</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftMetric.__init__","title":"<code>__init__(name, value, alert_threshold, alert_threshold_value=None, prompt=None)</code>","text":"<p>Initialize a metric for monitoring LLM performance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric being monitored. This should be a descriptive identifier for the metric.</p> required <code>value</code> <code>float</code> <p>The current value of the metric.</p> required <code>alert_threshold</code> <code>AlertThreshold</code> <p>The condition used to determine when an alert should be triggered.</p> required <code>alert_threshold_value</code> <code>Optional[float]</code> <p>The threshold or boundary value used in conjunction with the alert_threshold. If supplied, this value will be added or subtracted from the provided metric value to determine if an alert should be triggered.</p> <code>None</code> <code>prompt</code> <code>Optional[Prompt]</code> <p>Optional prompt associated with the metric. This can be used to provide context or additional information about the metric being monitored. If creating an LLM drift profile from a pre-defined workflow, this can be none.</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    value: float,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float] = None,\n    prompt: Optional[Prompt] = None,\n):\n    \"\"\"\n    Initialize a metric for monitoring LLM performance.\n\n    Args:\n        name (str):\n            The name of the metric being monitored. This should be a\n            descriptive identifier for the metric.\n        value (float):\n            The current value of the metric.\n        alert_threshold (AlertThreshold):\n            The condition used to determine when an alert should be triggered.\n        alert_threshold_value (Optional[float]):\n            The threshold or boundary value used in conjunction with the alert_threshold.\n            If supplied, this value will be added or subtracted from the provided metric value to\n            determine if an alert should be triggered.\n        prompt (Optional[Prompt]):\n            Optional prompt associated with the metric. This can be used to provide context or\n            additional information about the metric being monitored. If creating an LLM drift profile\n            from a pre-defined workflow, this can be none.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile","title":"<code>LLMDriftProfile</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftProfile:\n    def __init__(\n        self,\n        config: LLMDriftConfig,\n        metrics: list[LLMDriftMetric],\n        workflow: Optional[Workflow] = None,\n    ):\n        \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n        LLM evaluations are run asynchronously on the scouter server.\n\n        Logic flow:\n            1. If only metrics are provided, a workflow will be created automatically\n               from the metrics. In this case a prompt is required for each metric.\n            2. If a workflow is provided, it will be parsed and validated for compatibility:\n               - A list of metrics to evaluate workflow output must be provided\n               - Metric names must correspond to the final task names in the workflow\n\n        Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n        Args:\n            config (LLMDriftConfig):\n                The configuration for the LLM drift profile containing space, name,\n                version, and alert settings.\n            metrics (list[LLMDriftMetric]):\n                A list of LLMDriftMetric objects representing the metrics to be monitored.\n                Each metric defines evaluation criteria and alert thresholds.\n            workflow (Optional[Workflow]):\n                Optional custom workflow for advanced evaluation scenarios. If provided,\n                the workflow will be validated to ensure proper parameter and response\n                type configuration.\n\n        Returns:\n            LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n        Raises:\n            ProfileError: If workflow validation fails, metrics are empty when no\n                workflow is provided, or if workflow tasks don't match metric names.\n\n        Examples:\n            Basic usage with metrics only:\n\n            &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n            &gt;&gt;&gt; metrics = [\n            ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n            ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n            ... ]\n            &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics)\n\n            Advanced usage with custom workflow:\n\n            &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n            &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n            &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics, workflow)\n\n        Note:\n            - When using custom workflows, ensure final tasks have Score response types\n            - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n            - All metric names must match corresponding workflow task names\n        \"\"\"\n\n    @property\n    def config(self) -&gt; LLMDriftConfig:\n        \"\"\"Return the drift config\"\"\"\n\n    @property\n    def metrics(self) -&gt; List[LLMDriftMetric]:\n        \"\"\"Return LLM metrics and their corresponding values\"\"\"\n\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of LLMDriftProfile\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path: Optional path to save the json file. If not provided, a default path will be used.\n\n        Returns:\n            Path to the saved json file.\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"LLMDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"LLMDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"LLMDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the json file\n\n        Returns:\n            LLMDriftProfile\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        sample_size: Optional[int] = None,\n        alert_config: Optional[LLMAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the drift config</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Return LLM metrics and their corresponding values</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.__init__","title":"<code>__init__(config, metrics, workflow=None)</code>","text":"<p>Initialize a LLMDriftProfile for LLM evaluation and drift detection.</p> <p>LLM evaluations are run asynchronously on the scouter server.</p> Logic flow <ol> <li>If only metrics are provided, a workflow will be created automatically    from the metrics. In this case a prompt is required for each metric.</li> <li>If a workflow is provided, it will be parsed and validated for compatibility:</li> <li>A list of metrics to evaluate workflow output must be provided</li> <li>Metric names must correspond to the final task names in the workflow</li> </ol> <p>Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LLMDriftConfig</code> <p>The configuration for the LLM drift profile containing space, name, version, and alert settings.</p> required <code>metrics</code> <code>list[LLMDriftMetric]</code> <p>A list of LLMDriftMetric objects representing the metrics to be monitored. Each metric defines evaluation criteria and alert thresholds.</p> required <code>workflow</code> <code>Optional[Workflow]</code> <p>Optional custom workflow for advanced evaluation scenarios. If provided, the workflow will be validated to ensure proper parameter and response type configuration.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LLMDriftProfile</code> <p>Configured profile ready for LLM drift monitoring.</p> <p>Raises:</p> Type Description <code>ProfileError</code> <p>If workflow validation fails, metrics are empty when no workflow is provided, or if workflow tasks don't match metric names.</p> <p>Examples:</p> <p>Basic usage with metrics only:</p> <pre><code>&gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n&gt;&gt;&gt; metrics = [\n...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n... ]\n&gt;&gt;&gt; profile = LLMDriftProfile(config, metrics)\n</code></pre> <p>Advanced usage with custom workflow:</p> <pre><code>&gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n&gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n&gt;&gt;&gt; profile = LLMDriftProfile(config, metrics, workflow)\n</code></pre> Note <ul> <li>When using custom workflows, ensure final tasks have Score response types</li> <li>Initial workflow tasks must include \"input\" and/or \"response\" parameters</li> <li>All metric names must match corresponding workflow task names</li> </ul> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    config: LLMDriftConfig,\n    metrics: list[LLMDriftMetric],\n    workflow: Optional[Workflow] = None,\n):\n    \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n    LLM evaluations are run asynchronously on the scouter server.\n\n    Logic flow:\n        1. If only metrics are provided, a workflow will be created automatically\n           from the metrics. In this case a prompt is required for each metric.\n        2. If a workflow is provided, it will be parsed and validated for compatibility:\n           - A list of metrics to evaluate workflow output must be provided\n           - Metric names must correspond to the final task names in the workflow\n\n    Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n    Args:\n        config (LLMDriftConfig):\n            The configuration for the LLM drift profile containing space, name,\n            version, and alert settings.\n        metrics (list[LLMDriftMetric]):\n            A list of LLMDriftMetric objects representing the metrics to be monitored.\n            Each metric defines evaluation criteria and alert thresholds.\n        workflow (Optional[Workflow]):\n            Optional custom workflow for advanced evaluation scenarios. If provided,\n            the workflow will be validated to ensure proper parameter and response\n            type configuration.\n\n    Returns:\n        LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n    Raises:\n        ProfileError: If workflow validation fails, metrics are empty when no\n            workflow is provided, or if workflow tasks don't match metric names.\n\n    Examples:\n        Basic usage with metrics only:\n\n        &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n        &gt;&gt;&gt; metrics = [\n        ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n        ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n        ... ]\n        &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics)\n\n        Advanced usage with custom workflow:\n\n        &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n        &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n        &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics, workflow)\n\n    Note:\n        - When using custom workflows, ensure final tasks have Score response types\n        - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n        - All metric names must match corresponding workflow task names\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>String representation of LLMDriftProfile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of LLMDriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the json file</p> required <p>Returns:</p> Type Description <code>LLMDriftProfile</code> <p>LLMDriftProfile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"LLMDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the json file\n\n    Returns:\n        LLMDriftProfile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"LLMDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"LLMDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the json file. If not provided, a default path will be used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path: Optional path to save the json file. If not provided, a default path will be used.\n\n    Returns:\n        Path to the saved json file.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, sample_size=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size</p> <code>None</code> <code>alert_config</code> <code>Optional[LLMAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    alert_config: Optional[LLMAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord","title":"<code>LLMMetricRecord</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class LLMMetricRecord:\n    @property\n    def record_uid(self) -&gt; str:\n        \"\"\"Return the record id\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Return the timestamp when the record was created\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space associated with the record\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name associated with the record\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version associated with the record\"\"\"\n\n    @property\n    def metric(self) -&gt; str:\n        \"\"\"Return the name of the metric associated with the record\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the value of the metric associated with the record\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the timestamp when the record was created</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.metric","title":"<code>metric</code>  <code>property</code>","text":"<p>Return the name of the metric associated with the record</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name associated with the record</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.record_uid","title":"<code>record_uid</code>  <code>property</code>","text":"<p>Return the record id</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space associated with the record</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the value of the metric associated with the record</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version associated with the record</p>"},{"location":"docs/api/drift/#scouter.drift._drift.LLMMetricRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.Prompt","title":"<code>Prompt</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Potato Head Prompt Protocol</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class Prompt(Protocol):\n    \"\"\"Potato Head Prompt Protocol\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig","title":"<code>PsiDriftConfig</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class PsiDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        alert_config: PsiAlertConfig = PsiAlertConfig(),\n        config_path: Optional[Path] = None,\n        categorical_features: Optional[list[str]] = None,\n    ):\n        \"\"\"Initialize monitor config\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version. Defaults to 0.1.0\n            alert_config:\n                Alert configuration\n            config_path:\n                Optional path to load config from.\n            categorical_features:\n                List of features to treat as categorical for PSI calculation.\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def feature_map(self) -&gt; Optional[FeatureMap]:\n        \"\"\"Feature map\"\"\"\n\n    @property\n    def alert_config(self) -&gt; PsiAlertConfig:\n        \"\"\"Alert configuration\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: PsiAlertConfig) -&gt; None:\n        \"\"\"Set alert configuration\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @property\n    def categorical_features(self) -&gt; list[str]:\n        \"\"\"list of categorical features\"\"\"\n\n    @categorical_features.setter\n    def categorical_features(self, categorical_features: list[str]) -&gt; None:\n        \"\"\"Set list of categorical features\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"PsiDriftConfig\":\n        \"\"\"Load config from json file\n\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[PsiAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            alert_config:\n                Alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>Alert configuration</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.categorical_features","title":"<code>categorical_features</code>  <code>property</code> <code>writable</code>","text":"<p>list of categorical features</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.feature_map","title":"<code>feature_map</code>  <code>property</code>","text":"<p>Feature map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', alert_config=PsiAlertConfig(), config_path=None, categorical_features=None)</code>","text":"<p>Initialize monitor config</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> <code>'__missing__'</code> <code>name</code> <code>str</code> <p>Model name</p> <code>'__missing__'</code> <code>version</code> <code>str</code> <p>Model version. Defaults to 0.1.0</p> <code>'0.1.0'</code> <code>alert_config</code> <code>PsiAlertConfig</code> <p>Alert configuration</p> <code>PsiAlertConfig()</code> <code>config_path</code> <code>Optional[Path]</code> <p>Optional path to load config from.</p> <code>None</code> <code>categorical_features</code> <code>Optional[list[str]]</code> <p>List of features to treat as categorical for PSI calculation.</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    alert_config: PsiAlertConfig = PsiAlertConfig(),\n    config_path: Optional[Path] = None,\n    categorical_features: Optional[list[str]] = None,\n):\n    \"\"\"Initialize monitor config\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version. Defaults to 0.1.0\n        alert_config:\n            Alert configuration\n        config_path:\n            Optional path to load config from.\n        categorical_features:\n            List of features to treat as categorical for PSI calculation.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to json file to load config from.</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"PsiDriftConfig\":\n    \"\"\"Load config from json file\n\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>alert_config</code> <code>Optional[PsiAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[PsiAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap","title":"<code>PsiDriftMap</code>","text":"<p>Drift map of features</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class PsiDriftMap:\n    \"\"\"Drift map of features\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Space to associate with drift map\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"name to associate with drift map\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Version to associate with drift map\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, float]:\n        \"\"\"Returns dictionary of features and their reported drift, if any\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of data drift\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of data drift\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"PsiDriftMap\":\n        \"\"\"Load drift map from json file.\n\n        Args:\n            json_string:\n                JSON string representation of the drift map\n        \"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift map to json file\n\n        Args:\n            path:\n                Optional path to save the drift map. If None, outputs to `psi_drift_map.json`\n\n        Returns:\n            Path to the saved json file\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.features","title":"<code>features</code>  <code>property</code>","text":"<p>Returns dictionary of features and their reported drift, if any</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.name","title":"<code>name</code>  <code>property</code>","text":"<p>name to associate with drift map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.space","title":"<code>space</code>  <code>property</code>","text":"<p>Space to associate with drift map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.version","title":"<code>version</code>  <code>property</code>","text":"<p>Version to associate with drift map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of data drift</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of data drift</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift map from json file.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift map</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"PsiDriftMap\":\n    \"\"\"Load drift map from json file.\n\n    Args:\n        json_string:\n            JSON string representation of the drift map\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftMap.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift map to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift map. If None, outputs to <code>psi_drift_map.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift map to json file\n\n    Args:\n        path:\n            Optional path to save the drift map. If None, outputs to `psi_drift_map.json`\n\n    Returns:\n        Path to the saved json file\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile","title":"<code>PsiDriftProfile</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class PsiDriftProfile:\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, PsiFeatureDriftProfile]:\n        \"\"\"Return the list of features.\"\"\"\n\n    @property\n    def config(self) -&gt; PsiDriftConfig:\n        \"\"\"Return the monitor config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path:\n                Optional path to save the drift profile. If None, outputs to `psi_drift_profile.json`\n\n        Returns:\n            Path to the saved json file\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"PsiDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"PsiDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the file\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"PsiDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[PsiAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            alert_config:\n                Alert configuration\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the monitor config.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the list of features.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>Sting representation of DriftProfile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the file</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"PsiDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"PsiDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"PsiDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift profile. If None, outputs to <code>psi_drift_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path:\n            Optional path to save the drift profile. If None, outputs to `psi_drift_profile.json`\n\n    Returns:\n        Path to the saved json file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>alert_config</code> <code>Optional[PsiAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[PsiAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiFeatureDriftProfile","title":"<code>PsiFeatureDriftProfile</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class PsiFeatureDriftProfile:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the feature name\"\"\"\n\n    @property\n    def bins(self) -&gt; List[Bin]:\n        \"\"\"Return the bins\"\"\"\n\n    @property\n    def timestamp(self) -&gt; str:\n        \"\"\"Return the timestamp.\"\"\"\n\n    @property\n    def bin_type(self) -&gt; BinType:\n        \"\"\"Return the timestamp.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiFeatureDriftProfile.bin_type","title":"<code>bin_type</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiFeatureDriftProfile.bins","title":"<code>bins</code>  <code>property</code>","text":"<p>Return the bins</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiFeatureDriftProfile.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the feature name</p>"},{"location":"docs/api/drift/#scouter.drift._drift.PsiFeatureDriftProfile.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig","title":"<code>SpcDriftConfig</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class SpcDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        sample_size: int = 25,\n        alert_config: SpcAlertConfig = SpcAlertConfig(),\n        config_path: Optional[Path] = None,\n    ):\n        \"\"\"Initialize monitor config\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version. Defaults to 0.1.0\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n            config_path:\n                Optional path to load config from.\n        \"\"\"\n\n    @property\n    def sample_size(self) -&gt; int:\n        \"\"\"Return the sample size.\"\"\"\n\n    @sample_size.setter\n    def sample_size(self, sample_size: int) -&gt; None:\n        \"\"\"Set the sample size.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def feature_map(self) -&gt; Optional[FeatureMap]:\n        \"\"\"Feature map\"\"\"\n\n    @property\n    def alert_config(self) -&gt; SpcAlertConfig:\n        \"\"\"Alert configuration\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: SpcAlertConfig) -&gt; None:\n        \"\"\"Set alert configuration\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"SpcDriftConfig\":\n        \"\"\"Load config from json file\n\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        sample_size: Optional[int] = None,\n        alert_config: Optional[SpcAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>Alert configuration</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.feature_map","title":"<code>feature_map</code>  <code>property</code>","text":"<p>Feature map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.sample_size","title":"<code>sample_size</code>  <code>property</code> <code>writable</code>","text":"<p>Return the sample size.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', sample_size=25, alert_config=SpcAlertConfig(), config_path=None)</code>","text":"<p>Initialize monitor config</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> <code>'__missing__'</code> <code>name</code> <code>str</code> <p>Model name</p> <code>'__missing__'</code> <code>version</code> <code>str</code> <p>Model version. Defaults to 0.1.0</p> <code>'0.1.0'</code> <code>sample_size</code> <code>int</code> <p>Sample size</p> <code>25</code> <code>alert_config</code> <code>SpcAlertConfig</code> <p>Alert configuration</p> <code>SpcAlertConfig()</code> <code>config_path</code> <code>Optional[Path]</code> <p>Optional path to load config from.</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    sample_size: int = 25,\n    alert_config: SpcAlertConfig = SpcAlertConfig(),\n    config_path: Optional[Path] = None,\n):\n    \"\"\"Initialize monitor config\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version. Defaults to 0.1.0\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n        config_path:\n            Optional path to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to json file to load config from.</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"SpcDriftConfig\":\n    \"\"\"Load config from json file\n\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, sample_size=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size</p> <code>None</code> <code>alert_config</code> <code>Optional[SpcAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    alert_config: Optional[SpcAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap","title":"<code>SpcDriftMap</code>","text":"<p>Drift map of features</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class SpcDriftMap:\n    \"\"\"Drift map of features\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Space to associate with drift map\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"name to associate with drift map\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Version to associate with drift map\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, SpcFeatureDrift]:\n        \"\"\"Returns dictionary of features and their data profiles\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of data drift\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of data drift\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"SpcDriftMap\":\n        \"\"\"Load drift map from json file.\n\n        Args:\n            json_string:\n                JSON string representation of the drift map\n        \"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift map to json file\n\n        Args:\n            path:\n                Optional path to save the drift map. If None, outputs to `spc_drift_map.json`\n\n        Returns:\n            Path to the saved json file\n\n        \"\"\"\n\n    def to_numpy(self) -&gt; Any:\n        \"\"\"Return drift map as a tuple of sample_array, drift_array and list of features\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.features","title":"<code>features</code>  <code>property</code>","text":"<p>Returns dictionary of features and their data profiles</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.name","title":"<code>name</code>  <code>property</code>","text":"<p>name to associate with drift map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.space","title":"<code>space</code>  <code>property</code>","text":"<p>Space to associate with drift map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.version","title":"<code>version</code>  <code>property</code>","text":"<p>Version to associate with drift map</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of data drift</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of data drift</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift map from json file.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift map</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"SpcDriftMap\":\n    \"\"\"Load drift map from json file.\n\n    Args:\n        json_string:\n            JSON string representation of the drift map\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift map to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift map. If None, outputs to <code>spc_drift_map.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift map to json file\n\n    Args:\n        path:\n            Optional path to save the drift map. If None, outputs to `spc_drift_map.json`\n\n    Returns:\n        Path to the saved json file\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftMap.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Return drift map as a tuple of sample_array, drift_array and list of features</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def to_numpy(self) -&gt; Any:\n    \"\"\"Return drift map as a tuple of sample_array, drift_array and list of features\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile","title":"<code>SpcDriftProfile</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class SpcDriftProfile:\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, SpcFeatureDriftProfile]:\n        \"\"\"Return the list of features.\"\"\"\n\n    @property\n    def config(self) -&gt; SpcDriftConfig:\n        \"\"\"Return the monitor config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path:\n                Optional path to save the drift profile. If None, outputs to `spc_drift_profile.json`\n\n\n        Returns:\n            Path to the saved json file\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"SpcDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"SpcDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the file\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"SpcDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        sample_size: Optional[int] = None,\n        alert_config: Optional[SpcAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the monitor config.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the list of features.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>Sting representation of DriftProfile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the file</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"SpcDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"SpcDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"SpcDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift profile. If None, outputs to <code>spc_drift_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path:\n            Optional path to save the drift profile. If None, outputs to `spc_drift_profile.json`\n\n\n    Returns:\n        Path to the saved json file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, sample_size=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size</p> <code>None</code> <code>alert_config</code> <code>Optional[SpcAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    alert_config: Optional[SpcAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDrift","title":"<code>SpcFeatureDrift</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class SpcFeatureDrift:\n    @property\n    def samples(self) -&gt; List[float]:\n        \"\"\"Return list of samples\"\"\"\n\n    @property\n    def drift(self) -&gt; List[float]:\n        \"\"\"Return list of drift values\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDrift.drift","title":"<code>drift</code>  <code>property</code>","text":"<p>Return list of drift values</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDrift.samples","title":"<code>samples</code>  <code>property</code>","text":"<p>Return list of samples</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile","title":"<code>SpcFeatureDriftProfile</code>","text":"Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class SpcFeatureDriftProfile:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the id.\"\"\"\n\n    @property\n    def center(self) -&gt; float:\n        \"\"\"Return the center.\"\"\"\n\n    @property\n    def one_ucl(self) -&gt; float:\n        \"\"\"Return the zone 1 ucl.\"\"\"\n\n    @property\n    def one_lcl(self) -&gt; float:\n        \"\"\"Return the zone 1 lcl.\"\"\"\n\n    @property\n    def two_ucl(self) -&gt; float:\n        \"\"\"Return the zone 2 ucl.\"\"\"\n\n    @property\n    def two_lcl(self) -&gt; float:\n        \"\"\"Return the zone 2 lcl.\"\"\"\n\n    @property\n    def three_ucl(self) -&gt; float:\n        \"\"\"Return the zone 3 ucl.\"\"\"\n\n    @property\n    def three_lcl(self) -&gt; float:\n        \"\"\"Return the zone 3 lcl.\"\"\"\n\n    @property\n    def timestamp(self) -&gt; str:\n        \"\"\"Return the timestamp.\"\"\"\n</code></pre>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.center","title":"<code>center</code>  <code>property</code>","text":"<p>Return the center.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the id.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.one_lcl","title":"<code>one_lcl</code>  <code>property</code>","text":"<p>Return the zone 1 lcl.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.one_ucl","title":"<code>one_ucl</code>  <code>property</code>","text":"<p>Return the zone 1 ucl.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.three_lcl","title":"<code>three_lcl</code>  <code>property</code>","text":"<p>Return the zone 3 lcl.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.three_ucl","title":"<code>three_ucl</code>  <code>property</code>","text":"<p>Return the zone 3 ucl.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.two_lcl","title":"<code>two_lcl</code>  <code>property</code>","text":"<p>Return the zone 2 lcl.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.SpcFeatureDriftProfile.two_ucl","title":"<code>two_ucl</code>  <code>property</code>","text":"<p>Return the zone 2 ucl.</p>"},{"location":"docs/api/drift/#scouter.drift._drift.Workflow","title":"<code>Workflow</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Potato Head Workflow Protocol</p> Source code in <code>python/scouter/drift/_drift.pyi</code> <pre><code>class Workflow(Protocol):\n    \"\"\"Potato Head Workflow Protocol\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/","title":"Evaluate","text":""},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for pydantic BaseModel to ensure compatibility with context</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>class BaseModel(Protocol):\n    \"\"\"Protocol for pydantic BaseModel to ensure compatibility with context\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Dump the model as a dictionary\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model as a JSON string\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the model\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.BaseModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the model</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the model\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.BaseModel.model_dump","title":"<code>model_dump()</code>","text":"<p>Dump the model as a dictionary</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Dump the model as a dictionary\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.BaseModel.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model as a JSON string</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model as a JSON string\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.EvaluationConfig","title":"<code>EvaluationConfig</code>","text":"<p>Configuration options for LLM evaluation.</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>class EvaluationConfig:\n    \"\"\"Configuration options for LLM evaluation.\"\"\"\n\n    def __init__(\n        self,\n        embedder: Optional[Embedder] = None,\n        embedding_targets: Optional[List[str]] = None,\n        compute_similarity: bool = False,\n        cluster: bool = False,\n        compute_histograms: bool = False,\n    ):\n        \"\"\"\n        Initialize the EvaluationConfig with optional parameters.\n\n        Args:\n            embedder (Optional[Embedder]):\n                Optional Embedder instance to use for generating embeddings for similarity-based metrics.\n                If not provided, no embeddings will be generated.\n            embedding_targets (Optional[List[str]]):\n                Optional list of context keys to generate embeddings for. If not provided, embeddings will\n                be generated for all string fields in the record context.\n            compute_similarity (bool):\n                Whether to compute similarity between embeddings. Default is False.\n            cluster (bool):\n                Whether to perform clustering on the embeddings. Default is False.\n            compute_histograms (bool):\n                Whether to compute histograms for all calculated features (metrics, embeddings, similarities).\n                Default is False.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.EvaluationConfig.__init__","title":"<code>__init__(embedder=None, embedding_targets=None, compute_similarity=False, cluster=False, compute_histograms=False)</code>","text":"<p>Initialize the EvaluationConfig with optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>embedder</code> <code>Optional[Embedder]</code> <p>Optional Embedder instance to use for generating embeddings for similarity-based metrics. If not provided, no embeddings will be generated.</p> <code>None</code> <code>embedding_targets</code> <code>Optional[List[str]]</code> <p>Optional list of context keys to generate embeddings for. If not provided, embeddings will be generated for all string fields in the record context.</p> <code>None</code> <code>compute_similarity</code> <code>bool</code> <p>Whether to compute similarity between embeddings. Default is False.</p> <code>False</code> <code>cluster</code> <code>bool</code> <p>Whether to perform clustering on the embeddings. Default is False.</p> <code>False</code> <code>compute_histograms</code> <code>bool</code> <p>Whether to compute histograms for all calculated features (metrics, embeddings, similarities). Default is False.</p> <code>False</code> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def __init__(\n    self,\n    embedder: Optional[Embedder] = None,\n    embedding_targets: Optional[List[str]] = None,\n    compute_similarity: bool = False,\n    cluster: bool = False,\n    compute_histograms: bool = False,\n):\n    \"\"\"\n    Initialize the EvaluationConfig with optional parameters.\n\n    Args:\n        embedder (Optional[Embedder]):\n            Optional Embedder instance to use for generating embeddings for similarity-based metrics.\n            If not provided, no embeddings will be generated.\n        embedding_targets (Optional[List[str]]):\n            Optional list of context keys to generate embeddings for. If not provided, embeddings will\n            be generated for all string fields in the record context.\n        compute_similarity (bool):\n            Whether to compute similarity between embeddings. Default is False.\n        cluster (bool):\n            Whether to perform clustering on the embeddings. Default is False.\n        compute_histograms (bool):\n            Whether to compute histograms for all calculated features (metrics, embeddings, similarities).\n            Default is False.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalMetric","title":"<code>LLMEvalMetric</code>","text":"<p>Defines an LLM eval metric to use when evaluating LLMs</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalMetric:\n    \"\"\"Defines an LLM eval metric to use when evaluating LLMs\"\"\"\n\n    def __init__(self, name: str, prompt: Prompt):\n        \"\"\"\n        Initialize an LLMEvalMetric to use for evaluating LLMs. This is\n        most commonly used in conjunction with `evaluate_llm` where LLM inputs\n        and responses can be evaluated against a variety of user-defined metrics.\n\n        Args:\n            name (str):\n                Name of the metric\n            prompt (Prompt):\n                Prompt to use for the metric. For example, a user may create\n                an accuracy analysis prompt or a query reformulation analysis prompt.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        String representation of the LLMEvalMetric\n        \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalMetric.__init__","title":"<code>__init__(name, prompt)</code>","text":"<p>Initialize an LLMEvalMetric to use for evaluating LLMs. This is most commonly used in conjunction with <code>evaluate_llm</code> where LLM inputs and responses can be evaluated against a variety of user-defined metrics.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the metric</p> required <code>prompt</code> <code>Prompt</code> <p>Prompt to use for the metric. For example, a user may create an accuracy analysis prompt or a query reformulation analysis prompt.</p> required Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def __init__(self, name: str, prompt: Prompt):\n    \"\"\"\n    Initialize an LLMEvalMetric to use for evaluating LLMs. This is\n    most commonly used in conjunction with `evaluate_llm` where LLM inputs\n    and responses can be evaluated against a variety of user-defined metrics.\n\n    Args:\n        name (str):\n            Name of the metric\n        prompt (Prompt):\n            Prompt to use for the metric. For example, a user may create\n            an accuracy analysis prompt or a query reformulation analysis prompt.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalMetric.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the LLMEvalMetric</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    String representation of the LLMEvalMetric\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalRecord","title":"<code>LLMEvalRecord</code>","text":"<p>LLM record containing context tied to a Large Language Model interaction that is used to evaluate LLM responses.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; record = LLMEvalRecord(\n        id=\"123\",\n        context={\n            \"input\": \"What is the capital of France?\",\n            \"response\": \"Paris is the capital of France.\"\n        },\n... )\n&gt;&gt;&gt; print(record.context[\"input\"])\n\"What is the capital of France?\"\n</code></pre> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalRecord:\n    \"\"\"LLM record containing context tied to a Large Language Model interaction\n    that is used to evaluate LLM responses.\n\n\n    Examples:\n        &gt;&gt;&gt; record = LLMEvalRecord(\n                id=\"123\",\n                context={\n                    \"input\": \"What is the capital of France?\",\n                    \"response\": \"Paris is the capital of France.\"\n                },\n        ... )\n        &gt;&gt;&gt; print(record.context[\"input\"])\n        \"What is the capital of France?\"\n    \"\"\"\n\n    def __init__(\n        self,\n        context: Context,\n        id: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n        The record is sent to the `Scouter` server via the `ScouterQueue` and is\n        then used to inject context into the evaluation prompts.\n\n        Args:\n            context:\n                Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n                this will be merged with the input and response data and passed to the assigned\n                evaluation prompts. So if you're evaluation prompts expect additional context via\n                bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n                {\"foo\": \"bar\"}\n            id:\n                Unique identifier for the record. If not provided, a new UUID will be generated.\n                This is helpful for when joining evaluation results back to the original request.\n\n        Raises:\n            TypeError: If context is not a dict or a pydantic BaseModel.\n\n        \"\"\"\n\n    @property\n    def context(self) -&gt; Dict[str, Any]:\n        \"\"\"Get the contextual information.\n\n        Returns:\n            The context data as a Python object (deserialized from JSON).\n        \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalRecord.context","title":"<code>context</code>  <code>property</code>","text":"<p>Get the contextual information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The context data as a Python object (deserialized from JSON).</p>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalRecord.__init__","title":"<code>__init__(context, id=None)</code>","text":"<p>Creates a new LLM record to associate with an <code>LLMDriftProfile</code>. The record is sent to the <code>Scouter</code> server via the <code>ScouterQueue</code> and is then used to inject context into the evaluation prompts.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>Additional context information as a dictionary or a pydantic BaseModel. During evaluation, this will be merged with the input and response data and passed to the assigned evaluation prompts. So if you're evaluation prompts expect additional context via bound variables (e.g., <code>${foo}</code>), you can pass that here as key value pairs.</p> required <code>id</code> <code>Optional[str]</code> <p>Unique identifier for the record. If not provided, a new UUID will be generated. This is helpful for when joining evaluation results back to the original request.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If context is not a dict or a pydantic BaseModel.</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def __init__(\n    self,\n    context: Context,\n    id: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n    The record is sent to the `Scouter` server via the `ScouterQueue` and is\n    then used to inject context into the evaluation prompts.\n\n    Args:\n        context:\n            Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n            this will be merged with the input and response data and passed to the assigned\n            evaluation prompts. So if you're evaluation prompts expect additional context via\n            bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n            {\"foo\": \"bar\"}\n        id:\n            Unique identifier for the record. If not provided, a new UUID will be generated.\n            This is helpful for when joining evaluation results back to the original request.\n\n    Raises:\n        TypeError: If context is not a dict or a pydantic BaseModel.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults","title":"<code>LLMEvalResults</code>","text":"<p>Defines the results of an LLM eval metric</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalResults:\n    \"\"\"Defines the results of an LLM eval metric\"\"\"\n\n    def __getitem__(self, key: str) -&gt; LLMEvalTaskResult:\n        \"\"\"Get the task results for a specific record ID. A RuntimeError will be raised if the record ID does not exist.\"\"\"\n\n    def __str__(self):\n        \"\"\"String representation of the LLMEvalResults\"\"\"\n\n    def to_dataframe(self, polars: bool = False) -&gt; Any:\n        \"\"\"\n        Convert the results to a Pandas or Polars DataFrame.\n\n        Args:\n            polars (bool):\n                Whether to return a Polars DataFrame. If False, a Pandas DataFrame will be returned.\n\n        Returns:\n            DataFrame:\n                A Pandas or Polars DataFrame containing the results.\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the results as a JSON string\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"LLMEvalResults\":\n        \"\"\"Validate and create an LLMEvalResults instance from a JSON string\n\n        Args:\n            json_string (str):\n                JSON string to validate and create the LLMEvalResults instance from.\n        \"\"\"\n\n    @property\n    def errored_tasks(self) -&gt; List[str]:\n        \"\"\"Get a list of record IDs that had errors during evaluation\"\"\"\n\n    @property\n    def histograms(self) -&gt; Optional[Dict[str, Histogram]]:\n        \"\"\"Get histograms for all calculated features (metrics, embeddings, similarities)\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults.errored_tasks","title":"<code>errored_tasks</code>  <code>property</code>","text":"<p>Get a list of record IDs that had errors during evaluation</p>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults.histograms","title":"<code>histograms</code>  <code>property</code>","text":"<p>Get histograms for all calculated features (metrics, embeddings, similarities)</p>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the task results for a specific record ID. A RuntimeError will be raised if the record ID does not exist.</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; LLMEvalTaskResult:\n    \"\"\"Get the task results for a specific record ID. A RuntimeError will be raised if the record ID does not exist.\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the LLMEvalResults</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def __str__(self):\n    \"\"\"String representation of the LLMEvalResults\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the results as a JSON string</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the results as a JSON string\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate and create an LLMEvalResults instance from a JSON string</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string to validate and create the LLMEvalResults instance from.</p> required Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"LLMEvalResults\":\n    \"\"\"Validate and create an LLMEvalResults instance from a JSON string\n\n    Args:\n        json_string (str):\n            JSON string to validate and create the LLMEvalResults instance from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalResults.to_dataframe","title":"<code>to_dataframe(polars=False)</code>","text":"<p>Convert the results to a Pandas or Polars DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>polars</code> <code>bool</code> <p>Whether to return a Polars DataFrame. If False, a Pandas DataFrame will be returned.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>Any</code> <p>A Pandas or Polars DataFrame containing the results.</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def to_dataframe(self, polars: bool = False) -&gt; Any:\n    \"\"\"\n    Convert the results to a Pandas or Polars DataFrame.\n\n    Args:\n        polars (bool):\n            Whether to return a Polars DataFrame. If False, a Pandas DataFrame will be returned.\n\n    Returns:\n        DataFrame:\n            A Pandas or Polars DataFrame containing the results.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalTaskResult","title":"<code>LLMEvalTaskResult</code>","text":"<p>Eval Result for a specific evaluation</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalTaskResult:\n    \"\"\"Eval Result for a specific evaluation\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Get the record id associated with this result\"\"\"\n\n    @property\n    def metrics(self) -&gt; Dict[str, Score]:\n        \"\"\"Get the list of metrics\"\"\"\n\n    @property\n    def embedding(self) -&gt; Dict[str, List[float]]:\n        \"\"\"Get embeddings of embedding targets\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalTaskResult.embedding","title":"<code>embedding</code>  <code>property</code>","text":"<p>Get embeddings of embedding targets</p>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalTaskResult.id","title":"<code>id</code>  <code>property</code>","text":"<p>Get the record id associated with this result</p>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.LLMEvalTaskResult.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Get the list of metrics</p>"},{"location":"docs/api/evaluate/#scouter.evaluate._evaluate.evaluate_llm","title":"<code>evaluate_llm(records, metrics, config=None)</code>","text":"<p>Evaluate LLM responses using the provided evaluation metrics.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[LLMEvalRecord]</code> <p>List of LLM evaluation records to evaluate.</p> required <code>metrics</code> <code>List[LLMEvalMetric]</code> <p>List of LLMEvalMetric instances to use for evaluation.</p> required <code>config</code> <code>Optional[EvaluationConfig]</code> <p>Optional EvaluationConfig instance to configure evaluation options.</p> <code>None</code> <p>Returns:</p> Type Description <code>LLMEvalResults</code> <p>LLMEvalResults</p> Source code in <code>python/scouter/evaluate/_evaluate.pyi</code> <pre><code>def evaluate_llm(\n    records: List[LLMEvalRecord],\n    metrics: List[LLMEvalMetric],\n    config: Optional[EvaluationConfig] = None,\n) -&gt; LLMEvalResults:\n    \"\"\"\n    Evaluate LLM responses using the provided evaluation metrics.\n\n    Args:\n        records (List[LLMEvalRecord]):\n            List of LLM evaluation records to evaluate.\n        metrics (List[LLMEvalMetric]):\n            List of LLMEvalMetric instances to use for evaluation.\n        config (Optional[EvaluationConfig]):\n            Optional EvaluationConfig instance to configure evaluation options.\n\n    Returns:\n        LLMEvalResults\n    \"\"\"\n</code></pre>"},{"location":"docs/api/profile/","title":"Profile","text":""},{"location":"docs/api/profile/#scouter.profile._profile.CharStats","title":"<code>CharStats</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class CharStats:\n    @property\n    def min_length(self) -&gt; int:\n        \"\"\"Minimum string length\"\"\"\n\n    @property\n    def max_length(self) -&gt; int:\n        \"\"\"Maximum string length\"\"\"\n\n    @property\n    def median_length(self) -&gt; int:\n        \"\"\"Median string length\"\"\"\n\n    @property\n    def mean_length(self) -&gt; float:\n        \"\"\"Mean string length\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.CharStats.max_length","title":"<code>max_length</code>  <code>property</code>","text":"<p>Maximum string length</p>"},{"location":"docs/api/profile/#scouter.profile._profile.CharStats.mean_length","title":"<code>mean_length</code>  <code>property</code>","text":"<p>Mean string length</p>"},{"location":"docs/api/profile/#scouter.profile._profile.CharStats.median_length","title":"<code>median_length</code>  <code>property</code>","text":"<p>Median string length</p>"},{"location":"docs/api/profile/#scouter.profile._profile.CharStats.min_length","title":"<code>min_length</code>  <code>property</code>","text":"<p>Minimum string length</p>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfile","title":"<code>DataProfile</code>","text":"<p>Data profile of features</p> Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class DataProfile:\n    \"\"\"Data profile of features\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, FeatureProfile]:\n        \"\"\"Returns dictionary of features and their data profiles\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the data profile\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of data profile\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"DataProfile\":\n        \"\"\"Load Data profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the data profile\n        \"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save data profile to json file\n\n        Args:\n            path:\n                Optional path to save the data profile. If None, outputs to `data_profile.json`\n\n        Returns:\n            Path to the saved data profile\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfile.features","title":"<code>features</code>  <code>property</code>","text":"<p>Returns dictionary of features and their data profiles</p>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfile.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of the data profile</p> Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the data profile\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of data profile</p> Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of data profile\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load Data profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the data profile</p> required Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"DataProfile\":\n    \"\"\"Load Data profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save data profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the data profile. If None, outputs to <code>data_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved data profile</p> Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save data profile to json file\n\n    Args:\n        path:\n            Optional path to save the data profile. If None, outputs to `data_profile.json`\n\n    Returns:\n        Path to the saved data profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfiler","title":"<code>DataProfiler</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class DataProfiler:\n    def __init__(self):\n        \"\"\"Instantiate DataProfiler class that is\n        used to profile data\"\"\"\n\n    def create_data_profile(\n        self,\n        data: Any,\n        data_type: Optional[DataType] = None,\n        bin_size: int = 20,\n        compute_correlations: bool = False,\n    ) -&gt; DataProfile:\n        \"\"\"Create a data profile from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n                These types are incompatible with computing\n                quantiles, histograms, and correlations. These values must be removed or imputed.\n\n            data_type:\n                Optional data type. Inferred from data if not provided.\n            bin_size:\n                Optional bin size for histograms. Defaults to 20 bins.\n            compute_correlations:\n                Whether to compute correlations or not.\n\n        Returns:\n            DataProfile\n        \"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfiler.__init__","title":"<code>__init__()</code>","text":"<p>Instantiate DataProfiler class that is used to profile data</p> Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>def __init__(self):\n    \"\"\"Instantiate DataProfiler class that is\n    used to profile data\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.DataProfiler.create_data_profile","title":"<code>create_data_profile(data, data_type=None, bin_size=20, compute_correlations=False)</code>","text":"<p>Create a data profile from data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to create a data profile from. Data can be a numpy array, a polars dataframe or pandas dataframe.</p> <p>Data is expected to not contain any missing values, NaNs or infinities</p> <p>These types are incompatible with computing quantiles, histograms, and correlations. These values must be removed or imputed.</p> required <code>data_type</code> <code>Optional[DataType]</code> <p>Optional data type. Inferred from data if not provided.</p> <code>None</code> <code>bin_size</code> <code>int</code> <p>Optional bin size for histograms. Defaults to 20 bins.</p> <code>20</code> <code>compute_correlations</code> <code>bool</code> <p>Whether to compute correlations or not.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataProfile</code> <p>DataProfile</p> Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>def create_data_profile(\n    self,\n    data: Any,\n    data_type: Optional[DataType] = None,\n    bin_size: int = 20,\n    compute_correlations: bool = False,\n) -&gt; DataProfile:\n    \"\"\"Create a data profile from data.\n\n    Args:\n        data:\n            Data to create a data profile from. Data can be a numpy array,\n            a polars dataframe or pandas dataframe.\n\n            **Data is expected to not contain any missing values, NaNs or infinities**\n\n            These types are incompatible with computing\n            quantiles, histograms, and correlations. These values must be removed or imputed.\n\n        data_type:\n            Optional data type. Inferred from data if not provided.\n        bin_size:\n            Optional bin size for histograms. Defaults to 20 bins.\n        compute_correlations:\n            Whether to compute correlations or not.\n\n    Returns:\n        DataProfile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.Distinct","title":"<code>Distinct</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class Distinct:\n    @property\n    def count(self) -&gt; int:\n        \"\"\"total unique value counts\"\"\"\n\n    @property\n    def percent(self) -&gt; float:\n        \"\"\"percent value uniqueness\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.Distinct.count","title":"<code>count</code>  <code>property</code>","text":"<p>total unique value counts</p>"},{"location":"docs/api/profile/#scouter.profile._profile.Distinct.percent","title":"<code>percent</code>  <code>property</code>","text":"<p>percent value uniqueness</p>"},{"location":"docs/api/profile/#scouter.profile._profile.FeatureProfile","title":"<code>FeatureProfile</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class FeatureProfile:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the id.\"\"\"\n\n    @property\n    def numeric_stats(self) -&gt; Optional[NumericStats]:\n        \"\"\"Return the numeric stats.\"\"\"\n\n    @property\n    def string_stats(self) -&gt; Optional[StringStats]:\n        \"\"\"Return the string stats.\"\"\"\n\n    @property\n    def timestamp(self) -&gt; str:\n        \"\"\"Return the timestamp.\"\"\"\n\n    @property\n    def correlations(self) -&gt; Optional[Dict[str, float]]:\n        \"\"\"Feature correlation values\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the feature profile.\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.FeatureProfile.correlations","title":"<code>correlations</code>  <code>property</code>","text":"<p>Feature correlation values</p>"},{"location":"docs/api/profile/#scouter.profile._profile.FeatureProfile.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the id.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.FeatureProfile.numeric_stats","title":"<code>numeric_stats</code>  <code>property</code>","text":"<p>Return the numeric stats.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.FeatureProfile.string_stats","title":"<code>string_stats</code>  <code>property</code>","text":"<p>Return the string stats.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.FeatureProfile.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.FeatureProfile.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the feature profile.</p> Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the feature profile.\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.Histogram","title":"<code>Histogram</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class Histogram:\n    @property\n    def bins(self) -&gt; List[float]:\n        \"\"\"Bin values\"\"\"\n\n    @property\n    def bin_counts(self) -&gt; List[int]:\n        \"\"\"Bin counts\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.Histogram.bin_counts","title":"<code>bin_counts</code>  <code>property</code>","text":"<p>Bin counts</p>"},{"location":"docs/api/profile/#scouter.profile._profile.Histogram.bins","title":"<code>bins</code>  <code>property</code>","text":"<p>Bin values</p>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats","title":"<code>NumericStats</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class NumericStats:\n    @property\n    def mean(self) -&gt; float:\n        \"\"\"Return the mean.\"\"\"\n\n    @property\n    def stddev(self) -&gt; float:\n        \"\"\"Return the stddev.\"\"\"\n\n    @property\n    def min(self) -&gt; float:\n        \"\"\"Return the min.\"\"\"\n\n    @property\n    def max(self) -&gt; float:\n        \"\"\"Return the max.\"\"\"\n\n    @property\n    def distinct(self) -&gt; Distinct:\n        \"\"\"Distinct value counts\"\"\"\n\n    @property\n    def quantiles(self) -&gt; Quantiles:\n        \"\"\"Value quantiles\"\"\"\n\n    @property\n    def histogram(self) -&gt; Histogram:\n        \"\"\"Value histograms\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats.distinct","title":"<code>distinct</code>  <code>property</code>","text":"<p>Distinct value counts</p>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats.histogram","title":"<code>histogram</code>  <code>property</code>","text":"<p>Value histograms</p>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats.max","title":"<code>max</code>  <code>property</code>","text":"<p>Return the max.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats.mean","title":"<code>mean</code>  <code>property</code>","text":"<p>Return the mean.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats.min","title":"<code>min</code>  <code>property</code>","text":"<p>Return the min.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats.quantiles","title":"<code>quantiles</code>  <code>property</code>","text":"<p>Value quantiles</p>"},{"location":"docs/api/profile/#scouter.profile._profile.NumericStats.stddev","title":"<code>stddev</code>  <code>property</code>","text":"<p>Return the stddev.</p>"},{"location":"docs/api/profile/#scouter.profile._profile.Quantiles","title":"<code>Quantiles</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class Quantiles:\n    @property\n    def q25(self) -&gt; float:\n        \"\"\"25th quantile\"\"\"\n\n    @property\n    def q50(self) -&gt; float:\n        \"\"\"50th quantile\"\"\"\n\n    @property\n    def q75(self) -&gt; float:\n        \"\"\"75th quantile\"\"\"\n\n    @property\n    def q99(self) -&gt; float:\n        \"\"\"99th quantile\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.Quantiles.q25","title":"<code>q25</code>  <code>property</code>","text":"<p>25th quantile</p>"},{"location":"docs/api/profile/#scouter.profile._profile.Quantiles.q50","title":"<code>q50</code>  <code>property</code>","text":"<p>50th quantile</p>"},{"location":"docs/api/profile/#scouter.profile._profile.Quantiles.q75","title":"<code>q75</code>  <code>property</code>","text":"<p>75th quantile</p>"},{"location":"docs/api/profile/#scouter.profile._profile.Quantiles.q99","title":"<code>q99</code>  <code>property</code>","text":"<p>99th quantile</p>"},{"location":"docs/api/profile/#scouter.profile._profile.StringStats","title":"<code>StringStats</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class StringStats:\n    @property\n    def distinct(self) -&gt; Distinct:\n        \"\"\"Distinct value counts\"\"\"\n\n    @property\n    def char_stats(self) -&gt; CharStats:\n        \"\"\"Character statistics\"\"\"\n\n    @property\n    def word_stats(self) -&gt; WordStats:\n        \"\"\"word statistics\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.StringStats.char_stats","title":"<code>char_stats</code>  <code>property</code>","text":"<p>Character statistics</p>"},{"location":"docs/api/profile/#scouter.profile._profile.StringStats.distinct","title":"<code>distinct</code>  <code>property</code>","text":"<p>Distinct value counts</p>"},{"location":"docs/api/profile/#scouter.profile._profile.StringStats.word_stats","title":"<code>word_stats</code>  <code>property</code>","text":"<p>word statistics</p>"},{"location":"docs/api/profile/#scouter.profile._profile.WordStats","title":"<code>WordStats</code>","text":"Source code in <code>python/scouter/profile/_profile.pyi</code> <pre><code>class WordStats:\n    @property\n    def words(self) -&gt; Dict[str, Distinct]:\n        \"\"\"Distinct word counts\"\"\"\n</code></pre>"},{"location":"docs/api/profile/#scouter.profile._profile.WordStats.words","title":"<code>words</code>  <code>property</code>","text":"<p>Distinct word counts</p>"},{"location":"docs/api/queue/","title":"Queue","text":""},{"location":"docs/api/queue/#scouter.queue._queue.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for pydantic BaseModel to ensure compatibility with context</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class BaseModel(Protocol):\n    \"\"\"Protocol for pydantic BaseModel to ensure compatibility with context\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Dump the model as a dictionary\"\"\"\n        ...\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model as a JSON string\"\"\"\n        ...\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the model\"\"\"\n        ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.BaseModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the model</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the model\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.BaseModel.model_dump","title":"<code>model_dump()</code>","text":"<p>Dump the model as a dictionary</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Dump the model as a dictionary\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.BaseModel.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model as a JSON string</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model as a JSON string\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord","title":"<code>CustomMetricServerRecord</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class CustomMetricServerRecord:\n    def __init__(\n        self,\n        space: str,\n        name: str,\n        version: str,\n        metric: str,\n        value: float,\n    ):\n        \"\"\"Initialize spc drift server record\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            metric:\n                Metric name\n            value:\n                Metric value\n        \"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime.datetime:\n        \"\"\"Return the created at timestamp.\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name.\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version.\"\"\"\n\n    @property\n    def metric(self) -&gt; str:\n        \"\"\"Return the metric name.\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the metric value.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def to_dict(self) -&gt; Dict[str, str]:\n        \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the created at timestamp.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.metric","title":"<code>metric</code>  <code>property</code>","text":"<p>Return the metric name.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the metric value.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.__init__","title":"<code>__init__(space, name, version, metric, value)</code>","text":"<p>Initialize spc drift server record</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> required <code>name</code> <code>str</code> <p>Model name</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>metric</code> <code>str</code> <p>Metric name</p> required <code>value</code> <code>float</code> <p>Metric value</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    space: str,\n    name: str,\n    version: str,\n    metric: str,\n    value: float,\n):\n    \"\"\"Initialize spc drift server record\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        metric:\n            Metric name\n        value:\n            Metric value\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.CustomMetricServerRecord.to_dict","title":"<code>to_dict()</code>","text":"<p>Return the dictionary representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def to_dict(self) -&gt; Dict[str, str]:\n    \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Feature","title":"<code>Feature</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class Feature:\n    def __init__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Initialize feature. Will attempt to convert the value to it's corresponding feature type.\n        Current support types are int, float, string.\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature. Can be an int, float, or string.\n\n        Example:\n            ```python\n            feature = Feature(\"feature_1\", 1) # int feature\n            feature = Feature(\"feature_2\", 2.0) # float feature\n            feature = Feature(\"feature_3\", \"value\") # string feature\n            ```\n        \"\"\"\n\n    @staticmethod\n    def int(name: str, value: int) -&gt; \"Feature\":\n        \"\"\"Create an integer feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n\n    @staticmethod\n    def float(name: str, value: float) -&gt; \"Feature\":\n        \"\"\"Create a float feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n\n    @staticmethod\n    def string(name: str, value: str) -&gt; \"Feature\":\n        \"\"\"Create a string feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n\n    @staticmethod\n    def categorical(name: str, value: str) -&gt; \"Feature\":\n        \"\"\"Create a categorical feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Feature.__init__","title":"<code>__init__(name, value)</code>","text":"<p>Initialize feature. Will attempt to convert the value to it's corresponding feature type. Current support types are int, float, string.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>Any</code> <p>Value of the feature. Can be an int, float, or string.</p> required Example <pre><code>feature = Feature(\"feature_1\", 1) # int feature\nfeature = Feature(\"feature_2\", 2.0) # float feature\nfeature = Feature(\"feature_3\", \"value\") # string feature\n</code></pre> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Initialize feature. Will attempt to convert the value to it's corresponding feature type.\n    Current support types are int, float, string.\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature. Can be an int, float, or string.\n\n    Example:\n        ```python\n        feature = Feature(\"feature_1\", 1) # int feature\n        feature = Feature(\"feature_2\", 2.0) # float feature\n        feature = Feature(\"feature_3\", \"value\") # string feature\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Feature.categorical","title":"<code>categorical(name, value)</code>  <code>staticmethod</code>","text":"<p>Create a categorical feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>str</code> <p>Value of the feature</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef categorical(name: str, value: str) -&gt; \"Feature\":\n    \"\"\"Create a categorical feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Feature.float","title":"<code>float(name, value)</code>  <code>staticmethod</code>","text":"<p>Create a float feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>float</code> <p>Value of the feature</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef float(name: str, value: float) -&gt; \"Feature\":\n    \"\"\"Create a float feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Feature.int","title":"<code>int(name, value)</code>  <code>staticmethod</code>","text":"<p>Create an integer feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>int</code> <p>Value of the feature</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef int(name: str, value: int) -&gt; \"Feature\":\n    \"\"\"Create an integer feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Feature.string","title":"<code>string(name, value)</code>  <code>staticmethod</code>","text":"<p>Create a string feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>str</code> <p>Value of the feature</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef string(name: str, value: str) -&gt; \"Feature\":\n    \"\"\"Create a string feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Features","title":"<code>Features</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class Features:\n    def __init__(\n        self,\n        features: List[Feature] | Dict[str, Union[int, float, str]],\n    ) -&gt; None:\n        \"\"\"Initialize a features class\n\n        Args:\n            features:\n                List of features or a dictionary of key-value pairs.\n                If a list, each item must be an instance of Feature.\n                If a dictionary, each key is the feature name and each value is the feature value.\n                Supported types for values are int, float, and string.\n\n        Example:\n            ```python\n            # Passing a list of features\n            features = Features(\n                features=[\n                    Feature.int(\"feature_1\", 1),\n                    Feature.float(\"feature_2\", 2.0),\n                    Feature.string(\"feature_3\", \"value\"),\n                ]\n            )\n\n            # Passing a dictionary (pydantic model) of features\n            class MyFeatures(BaseModel):\n                feature1: int\n                feature2: float\n                feature3: str\n\n            my_features = MyFeatures(\n                feature1=1,\n                feature2=2.0,\n                feature3=\"value\",\n            )\n\n            features = Features(my_features.model_dump())\n            ```\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the features\"\"\"\n\n    @property\n    def features(self) -&gt; List[Feature]:\n        \"\"\"Return the list of features\"\"\"\n\n    @property\n    def entity_type(self) -&gt; EntityType:\n        \"\"\"Return the entity type\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Features.entity_type","title":"<code>entity_type</code>  <code>property</code>","text":"<p>Return the entity type</p>"},{"location":"docs/api/queue/#scouter.queue._queue.Features.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the list of features</p>"},{"location":"docs/api/queue/#scouter.queue._queue.Features.__init__","title":"<code>__init__(features)</code>","text":"<p>Initialize a features class</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>List[Feature] | Dict[str, Union[int, float, str]]</code> <p>List of features or a dictionary of key-value pairs. If a list, each item must be an instance of Feature. If a dictionary, each key is the feature name and each value is the feature value. Supported types for values are int, float, and string.</p> required Example <pre><code># Passing a list of features\nfeatures = Features(\n    features=[\n        Feature.int(\"feature_1\", 1),\n        Feature.float(\"feature_2\", 2.0),\n        Feature.string(\"feature_3\", \"value\"),\n    ]\n)\n\n# Passing a dictionary (pydantic model) of features\nclass MyFeatures(BaseModel):\n    feature1: int\n    feature2: float\n    feature3: str\n\nmy_features = MyFeatures(\n    feature1=1,\n    feature2=2.0,\n    feature3=\"value\",\n)\n\nfeatures = Features(my_features.model_dump())\n</code></pre> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    features: List[Feature] | Dict[str, Union[int, float, str]],\n) -&gt; None:\n    \"\"\"Initialize a features class\n\n    Args:\n        features:\n            List of features or a dictionary of key-value pairs.\n            If a list, each item must be an instance of Feature.\n            If a dictionary, each key is the feature name and each value is the feature value.\n            Supported types for values are int, float, and string.\n\n    Example:\n        ```python\n        # Passing a list of features\n        features = Features(\n            features=[\n                Feature.int(\"feature_1\", 1),\n                Feature.float(\"feature_2\", 2.0),\n                Feature.string(\"feature_3\", \"value\"),\n            ]\n        )\n\n        # Passing a dictionary (pydantic model) of features\n        class MyFeatures(BaseModel):\n            feature1: int\n            feature2: float\n            feature3: str\n\n        my_features = MyFeatures(\n            feature1=1,\n            feature2=2.0,\n            feature3=\"value\",\n        )\n\n        features = Features(my_features.model_dump())\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Features.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the features</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the features\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.KafkaConfig","title":"<code>KafkaConfig</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class KafkaConfig:\n    brokers: str\n    topic: str\n    compression_type: str\n    message_timeout_ms: int\n    message_max_bytes: int\n    log_level: LogLevel\n    config: Dict[str, str]\n    max_retries: int\n    transport_type: TransportType\n\n    def __init__(\n        self,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        brokers: Optional[str] = None,\n        topic: Optional[str] = None,\n        compression_type: Optional[str] = None,\n        message_timeout_ms: int = 600_000,\n        message_max_bytes: int = 2097164,\n        log_level: LogLevel = LogLevel.Info,\n        config: Dict[str, str] = {},\n        max_retries: int = 3,\n    ) -&gt; None:\n        \"\"\"Kafka configuration for connecting to and publishing messages to Kafka brokers.\n\n        This configuration supports both authenticated (SASL) and unauthenticated connections.\n        When credentials are provided, SASL authentication is automatically enabled with\n        secure defaults.\n\n        Authentication Priority (first match wins):\n            1. Direct parameters (username/password)\n            2. Environment variables (KAFKA_USERNAME/KAFKA_PASSWORD)\n            3. Configuration dictionary (sasl.username/sasl.password)\n\n        SASL Security Defaults:\n            - security.protocol: \"SASL_SSL\" (override via KAFKA_SECURITY_PROTOCOL env var)\n            - sasl.mechanism: \"PLAIN\" (override via KAFKA_SASL_MECHANISM env var)\n\n        Args:\n            username:\n                SASL username for authentication.\n                Fallback: KAFKA_USERNAME environment variable.\n            password:\n                SASL password for authentication.\n                Fallback: KAFKA_PASSWORD environment variable.\n            brokers:\n                Comma-separated list of Kafka broker addresses (host:port).\n                Fallback: KAFKA_BROKERS environment variable.\n                Default: \"localhost:9092\"\n            topic:\n                Target Kafka topic for message publishing.\n                Fallback: KAFKA_TOPIC environment variable.\n                Default: \"scouter_monitoring\"\n            compression_type:\n                Message compression algorithm.\n                Options: \"none\", \"gzip\", \"snappy\", \"lz4\", \"zstd\"\n                Default: \"gzip\"\n            message_timeout_ms:\n                Maximum time to wait for message delivery (milliseconds).\n                Default: 600000 (10 minutes)\n            message_max_bytes:\n                Maximum message size in bytes.\n                Default: 2097164 (~2MB)\n            log_level:\n                Logging verbosity for the Kafka producer.\n                Default: LogLevel.Info\n            config:\n                Additional Kafka producer configuration parameters.\n                See: https://kafka.apache.org/documentation/#producerconfigs\n                Note: Direct parameters take precedence over config dictionary values.\n            max_retries:\n                Maximum number of retry attempts for failed message deliveries.\n                Default: 3\n\n        Examples:\n            Basic usage (unauthenticated):\n            ```python\n            config = KafkaConfig(\n                brokers=\"kafka1:9092,kafka2:9092\",\n                topic=\"my_topic\"\n            )\n            ```\n\n            SASL authentication:\n            ```python\n            config = KafkaConfig(\n                username=\"my_user\",\n                password=\"my_password\",\n                brokers=\"secure-kafka:9093\",\n                topic=\"secure_topic\"\n            )\n            ```\n\n            Advanced configuration:\n            ```python\n            config = KafkaConfig(\n                brokers=\"kafka:9092\",\n                compression_type=\"lz4\",\n                config={\n                    \"acks\": \"all\",\n                    \"batch.size\": \"32768\",\n                    \"linger.ms\": \"10\"\n                }\n            )\n            ```\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.KafkaConfig.__init__","title":"<code>__init__(username=None, password=None, brokers=None, topic=None, compression_type=None, message_timeout_ms=600000, message_max_bytes=2097164, log_level=LogLevel.Info, config={}, max_retries=3)</code>","text":"<p>Kafka configuration for connecting to and publishing messages to Kafka brokers.</p> <p>This configuration supports both authenticated (SASL) and unauthenticated connections. When credentials are provided, SASL authentication is automatically enabled with secure defaults.</p> <p>Authentication Priority (first match wins):     1. Direct parameters (username/password)     2. Environment variables (KAFKA_USERNAME/KAFKA_PASSWORD)     3. Configuration dictionary (sasl.username/sasl.password)</p> SASL Security Defaults <ul> <li>security.protocol: \"SASL_SSL\" (override via KAFKA_SECURITY_PROTOCOL env var)</li> <li>sasl.mechanism: \"PLAIN\" (override via KAFKA_SASL_MECHANISM env var)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>Optional[str]</code> <p>SASL username for authentication. Fallback: KAFKA_USERNAME environment variable.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>SASL password for authentication. Fallback: KAFKA_PASSWORD environment variable.</p> <code>None</code> <code>brokers</code> <code>Optional[str]</code> <p>Comma-separated list of Kafka broker addresses (host:port). Fallback: KAFKA_BROKERS environment variable. Default: \"localhost:9092\"</p> <code>None</code> <code>topic</code> <code>Optional[str]</code> <p>Target Kafka topic for message publishing. Fallback: KAFKA_TOPIC environment variable. Default: \"scouter_monitoring\"</p> <code>None</code> <code>compression_type</code> <code>Optional[str]</code> <p>Message compression algorithm. Options: \"none\", \"gzip\", \"snappy\", \"lz4\", \"zstd\" Default: \"gzip\"</p> <code>None</code> <code>message_timeout_ms</code> <code>int</code> <p>Maximum time to wait for message delivery (milliseconds). Default: 600000 (10 minutes)</p> <code>600000</code> <code>message_max_bytes</code> <code>int</code> <p>Maximum message size in bytes. Default: 2097164 (~2MB)</p> <code>2097164</code> <code>log_level</code> <code>LogLevel</code> <p>Logging verbosity for the Kafka producer. Default: LogLevel.Info</p> <code>Info</code> <code>config</code> <code>Dict[str, str]</code> <p>Additional Kafka producer configuration parameters. See: https://kafka.apache.org/documentation/#producerconfigs Note: Direct parameters take precedence over config dictionary values.</p> <code>{}</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed message deliveries. Default: 3</p> <code>3</code> <p>Examples:</p> <p>Basic usage (unauthenticated): <pre><code>config = KafkaConfig(\n    brokers=\"kafka1:9092,kafka2:9092\",\n    topic=\"my_topic\"\n)\n</code></pre></p> <p>SASL authentication: <pre><code>config = KafkaConfig(\n    username=\"my_user\",\n    password=\"my_password\",\n    brokers=\"secure-kafka:9093\",\n    topic=\"secure_topic\"\n)\n</code></pre></p> <p>Advanced configuration: <pre><code>config = KafkaConfig(\n    brokers=\"kafka:9092\",\n    compression_type=\"lz4\",\n    config={\n        \"acks\": \"all\",\n        \"batch.size\": \"32768\",\n        \"linger.ms\": \"10\"\n    }\n)\n</code></pre></p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    brokers: Optional[str] = None,\n    topic: Optional[str] = None,\n    compression_type: Optional[str] = None,\n    message_timeout_ms: int = 600_000,\n    message_max_bytes: int = 2097164,\n    log_level: LogLevel = LogLevel.Info,\n    config: Dict[str, str] = {},\n    max_retries: int = 3,\n) -&gt; None:\n    \"\"\"Kafka configuration for connecting to and publishing messages to Kafka brokers.\n\n    This configuration supports both authenticated (SASL) and unauthenticated connections.\n    When credentials are provided, SASL authentication is automatically enabled with\n    secure defaults.\n\n    Authentication Priority (first match wins):\n        1. Direct parameters (username/password)\n        2. Environment variables (KAFKA_USERNAME/KAFKA_PASSWORD)\n        3. Configuration dictionary (sasl.username/sasl.password)\n\n    SASL Security Defaults:\n        - security.protocol: \"SASL_SSL\" (override via KAFKA_SECURITY_PROTOCOL env var)\n        - sasl.mechanism: \"PLAIN\" (override via KAFKA_SASL_MECHANISM env var)\n\n    Args:\n        username:\n            SASL username for authentication.\n            Fallback: KAFKA_USERNAME environment variable.\n        password:\n            SASL password for authentication.\n            Fallback: KAFKA_PASSWORD environment variable.\n        brokers:\n            Comma-separated list of Kafka broker addresses (host:port).\n            Fallback: KAFKA_BROKERS environment variable.\n            Default: \"localhost:9092\"\n        topic:\n            Target Kafka topic for message publishing.\n            Fallback: KAFKA_TOPIC environment variable.\n            Default: \"scouter_monitoring\"\n        compression_type:\n            Message compression algorithm.\n            Options: \"none\", \"gzip\", \"snappy\", \"lz4\", \"zstd\"\n            Default: \"gzip\"\n        message_timeout_ms:\n            Maximum time to wait for message delivery (milliseconds).\n            Default: 600000 (10 minutes)\n        message_max_bytes:\n            Maximum message size in bytes.\n            Default: 2097164 (~2MB)\n        log_level:\n            Logging verbosity for the Kafka producer.\n            Default: LogLevel.Info\n        config:\n            Additional Kafka producer configuration parameters.\n            See: https://kafka.apache.org/documentation/#producerconfigs\n            Note: Direct parameters take precedence over config dictionary values.\n        max_retries:\n            Maximum number of retry attempts for failed message deliveries.\n            Default: 3\n\n    Examples:\n        Basic usage (unauthenticated):\n        ```python\n        config = KafkaConfig(\n            brokers=\"kafka1:9092,kafka2:9092\",\n            topic=\"my_topic\"\n        )\n        ```\n\n        SASL authentication:\n        ```python\n        config = KafkaConfig(\n            username=\"my_user\",\n            password=\"my_password\",\n            brokers=\"secure-kafka:9093\",\n            topic=\"secure_topic\"\n        )\n        ```\n\n        Advanced configuration:\n        ```python\n        config = KafkaConfig(\n            brokers=\"kafka:9092\",\n            compression_type=\"lz4\",\n            config={\n                \"acks\": \"all\",\n                \"batch.size\": \"32768\",\n                \"linger.ms\": \"10\"\n            }\n        )\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.LLMRecord","title":"<code>LLMRecord</code>","text":"<p>LLM record containing context tied to a Large Language Model interaction that is used to evaluate drift in LLM responses.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; record = LLMRecord(\n...     context={\n...         \"input\": \"What is the capital of France?\",\n...         \"response\": \"Paris is the capital of France.\"\n...     },\n... )\n&gt;&gt;&gt; print(record.context[\"input\"])\n\"What is the capital of France?\"\n</code></pre> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class LLMRecord:\n    \"\"\"LLM record containing context tied to a Large Language Model interaction\n    that is used to evaluate drift in LLM responses.\n\n\n    Examples:\n        &gt;&gt;&gt; record = LLMRecord(\n        ...     context={\n        ...         \"input\": \"What is the capital of France?\",\n        ...         \"response\": \"Paris is the capital of France.\"\n        ...     },\n        ... )\n        &gt;&gt;&gt; print(record.context[\"input\"])\n        \"What is the capital of France?\"\n    \"\"\"\n\n    prompt: Optional[Prompt]\n    \"\"\"Optional prompt configuration associated with this record.\"\"\"\n\n    entity_type: EntityType\n    \"\"\"Type of entity, always EntityType.LLM for LLMRecord instances.\"\"\"\n\n    def __init__(\n        self,\n        context: Context,\n        prompt: Optional[Prompt | SerializedType] = None,\n    ) -&gt; None:\n        \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n        The record is sent to the `Scouter` server via the `ScouterQueue` and is\n        then used to inject context into the evaluation prompts.\n\n        Args:\n            context:\n                Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n                this will be merged with the input and response data and passed to the assigned\n                evaluation prompts. So if you're evaluation prompts expect additional context via\n                bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n                {\"foo\": \"bar\"}\n            prompt:\n                Optional prompt configuration associated with this record. Can be a Potatohead Prompt or\n                a JSON-serializable type.\n\n        Raises:\n            TypeError: If context is not a dict or a pydantic BaseModel.\n\n        \"\"\"\n        ...\n\n    @property\n    def context(self) -&gt; Dict[str, Any]:\n        \"\"\"Get the contextual information.\n\n        Returns:\n            The context data as a Python object (deserialized from JSON).\n\n        Raises:\n            TypeError: If the stored JSON cannot be converted to a Python object.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.LLMRecord.context","title":"<code>context</code>  <code>property</code>","text":"<p>Get the contextual information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The context data as a Python object (deserialized from JSON).</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the stored JSON cannot be converted to a Python object.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.LLMRecord.entity_type","title":"<code>entity_type</code>  <code>instance-attribute</code>","text":"<p>Type of entity, always EntityType.LLM for LLMRecord instances.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.LLMRecord.prompt","title":"<code>prompt</code>  <code>instance-attribute</code>","text":"<p>Optional prompt configuration associated with this record.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.LLMRecord.__init__","title":"<code>__init__(context, prompt=None)</code>","text":"<p>Creates a new LLM record to associate with an <code>LLMDriftProfile</code>. The record is sent to the <code>Scouter</code> server via the <code>ScouterQueue</code> and is then used to inject context into the evaluation prompts.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>Additional context information as a dictionary or a pydantic BaseModel. During evaluation, this will be merged with the input and response data and passed to the assigned evaluation prompts. So if you're evaluation prompts expect additional context via bound variables (e.g., <code>${foo}</code>), you can pass that here as key value pairs.</p> required <code>prompt</code> <code>Optional[Prompt | SerializedType]</code> <p>Optional prompt configuration associated with this record. Can be a Potatohead Prompt or a JSON-serializable type.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If context is not a dict or a pydantic BaseModel.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    context: Context,\n    prompt: Optional[Prompt | SerializedType] = None,\n) -&gt; None:\n    \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n    The record is sent to the `Scouter` server via the `ScouterQueue` and is\n    then used to inject context into the evaluation prompts.\n\n    Args:\n        context:\n            Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n            this will be merged with the input and response data and passed to the assigned\n            evaluation prompts. So if you're evaluation prompts expect additional context via\n            bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n            {\"foo\": \"bar\"}\n        prompt:\n            Optional prompt configuration associated with this record. Can be a Potatohead Prompt or\n            a JSON-serializable type.\n\n    Raises:\n        TypeError: If context is not a dict or a pydantic BaseModel.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Metric","title":"<code>Metric</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class Metric:\n    def __init__(self, name: str, value: float | int) -&gt; None:\n        \"\"\"Initialize metric\n\n        Args:\n            name:\n                Name of the metric\n            value:\n                Value to assign to the metric. Can be an int or float but will be converted to float.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the metric\"\"\"\n\n    @property\n    def metrics(self) -&gt; List[Metric]:\n        \"\"\"Return the list of metrics\"\"\"\n\n    @property\n    def entity_type(self) -&gt; EntityType:\n        \"\"\"Return the entity type\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Metric.entity_type","title":"<code>entity_type</code>  <code>property</code>","text":"<p>Return the entity type</p>"},{"location":"docs/api/queue/#scouter.queue._queue.Metric.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Return the list of metrics</p>"},{"location":"docs/api/queue/#scouter.queue._queue.Metric.__init__","title":"<code>__init__(name, value)</code>","text":"<p>Initialize metric</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the metric</p> required <code>value</code> <code>float | int</code> <p>Value to assign to the metric. Can be an int or float but will be converted to float.</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, name: str, value: float | int) -&gt; None:\n    \"\"\"Initialize metric\n\n    Args:\n        name:\n            Name of the metric\n        value:\n            Value to assign to the metric. Can be an int or float but will be converted to float.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Metric.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the metric</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the metric\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Metrics","title":"<code>Metrics</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class Metrics:\n    def __init__(self, metrics: List[Metric] | Dict[str, Union[int, float]]) -&gt; None:\n        \"\"\"Initialize metrics\n\n        Args:\n            metrics:\n                List of metrics or a dictionary of key-value pairs.\n                If a list, each item must be an instance of Metric.\n                If a dictionary, each key is the metric name and each value is the metric value.\n\n\n        Example:\n            ```python\n\n            # Passing a list of metrics\n            metrics = Metrics(\n                metrics=[\n                    Metric(\"metric_1\", 1.0),\n                    Metric(\"metric_2\", 2.5),\n                    Metric(\"metric_3\", 3),\n                ]\n            )\n\n            # Passing a dictionary (pydantic model) of metrics\n            class MyMetrics(BaseModel):\n                metric1: float\n                metric2: int\n\n            my_metrics = MyMetrics(\n                metric1=1.0,\n                metric2=2,\n            )\n\n            metrics = Metrics(my_metrics.model_dump())\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the metrics\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Metrics.__init__","title":"<code>__init__(metrics)</code>","text":"<p>Initialize metrics</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>List[Metric] | Dict[str, Union[int, float]]</code> <p>List of metrics or a dictionary of key-value pairs. If a list, each item must be an instance of Metric. If a dictionary, each key is the metric name and each value is the metric value.</p> required Example <p>```python</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, metrics: List[Metric] | Dict[str, Union[int, float]]) -&gt; None:\n    \"\"\"Initialize metrics\n\n    Args:\n        metrics:\n            List of metrics or a dictionary of key-value pairs.\n            If a list, each item must be an instance of Metric.\n            If a dictionary, each key is the metric name and each value is the metric value.\n\n\n    Example:\n        ```python\n\n        # Passing a list of metrics\n        metrics = Metrics(\n            metrics=[\n                Metric(\"metric_1\", 1.0),\n                Metric(\"metric_2\", 2.5),\n                Metric(\"metric_3\", 3),\n            ]\n        )\n\n        # Passing a dictionary (pydantic model) of metrics\n        class MyMetrics(BaseModel):\n            metric1: float\n            metric2: int\n\n        my_metrics = MyMetrics(\n            metric1=1.0,\n            metric2=2,\n        )\n\n        metrics = Metrics(my_metrics.model_dump())\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Metrics.__init__--passing-a-list-of-metrics","title":"Passing a list of metrics","text":"<p>metrics = Metrics(     metrics=[         Metric(\"metric_1\", 1.0),         Metric(\"metric_2\", 2.5),         Metric(\"metric_3\", 3),     ] )</p>"},{"location":"docs/api/queue/#scouter.queue._queue.Metrics.__init__--passing-a-dictionary-pydantic-model-of-metrics","title":"Passing a dictionary (pydantic model) of metrics","text":"<p>class MyMetrics(BaseModel):     metric1: float     metric2: int</p> <p>my_metrics = MyMetrics(     metric1=1.0,     metric2=2, )</p> <p>metrics = Metrics(my_metrics.model_dump())</p>"},{"location":"docs/api/queue/#scouter.queue._queue.Metrics.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the metrics</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the metrics\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord","title":"<code>PsiServerRecord</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class PsiServerRecord:\n    def __init__(\n        self,\n        space: str,\n        name: str,\n        version: str,\n        feature: str,\n        bin_id: int,\n        bin_count: int,\n    ):\n        \"\"\"Initialize spc drift server record\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            feature:\n                Feature name\n            bin_id:\n                Bundle ID\n            bin_count:\n                Bundle ID\n        \"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime.datetime:\n        \"\"\"Return the created at timestamp.\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name.\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version.\"\"\"\n\n    @property\n    def feature(self) -&gt; str:\n        \"\"\"Return the feature.\"\"\"\n\n    @property\n    def bin_id(self) -&gt; int:\n        \"\"\"Return the bin id.\"\"\"\n\n    @property\n    def bin_count(self) -&gt; int:\n        \"\"\"Return the sample value.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def to_dict(self) -&gt; Dict[str, str]:\n        \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.bin_count","title":"<code>bin_count</code>  <code>property</code>","text":"<p>Return the sample value.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.bin_id","title":"<code>bin_id</code>  <code>property</code>","text":"<p>Return the bin id.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the created at timestamp.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.feature","title":"<code>feature</code>  <code>property</code>","text":"<p>Return the feature.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.__init__","title":"<code>__init__(space, name, version, feature, bin_id, bin_count)</code>","text":"<p>Initialize spc drift server record</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> required <code>name</code> <code>str</code> <p>Model name</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>feature</code> <code>str</code> <p>Feature name</p> required <code>bin_id</code> <code>int</code> <p>Bundle ID</p> required <code>bin_count</code> <code>int</code> <p>Bundle ID</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    space: str,\n    name: str,\n    version: str,\n    feature: str,\n    bin_id: int,\n    bin_count: int,\n):\n    \"\"\"Initialize spc drift server record\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        feature:\n            Feature name\n        bin_id:\n            Bundle ID\n        bin_count:\n            Bundle ID\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.PsiServerRecord.to_dict","title":"<code>to_dict()</code>","text":"<p>Return the dictionary representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def to_dict(self) -&gt; Dict[str, str]:\n    \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Queue","title":"<code>Queue</code>","text":"<p>Individual queue associated with a drift profile</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class Queue:\n    \"\"\"Individual queue associated with a drift profile\"\"\"\n\n    def insert(self, entity: Union[Features, Metrics, LLMRecord]) -&gt; None:\n        \"\"\"Insert a record into the queue\n\n        Args:\n            entity:\n                Entity to insert into the queue.\n                Can be an instance for Features, Metrics, or LLMRecord.\n\n        Example:\n            ```python\n            features = Features(\n                features=[\n                    Feature(\"feature_1\", 1),\n                    Feature(\"feature_2\", 2.0),\n                    Feature(\"feature_3\", \"value\"),\n                ]\n            )\n            queue.insert(features)\n            ```\n        \"\"\"\n\n    @property\n    def identifier(self) -&gt; str:\n        \"\"\"Return the identifier of the queue\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.Queue.identifier","title":"<code>identifier</code>  <code>property</code>","text":"<p>Return the identifier of the queue</p>"},{"location":"docs/api/queue/#scouter.queue._queue.Queue.insert","title":"<code>insert(entity)</code>","text":"<p>Insert a record into the queue</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <code>Union[Features, Metrics, LLMRecord]</code> <p>Entity to insert into the queue. Can be an instance for Features, Metrics, or LLMRecord.</p> required Example <pre><code>features = Features(\n    features=[\n        Feature(\"feature_1\", 1),\n        Feature(\"feature_2\", 2.0),\n        Feature(\"feature_3\", \"value\"),\n    ]\n)\nqueue.insert(features)\n</code></pre> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def insert(self, entity: Union[Features, Metrics, LLMRecord]) -&gt; None:\n    \"\"\"Insert a record into the queue\n\n    Args:\n        entity:\n            Entity to insert into the queue.\n            Can be an instance for Features, Metrics, or LLMRecord.\n\n    Example:\n        ```python\n        features = Features(\n            features=[\n                Feature(\"feature_1\", 1),\n                Feature(\"feature_2\", 2.0),\n                Feature(\"feature_3\", \"value\"),\n            ]\n        )\n        queue.insert(features)\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.RabbitMQConfig","title":"<code>RabbitMQConfig</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class RabbitMQConfig:\n    address: str\n    queue: str\n    max_retries: int\n    transport_type: TransportType\n\n    def __init__(\n        self,\n        host: Optional[str] = None,\n        port: Optional[int] = None,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        queue: Optional[str] = None,\n        max_retries: int = 3,\n    ) -&gt; None:\n        \"\"\"RabbitMQ configuration to use with the RabbitMQProducer.\n\n        Args:\n            host:\n                RabbitMQ host.\n                If not provided, the value of the RABBITMQ_HOST environment variable is used.\n\n            port:\n                RabbitMQ port.\n                If not provided, the value of the RABBITMQ_PORT environment variable is used.\n\n            username:\n                RabbitMQ username.\n                If not provided, the value of the RABBITMQ_USERNAME environment variable is used.\n\n            password:\n                RabbitMQ password.\n                If not provided, the value of the RABBITMQ_PASSWORD environment variable is used.\n\n            queue:\n                RabbitMQ queue to publish messages to.\n                If not provided, the value of the RABBITMQ_QUEUE environment variable is used.\n\n            max_retries:\n                Maximum number of retries to attempt when publishing messages.\n                Default is 3.\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.RabbitMQConfig.__init__","title":"<code>__init__(host=None, port=None, username=None, password=None, queue=None, max_retries=3)</code>","text":"<p>RabbitMQ configuration to use with the RabbitMQProducer.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>Optional[str]</code> <p>RabbitMQ host. If not provided, the value of the RABBITMQ_HOST environment variable is used.</p> <code>None</code> <code>port</code> <code>Optional[int]</code> <p>RabbitMQ port. If not provided, the value of the RABBITMQ_PORT environment variable is used.</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>RabbitMQ username. If not provided, the value of the RABBITMQ_USERNAME environment variable is used.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>RabbitMQ password. If not provided, the value of the RABBITMQ_PASSWORD environment variable is used.</p> <code>None</code> <code>queue</code> <code>Optional[str]</code> <p>RabbitMQ queue to publish messages to. If not provided, the value of the RABBITMQ_QUEUE environment variable is used.</p> <code>None</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retries to attempt when publishing messages. Default is 3.</p> <code>3</code> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    host: Optional[str] = None,\n    port: Optional[int] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    queue: Optional[str] = None,\n    max_retries: int = 3,\n) -&gt; None:\n    \"\"\"RabbitMQ configuration to use with the RabbitMQProducer.\n\n    Args:\n        host:\n            RabbitMQ host.\n            If not provided, the value of the RABBITMQ_HOST environment variable is used.\n\n        port:\n            RabbitMQ port.\n            If not provided, the value of the RABBITMQ_PORT environment variable is used.\n\n        username:\n            RabbitMQ username.\n            If not provided, the value of the RABBITMQ_USERNAME environment variable is used.\n\n        password:\n            RabbitMQ password.\n            If not provided, the value of the RABBITMQ_PASSWORD environment variable is used.\n\n        queue:\n            RabbitMQ queue to publish messages to.\n            If not provided, the value of the RABBITMQ_QUEUE environment variable is used.\n\n        max_retries:\n            Maximum number of retries to attempt when publishing messages.\n            Default is 3.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.RedisConfig","title":"<code>RedisConfig</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class RedisConfig:\n    address: str\n    channel: str\n    transport_type: TransportType\n\n    def __init__(\n        self,\n        address: Optional[str] = None,\n        chanel: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Redis configuration to use with a Redis producer\n\n        Args:\n            address (str):\n                Redis address.\n                If not provided, the value of the REDIS_ADDR environment variable is used and defaults to \"redis://localhost:6379\".\n\n            channel (str):\n                Redis channel to publish messages to.\n\n                If not provided, the value of the REDIS_CHANNEL environment variable is used and defaults to \"scouter_monitoring\".\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.RedisConfig.__init__","title":"<code>__init__(address=None, chanel=None)</code>","text":"<p>Redis configuration to use with a Redis producer</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Redis address. If not provided, the value of the REDIS_ADDR environment variable is used and defaults to \"redis://localhost:6379\".</p> <code>None</code> <code>channel</code> <code>str</code> <p>Redis channel to publish messages to.</p> <p>If not provided, the value of the REDIS_CHANNEL environment variable is used and defaults to \"scouter_monitoring\".</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    address: Optional[str] = None,\n    chanel: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Redis configuration to use with a Redis producer\n\n    Args:\n        address (str):\n            Redis address.\n            If not provided, the value of the REDIS_ADDR environment variable is used and defaults to \"redis://localhost:6379\".\n\n        channel (str):\n            Redis channel to publish messages to.\n\n            If not provided, the value of the REDIS_CHANNEL environment variable is used and defaults to \"scouter_monitoring\".\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ScouterQueue","title":"<code>ScouterQueue</code>","text":"<p>Main queue class for Scouter. Publishes drift records to the configured transport</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class ScouterQueue:\n    \"\"\"Main queue class for Scouter. Publishes drift records to the configured transport\"\"\"\n\n    @staticmethod\n    def from_path(\n        path: Dict[str, Path],\n        transport_config: Union[\n            KafkaConfig,\n            RabbitMQConfig,\n            RedisConfig,\n            HTTPConfig,\n        ],\n    ) -&gt; ScouterQueue:\n        \"\"\"Initializes Scouter queue from one or more drift profile paths\n\n        Args:\n            path (Dict[str, Path]):\n                Dictionary of drift profile paths.\n                Each key is a user-defined alias for accessing a queue\n            transport_config (Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig]):\n                Transport configuration for the queue publisher\n                Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig\n\n        Example:\n            ```python\n            queue = ScouterQueue(\n                path={\n                    \"spc\": Path(\"spc_profile.json\"),\n                    \"psi\": Path(\"psi_profile.json\"),\n                },\n                transport_config=KafkaConfig(\n                    brokers=\"localhost:9092\",\n                    topic=\"scouter_topic\",\n                ),\n            )\n\n            queue[\"psi\"].insert(\n                Features(\n                    features=[\n                        Feature(\"feature_1\", 1),\n                        Feature(\"feature_2\", 2.0),\n                        Feature(\"feature_3\", \"value\"),\n                    ]\n                )\n            )\n            ```\n        \"\"\"\n\n    def __getitem__(self, key: str) -&gt; Queue:\n        \"\"\"Get the queue for the specified key\n\n        Args:\n            key (str):\n                Key to get the queue for\n\n        \"\"\"\n\n    def shutdown(self) -&gt; None:\n        \"\"\"Shutdown the queue. This will close and flush all queues and transports\"\"\"\n\n    @property\n    def transport_config(\n        self,\n    ) -&gt; Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig, MockConfig]:\n        \"\"\"Return the transport configuration used by the queue\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ScouterQueue.transport_config","title":"<code>transport_config</code>  <code>property</code>","text":"<p>Return the transport configuration used by the queue</p>"},{"location":"docs/api/queue/#scouter.queue._queue.ScouterQueue.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the queue for the specified key</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key to get the queue for</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; Queue:\n    \"\"\"Get the queue for the specified key\n\n    Args:\n        key (str):\n            Key to get the queue for\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ScouterQueue.from_path","title":"<code>from_path(path, transport_config)</code>  <code>staticmethod</code>","text":"<p>Initializes Scouter queue from one or more drift profile paths</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Dict[str, Path]</code> <p>Dictionary of drift profile paths. Each key is a user-defined alias for accessing a queue</p> required <code>transport_config</code> <code>Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig]</code> <p>Transport configuration for the queue publisher Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig</p> required Example <pre><code>queue = ScouterQueue(\n    path={\n        \"spc\": Path(\"spc_profile.json\"),\n        \"psi\": Path(\"psi_profile.json\"),\n    },\n    transport_config=KafkaConfig(\n        brokers=\"localhost:9092\",\n        topic=\"scouter_topic\",\n    ),\n)\n\nqueue[\"psi\"].insert(\n    Features(\n        features=[\n            Feature(\"feature_1\", 1),\n            Feature(\"feature_2\", 2.0),\n            Feature(\"feature_3\", \"value\"),\n        ]\n    )\n)\n</code></pre> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef from_path(\n    path: Dict[str, Path],\n    transport_config: Union[\n        KafkaConfig,\n        RabbitMQConfig,\n        RedisConfig,\n        HTTPConfig,\n    ],\n) -&gt; ScouterQueue:\n    \"\"\"Initializes Scouter queue from one or more drift profile paths\n\n    Args:\n        path (Dict[str, Path]):\n            Dictionary of drift profile paths.\n            Each key is a user-defined alias for accessing a queue\n        transport_config (Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig]):\n            Transport configuration for the queue publisher\n            Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig\n\n    Example:\n        ```python\n        queue = ScouterQueue(\n            path={\n                \"spc\": Path(\"spc_profile.json\"),\n                \"psi\": Path(\"psi_profile.json\"),\n            },\n            transport_config=KafkaConfig(\n                brokers=\"localhost:9092\",\n                topic=\"scouter_topic\",\n            ),\n        )\n\n        queue[\"psi\"].insert(\n            Features(\n                features=[\n                    Feature(\"feature_1\", 1),\n                    Feature(\"feature_2\", 2.0),\n                    Feature(\"feature_3\", \"value\"),\n                ]\n            )\n        )\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ScouterQueue.shutdown","title":"<code>shutdown()</code>","text":"<p>Shutdown the queue. This will close and flush all queues and transports</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the queue. This will close and flush all queues and transports\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecord","title":"<code>ServerRecord</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class ServerRecord:\n    Spc: \"ServerRecord\"\n    Psi: \"ServerRecord\"\n    Custom: \"ServerRecord\"\n    Observability: \"ServerRecord\"\n\n    def __init__(self, record: Any) -&gt; None:\n        \"\"\"Initialize server record\n\n        Args:\n            record:\n                Server record to initialize\n        \"\"\"\n\n    @property\n    def record(\n        self,\n    ) -&gt; Union[SpcServerRecord, PsiServerRecord, CustomMetricServerRecord, ObservabilityMetrics]:\n        \"\"\"Return the drift server record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecord.record","title":"<code>record</code>  <code>property</code>","text":"<p>Return the drift server record.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecord.__init__","title":"<code>__init__(record)</code>","text":"<p>Initialize server record</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Any</code> <p>Server record to initialize</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, record: Any) -&gt; None:\n    \"\"\"Initialize server record\n\n    Args:\n        record:\n            Server record to initialize\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecords","title":"<code>ServerRecords</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class ServerRecords:\n    def __init__(self, records: List[ServerRecord]) -&gt; None:\n        \"\"\"Initialize server records\n\n        Args:\n            records:\n                List of server records\n        \"\"\"\n\n    @property\n    def records(self) -&gt; List[ServerRecord]:\n        \"\"\"Return the drift server records.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecords.records","title":"<code>records</code>  <code>property</code>","text":"<p>Return the drift server records.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecords.__init__","title":"<code>__init__(records)</code>","text":"<p>Initialize server records</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[ServerRecord]</code> <p>List of server records</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, records: List[ServerRecord]) -&gt; None:\n    \"\"\"Initialize server records\n\n    Args:\n        records:\n            List of server records\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecords.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.ServerRecords.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord","title":"<code>SpcServerRecord</code>","text":"Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>class SpcServerRecord:\n    def __init__(\n        self,\n        space: str,\n        name: str,\n        version: str,\n        feature: str,\n        value: float,\n    ):\n        \"\"\"Initialize spc drift server record\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            feature:\n                Feature name\n            value:\n                Feature value\n        \"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime.datetime:\n        \"\"\"Return the created at timestamp.\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name.\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version.\"\"\"\n\n    @property\n    def feature(self) -&gt; str:\n        \"\"\"Return the feature.\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the sample value.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def to_dict(self) -&gt; Dict[str, str]:\n        \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the created at timestamp.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.feature","title":"<code>feature</code>  <code>property</code>","text":"<p>Return the feature.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the sample value.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version.</p>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.__init__","title":"<code>__init__(space, name, version, feature, value)</code>","text":"<p>Initialize spc drift server record</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> required <code>name</code> <code>str</code> <p>Model name</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>feature</code> <code>str</code> <p>Feature name</p> required <code>value</code> <code>float</code> <p>Feature value</p> required Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    space: str,\n    name: str,\n    version: str,\n    feature: str,\n    value: float,\n):\n    \"\"\"Initialize spc drift server record\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        feature:\n            Feature name\n        value:\n            Feature value\n    \"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/queue/#scouter.queue._queue.SpcServerRecord.to_dict","title":"<code>to_dict()</code>","text":"<p>Return the dictionary representation of the record.</p> Source code in <code>python/scouter/queue/_queue.pyi</code> <pre><code>def to_dict(self) -&gt; Dict[str, str]:\n    \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/types/","title":"Types","text":""},{"location":"docs/api/types/#scouter.types._types.CommonCrons","title":"<code>CommonCrons</code>","text":"Source code in <code>python/scouter/types/_types.pyi</code> <pre><code>class CommonCrons:\n    Every1Minute: \"CommonCrons\"\n    Every5Minutes: \"CommonCrons\"\n    Every15Minutes: \"CommonCrons\"\n    Every30Minutes: \"CommonCrons\"\n    EveryHour: \"CommonCrons\"\n    Every6Hours: \"CommonCrons\"\n    Every12Hours: \"CommonCrons\"\n    EveryDay: \"CommonCrons\"\n    EveryWeek: \"CommonCrons\"\n\n    @property\n    def cron(self) -&gt; str:\n        \"\"\"Return the cron\"\"\"\n\n    def get_next(self) -&gt; str:\n        \"\"\"Return the next cron time\"\"\"\n</code></pre>"},{"location":"docs/api/types/#scouter.types._types.CommonCrons.cron","title":"<code>cron</code>  <code>property</code>","text":"<p>Return the cron</p>"},{"location":"docs/api/types/#scouter.types._types.CommonCrons.get_next","title":"<code>get_next()</code>","text":"<p>Return the next cron time</p> Source code in <code>python/scouter/types/_types.pyi</code> <pre><code>def get_next(self) -&gt; str:\n    \"\"\"Return the next cron time\"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/","title":"Google","text":""},{"location":"docs/api/llm/google/#scouter.llm.google._google.GeminiEmbeddingConfig","title":"<code>GeminiEmbeddingConfig</code>","text":"Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class GeminiEmbeddingConfig:\n    def __init__(\n        self,\n        model: Optional[str] = None,\n        output_dimensionality: Optional[int] = None,\n        task_type: Optional[EmbeddingTaskType | str] = None,\n    ) -&gt; None:\n        \"\"\"Configuration to pass to the Gemini Embedding API when creating a request\n\n\n        Args:\n            model (Optional[str]):\n                The embedding model to use. If not specified, the default gemini model will be used.\n            output_dimensionality (Optional[int]):\n                The output dimensionality of the embeddings. If not specified, a default value will be used.\n            task_type (Optional[EmbeddingTaskType]):\n                The type of embedding task to perform. If not specified, the default gemini task type will be used.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.GeminiEmbeddingConfig.__init__","title":"<code>__init__(model=None, output_dimensionality=None, task_type=None)</code>","text":"<p>Configuration to pass to the Gemini Embedding API when creating a request</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[str]</code> <p>The embedding model to use. If not specified, the default gemini model will be used.</p> <code>None</code> <code>output_dimensionality</code> <code>Optional[int]</code> <p>The output dimensionality of the embeddings. If not specified, a default value will be used.</p> <code>None</code> <code>task_type</code> <code>Optional[EmbeddingTaskType]</code> <p>The type of embedding task to perform. If not specified, the default gemini task type will be used.</p> <code>None</code> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[str] = None,\n    output_dimensionality: Optional[int] = None,\n    task_type: Optional[EmbeddingTaskType | str] = None,\n) -&gt; None:\n    \"\"\"Configuration to pass to the Gemini Embedding API when creating a request\n\n\n    Args:\n        model (Optional[str]):\n            The embedding model to use. If not specified, the default gemini model will be used.\n        output_dimensionality (Optional[int]):\n            The output dimensionality of the embeddings. If not specified, a default value will be used.\n        task_type (Optional[EmbeddingTaskType]):\n            The type of embedding task to perform. If not specified, the default gemini task type will be used.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.GeminiSettings","title":"<code>GeminiSettings</code>","text":"Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class GeminiSettings:\n    def __init__(\n        self,\n        labels: Optional[dict[str, str]] = None,\n        tool_config: Optional[ToolConfig] = None,\n        generation_config: Optional[GenerationConfig] = None,\n        safety_settings: Optional[list[SafetySetting]] = None,\n        model_armor_config: Optional[ModelArmorConfig] = None,\n        extra_body: Optional[dict] = None,\n    ) -&gt; None:\n        \"\"\"Settings to pass to the Gemini API when creating a request\n\n        Reference:\n            https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/generateContent\n\n        Args:\n            labels (Optional[dict[str, str]]):\n                An optional dictionary of labels for the settings.\n            tool_config (Optional[ToolConfig]):\n                Configuration for tools like function calling and retrieval.\n            generation_config (Optional[GenerationConfig]):\n                Configuration for content generation parameters.\n            safety_settings (Optional[list[SafetySetting]]):\n                List of safety settings to apply.\n            model_armor_config (Optional[ModelArmorConfig]):\n                Configuration for model armor templates.\n            extra_body (Optional[dict]):\n                Additional configuration as a dictionary.\n        \"\"\"\n\n    @property\n    def labels(self) -&gt; Optional[dict[str, str]]: ...\n    @property\n    def tool_config(self) -&gt; Optional[ToolConfig]: ...\n    @property\n    def generation_config(self) -&gt; Optional[GenerationConfig]: ...\n    @property\n    def safety_settings(self) -&gt; Optional[list[SafetySetting]]: ...\n    @property\n    def model_armor_config(self) -&gt; Optional[ModelArmorConfig]: ...\n    @property\n    def extra_body(self) -&gt; Optional[dict]: ...\n    def __str__(self) -&gt; str: ...\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.GeminiSettings.__init__","title":"<code>__init__(labels=None, tool_config=None, generation_config=None, safety_settings=None, model_armor_config=None, extra_body=None)</code>","text":"<p>Settings to pass to the Gemini API when creating a request</p> Reference <p>https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/generateContent</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Optional[dict[str, str]]</code> <p>An optional dictionary of labels for the settings.</p> <code>None</code> <code>tool_config</code> <code>Optional[ToolConfig]</code> <p>Configuration for tools like function calling and retrieval.</p> <code>None</code> <code>generation_config</code> <code>Optional[GenerationConfig]</code> <p>Configuration for content generation parameters.</p> <code>None</code> <code>safety_settings</code> <code>Optional[list[SafetySetting]]</code> <p>List of safety settings to apply.</p> <code>None</code> <code>model_armor_config</code> <code>Optional[ModelArmorConfig]</code> <p>Configuration for model armor templates.</p> <code>None</code> <code>extra_body</code> <code>Optional[dict]</code> <p>Additional configuration as a dictionary.</p> <code>None</code> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    labels: Optional[dict[str, str]] = None,\n    tool_config: Optional[ToolConfig] = None,\n    generation_config: Optional[GenerationConfig] = None,\n    safety_settings: Optional[list[SafetySetting]] = None,\n    model_armor_config: Optional[ModelArmorConfig] = None,\n    extra_body: Optional[dict] = None,\n) -&gt; None:\n    \"\"\"Settings to pass to the Gemini API when creating a request\n\n    Reference:\n        https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/generateContent\n\n    Args:\n        labels (Optional[dict[str, str]]):\n            An optional dictionary of labels for the settings.\n        tool_config (Optional[ToolConfig]):\n            Configuration for tools like function calling and retrieval.\n        generation_config (Optional[GenerationConfig]):\n            Configuration for content generation parameters.\n        safety_settings (Optional[list[SafetySetting]]):\n            List of safety settings to apply.\n        model_armor_config (Optional[ModelArmorConfig]):\n            Configuration for model armor templates.\n        extra_body (Optional[dict]):\n            Additional configuration as a dictionary.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.GenerationConfig","title":"<code>GenerationConfig</code>","text":"<p>Configuration for content generation with comprehensive parameter control.</p> <p>This class provides fine-grained control over the generation process including sampling parameters, output format, modalities, and various specialized features.</p> <p>Examples:</p> <p>Basic usage with temperature control:</p> <pre><code>GenerationConfig(temperature=0.7, max_output_tokens=1000)\n</code></pre> <p>Multi-modal configuration: <pre><code>config = GenerationConfig(\n    response_modalities=[Modality.TEXT, Modality.AUDIO],\n    speech_config=SpeechConfig(language_code=\"en-US\")\n)\n</code></pre></p> <p>Advanced sampling with penalties: <pre><code>config = GenerationConfig(\n    temperature=0.8,\n    top_p=0.9,\n    top_k=40,\n    presence_penalty=0.1,\n    frequency_penalty=0.2\n)\n</code></pre></p> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class GenerationConfig:\n    \"\"\"Configuration for content generation with comprehensive parameter control.\n\n    This class provides fine-grained control over the generation process including\n    sampling parameters, output format, modalities, and various specialized features.\n\n    Examples:\n        Basic usage with temperature control:\n\n        ```python\n        GenerationConfig(temperature=0.7, max_output_tokens=1000)\n        ```\n\n        Multi-modal configuration:\n        ```python\n        config = GenerationConfig(\n            response_modalities=[Modality.TEXT, Modality.AUDIO],\n            speech_config=SpeechConfig(language_code=\"en-US\")\n        )\n        ```\n\n        Advanced sampling with penalties:\n        ```python\n        config = GenerationConfig(\n            temperature=0.8,\n            top_p=0.9,\n            top_k=40,\n            presence_penalty=0.1,\n            frequency_penalty=0.2\n        )\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        stop_sequences: Optional[List[str]] = None,\n        response_mime_type: Optional[str] = None,\n        response_modalities: Optional[List[Modality]] = None,\n        thinking_config: Optional[ThinkingConfig] = None,\n        temperature: Optional[float] = None,\n        top_p: Optional[float] = None,\n        top_k: Optional[int] = None,\n        candidate_count: Optional[int] = None,\n        max_output_tokens: Optional[int] = None,\n        response_logprobs: Optional[bool] = None,\n        logprobs: Optional[int] = None,\n        presence_penalty: Optional[float] = None,\n        frequency_penalty: Optional[float] = None,\n        seed: Optional[int] = None,\n        audio_timestamp: Optional[bool] = None,\n        media_resolution: Optional[MediaResolution] = None,\n        speech_config: Optional[SpeechConfig] = None,\n        enable_affective_dialog: Optional[bool] = None,\n    ) -&gt; None:\n        \"\"\"Initialize GenerationConfig with optional parameters.\n\n        Args:\n            stop_sequences (Optional[List[str]]):\n                List of strings that will stop generation when encountered\n            response_mime_type (Optional[str]):\n                MIME type for the response format\n            response_modalities (Optional[List[Modality]]):\n                List of modalities to include in the response\n            thinking_config (Optional[ThinkingConfig]):\n                Configuration for reasoning/thinking capabilities\n            temperature (Optional[float]):\n                Controls randomness in generation (0.0-1.0)\n            top_p (Optional[float]):\n                Nucleus sampling parameter (0.0-1.0)\n            top_k (Optional[int]):\n                Top-k sampling parameter\n            candidate_count (Optional[int]):\n                Number of response candidates to generate\n            max_output_tokens (Optional[int]):\n                Maximum number of tokens to generate\n            response_logprobs (Optional[bool]):\n                Whether to return log probabilities\n            logprobs (Optional[int]):\n                Number of log probabilities to return per token\n            presence_penalty (Optional[float]):\n                Penalty for token presence (-2.0 to 2.0)\n            frequency_penalty (Optional[float]):\n                Penalty for token frequency (-2.0 to 2.0)\n            seed (Optional[int]):\n                Random seed for deterministic generation\n            audio_timestamp (Optional[bool]):\n                Whether to include timestamps in audio responses\n            media_resolution (Optional[MediaResolution]):\n                Resolution setting for media content\n            speech_config (Optional[SpeechConfig]):\n                Configuration for speech synthesis\n            enable_affective_dialog (Optional[bool]):\n                Whether to enable emotional dialog features\n        \"\"\"\n\n    def __str__(self) -&gt; str: ...\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.GenerationConfig.__init__","title":"<code>__init__(stop_sequences=None, response_mime_type=None, response_modalities=None, thinking_config=None, temperature=None, top_p=None, top_k=None, candidate_count=None, max_output_tokens=None, response_logprobs=None, logprobs=None, presence_penalty=None, frequency_penalty=None, seed=None, audio_timestamp=None, media_resolution=None, speech_config=None, enable_affective_dialog=None)</code>","text":"<p>Initialize GenerationConfig with optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>stop_sequences</code> <code>Optional[List[str]]</code> <p>List of strings that will stop generation when encountered</p> <code>None</code> <code>response_mime_type</code> <code>Optional[str]</code> <p>MIME type for the response format</p> <code>None</code> <code>response_modalities</code> <code>Optional[List[Modality]]</code> <p>List of modalities to include in the response</p> <code>None</code> <code>thinking_config</code> <code>Optional[ThinkingConfig]</code> <p>Configuration for reasoning/thinking capabilities</p> <code>None</code> <code>temperature</code> <code>Optional[float]</code> <p>Controls randomness in generation (0.0-1.0)</p> <code>None</code> <code>top_p</code> <code>Optional[float]</code> <p>Nucleus sampling parameter (0.0-1.0)</p> <code>None</code> <code>top_k</code> <code>Optional[int]</code> <p>Top-k sampling parameter</p> <code>None</code> <code>candidate_count</code> <code>Optional[int]</code> <p>Number of response candidates to generate</p> <code>None</code> <code>max_output_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens to generate</p> <code>None</code> <code>response_logprobs</code> <code>Optional[bool]</code> <p>Whether to return log probabilities</p> <code>None</code> <code>logprobs</code> <code>Optional[int]</code> <p>Number of log probabilities to return per token</p> <code>None</code> <code>presence_penalty</code> <code>Optional[float]</code> <p>Penalty for token presence (-2.0 to 2.0)</p> <code>None</code> <code>frequency_penalty</code> <code>Optional[float]</code> <p>Penalty for token frequency (-2.0 to 2.0)</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed for deterministic generation</p> <code>None</code> <code>audio_timestamp</code> <code>Optional[bool]</code> <p>Whether to include timestamps in audio responses</p> <code>None</code> <code>media_resolution</code> <code>Optional[MediaResolution]</code> <p>Resolution setting for media content</p> <code>None</code> <code>speech_config</code> <code>Optional[SpeechConfig]</code> <p>Configuration for speech synthesis</p> <code>None</code> <code>enable_affective_dialog</code> <code>Optional[bool]</code> <p>Whether to enable emotional dialog features</p> <code>None</code> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    stop_sequences: Optional[List[str]] = None,\n    response_mime_type: Optional[str] = None,\n    response_modalities: Optional[List[Modality]] = None,\n    thinking_config: Optional[ThinkingConfig] = None,\n    temperature: Optional[float] = None,\n    top_p: Optional[float] = None,\n    top_k: Optional[int] = None,\n    candidate_count: Optional[int] = None,\n    max_output_tokens: Optional[int] = None,\n    response_logprobs: Optional[bool] = None,\n    logprobs: Optional[int] = None,\n    presence_penalty: Optional[float] = None,\n    frequency_penalty: Optional[float] = None,\n    seed: Optional[int] = None,\n    audio_timestamp: Optional[bool] = None,\n    media_resolution: Optional[MediaResolution] = None,\n    speech_config: Optional[SpeechConfig] = None,\n    enable_affective_dialog: Optional[bool] = None,\n) -&gt; None:\n    \"\"\"Initialize GenerationConfig with optional parameters.\n\n    Args:\n        stop_sequences (Optional[List[str]]):\n            List of strings that will stop generation when encountered\n        response_mime_type (Optional[str]):\n            MIME type for the response format\n        response_modalities (Optional[List[Modality]]):\n            List of modalities to include in the response\n        thinking_config (Optional[ThinkingConfig]):\n            Configuration for reasoning/thinking capabilities\n        temperature (Optional[float]):\n            Controls randomness in generation (0.0-1.0)\n        top_p (Optional[float]):\n            Nucleus sampling parameter (0.0-1.0)\n        top_k (Optional[int]):\n            Top-k sampling parameter\n        candidate_count (Optional[int]):\n            Number of response candidates to generate\n        max_output_tokens (Optional[int]):\n            Maximum number of tokens to generate\n        response_logprobs (Optional[bool]):\n            Whether to return log probabilities\n        logprobs (Optional[int]):\n            Number of log probabilities to return per token\n        presence_penalty (Optional[float]):\n            Penalty for token presence (-2.0 to 2.0)\n        frequency_penalty (Optional[float]):\n            Penalty for token frequency (-2.0 to 2.0)\n        seed (Optional[int]):\n            Random seed for deterministic generation\n        audio_timestamp (Optional[bool]):\n            Whether to include timestamps in audio responses\n        media_resolution (Optional[MediaResolution]):\n            Resolution setting for media content\n        speech_config (Optional[SpeechConfig]):\n            Configuration for speech synthesis\n        enable_affective_dialog (Optional[bool]):\n            Whether to enable emotional dialog features\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.LatLng","title":"<code>LatLng</code>","text":"Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class LatLng:\n    @property\n    def latitude(self) -&gt; float: ...\n    @property\n    def longitude(self) -&gt; float: ...\n    def __init__(self, latitude: float, longitude: float) -&gt; None:\n        \"\"\"Initialize LatLng with latitude and longitude.\n\n        Args:\n            latitude (float):\n                The latitude value.\n            longitude (float):\n                The longitude value.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.LatLng.__init__","title":"<code>__init__(latitude, longitude)</code>","text":"<p>Initialize LatLng with latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>latitude</code> <code>float</code> <p>The latitude value.</p> required <code>longitude</code> <code>float</code> <p>The longitude value.</p> required Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(self, latitude: float, longitude: float) -&gt; None:\n    \"\"\"Initialize LatLng with latitude and longitude.\n\n    Args:\n        latitude (float):\n            The latitude value.\n        longitude (float):\n            The longitude value.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.MediaResolution","title":"<code>MediaResolution</code>","text":"<p>Media resolution settings for content generation.</p> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class MediaResolution:\n    \"\"\"Media resolution settings for content generation.\"\"\"\n\n    MediaResolutionUnspecified: \"MediaResolution\"\n    MediaResolutionLow: \"MediaResolution\"\n    MediaResolutionMedium: \"MediaResolution\"\n    MediaResolutionHigh: \"MediaResolution\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.Modality","title":"<code>Modality</code>","text":"<p>Represents different modalities for content generation.</p> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class Modality:\n    \"\"\"Represents different modalities for content generation.\"\"\"\n\n    ModalityUnspecified: \"Modality\"\n    Text: \"Modality\"\n    Image: \"Modality\"\n    Audio: \"Modality\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.ModelArmorConfig","title":"<code>ModelArmorConfig</code>","text":"Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class ModelArmorConfig:\n    def __init__(\n        self,\n        prompt_template_name: Optional[str],\n        response_template_name: Optional[str],\n    ) -&gt; None:\n        \"\"\"\n        Args:\n            prompt_template_name (Optional[str]):\n                The name of the prompt template to use.\n            response_template_name (Optional[str]):\n                The name of the response template to use.\n        \"\"\"\n\n    @property\n    def prompt_template_name(self) -&gt; Optional[str]: ...\n    @property\n    def response_template_name(self) -&gt; Optional[str]: ...\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.ModelArmorConfig.__init__","title":"<code>__init__(prompt_template_name, response_template_name)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>prompt_template_name</code> <code>Optional[str]</code> <p>The name of the prompt template to use.</p> required <code>response_template_name</code> <code>Optional[str]</code> <p>The name of the response template to use.</p> required Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    prompt_template_name: Optional[str],\n    response_template_name: Optional[str],\n) -&gt; None:\n    \"\"\"\n    Args:\n        prompt_template_name (Optional[str]):\n            The name of the prompt template to use.\n        response_template_name (Optional[str]):\n            The name of the response template to use.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.PrebuiltVoiceConfig","title":"<code>PrebuiltVoiceConfig</code>","text":"<p>Configuration for prebuilt voice models.</p> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class PrebuiltVoiceConfig:\n    \"\"\"Configuration for prebuilt voice models.\"\"\"\n\n    def __init__(\n        self,\n        voice_name: str,\n    ) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.PredictRequest","title":"<code>PredictRequest</code>","text":"Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class PredictRequest:\n    def __init__(self, instances: List[dict], parameters: Optional[dict] = None) -&gt; None:\n        \"\"\"Request to pass to the Vertex Predict API when creating a request\n\n        Args:\n            instances (List[dict]):\n                A list of instances to be sent in the request.\n            parameters (Optional[dict]):\n                Optional parameters for the request.\n        \"\"\"\n\n    @property\n    def instances(self) -&gt; List[dict]: ...\n    @property\n    def parameters(self) -&gt; dict: ...\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.PredictRequest.__init__","title":"<code>__init__(instances, parameters=None)</code>","text":"<p>Request to pass to the Vertex Predict API when creating a request</p> <p>Parameters:</p> Name Type Description Default <code>instances</code> <code>List[dict]</code> <p>A list of instances to be sent in the request.</p> required <code>parameters</code> <code>Optional[dict]</code> <p>Optional parameters for the request.</p> <code>None</code> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(self, instances: List[dict], parameters: Optional[dict] = None) -&gt; None:\n    \"\"\"Request to pass to the Vertex Predict API when creating a request\n\n    Args:\n        instances (List[dict]):\n            A list of instances to be sent in the request.\n        parameters (Optional[dict]):\n            Optional parameters for the request.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.RetrievalConfig","title":"<code>RetrievalConfig</code>","text":"Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class RetrievalConfig:\n    @property\n    def lat_lng(self) -&gt; LatLng: ...\n    @property\n    def language_code(self) -&gt; str: ...\n    def __init__(self, lat_lng: LatLng, language_code: str) -&gt; None:\n        \"\"\"Initialize RetrievalConfig with latitude/longitude and language code.\n\n        Args:\n            lat_lng (LatLng):\n                The latitude and longitude configuration.\n            language_code (str):\n                The language code for the retrieval.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.RetrievalConfig.__init__","title":"<code>__init__(lat_lng, language_code)</code>","text":"<p>Initialize RetrievalConfig with latitude/longitude and language code.</p> <p>Parameters:</p> Name Type Description Default <code>lat_lng</code> <code>LatLng</code> <p>The latitude and longitude configuration.</p> required <code>language_code</code> <code>str</code> <p>The language code for the retrieval.</p> required Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(self, lat_lng: LatLng, language_code: str) -&gt; None:\n    \"\"\"Initialize RetrievalConfig with latitude/longitude and language code.\n\n    Args:\n        lat_lng (LatLng):\n            The latitude and longitude configuration.\n        language_code (str):\n            The language code for the retrieval.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.SafetySetting","title":"<code>SafetySetting</code>","text":"Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class SafetySetting:\n    category: HarmCategory\n    threshold: HarmBlockThreshold\n    method: Optional[HarmBlockMethod]\n\n    def __init__(\n        self,\n        category: HarmCategory,\n        threshold: HarmBlockThreshold,\n        method: Optional[HarmBlockMethod] = None,\n    ) -&gt; None:\n        \"\"\"Initialize SafetySetting with required and optional parameters.\n\n        Args:\n            category (HarmCategory):\n                The category of harm to protect against.\n            threshold (HarmBlockThreshold):\n                The threshold for blocking content.\n            method (Optional[HarmBlockMethod]):\n                The method used for blocking (if any).\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.SafetySetting.__init__","title":"<code>__init__(category, threshold, method=None)</code>","text":"<p>Initialize SafetySetting with required and optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>HarmCategory</code> <p>The category of harm to protect against.</p> required <code>threshold</code> <code>HarmBlockThreshold</code> <p>The threshold for blocking content.</p> required <code>method</code> <code>Optional[HarmBlockMethod]</code> <p>The method used for blocking (if any).</p> <code>None</code> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    category: HarmCategory,\n    threshold: HarmBlockThreshold,\n    method: Optional[HarmBlockMethod] = None,\n) -&gt; None:\n    \"\"\"Initialize SafetySetting with required and optional parameters.\n\n    Args:\n        category (HarmCategory):\n            The category of harm to protect against.\n        threshold (HarmBlockThreshold):\n            The threshold for blocking content.\n        method (Optional[HarmBlockMethod]):\n            The method used for blocking (if any).\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.SpeechConfig","title":"<code>SpeechConfig</code>","text":"<p>Configuration for speech generation.</p> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class SpeechConfig:\n    \"\"\"Configuration for speech generation.\"\"\"\n\n    def __init__(\n        self,\n        voice_config: Optional[\"VoiceConfig\"] = None,\n        language_code: Optional[str] = None,\n    ) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.ThinkingConfig","title":"<code>ThinkingConfig</code>","text":"<p>Configuration for thinking/reasoning capabilities.</p> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class ThinkingConfig:\n    \"\"\"Configuration for thinking/reasoning capabilities.\"\"\"\n\n    def __init__(\n        self,\n        include_thoughts: Optional[bool] = None,\n        thinking_budget: Optional[int] = None,\n    ) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/llm/google/#scouter.llm.google._google.VoiceConfig","title":"<code>VoiceConfig</code>","text":"<p>Configuration for voice generation.</p> Source code in <code>python/scouter/llm/google/_google.pyi</code> <pre><code>class VoiceConfig:\n    \"\"\"Configuration for voice generation.\"\"\"\n\n    def __init__(self, voice_config: VoiceConfigMode) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/llm/llm/","title":"LLM","text":""},{"location":"docs/api/llm/llm/#scouter.llm._llm.Agent","title":"<code>Agent</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Agent:\n    def __init__(\n        self,\n        provider: Provider | str,\n        system_instruction: Optional[str | List[str] | Message | List[Message]] = None,\n    ) -&gt; None:\n        \"\"\"Create an Agent object.\n\n        Args:\n            provider (Provider | str):\n                The provider to use for the agent. This can be a Provider enum or a string\n                representing the provider.\n            system_instruction (Optional[str | List[str] | Message | List[Message]]):\n                The system message to use for the agent. This can be a string, a list of strings,\n                a Message object, or a list of Message objects. If None, no system message will be used.\n                This is added to all tasks that the agent executes. If a given task contains it's own\n                system message, the agent's system message will be prepended to the task's system message.\n\n        Example:\n        ```python\n            agent = Agent(\n                provider=Provider.OpenAI,\n                system_instruction=\"You are a helpful assistant.\",\n            )\n        ```\n        \"\"\"\n\n    @property\n    def system_instruction(self) -&gt; List[Message]:\n        \"\"\"The system message to use for the agent. This is a list of Message objects.\"\"\"\n\n    def execute_task(\n        self,\n        task: Task,\n        output_type: Optional[Any] = None,\n        model: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        \"\"\"Execute a task.\n\n        Args:\n            task (Task):\n                The task to execute.\n            output_type (Optional[Any]):\n                The output type to use for the task. This can either be a Pydantic `BaseModel` class\n                or a supported PotatoHead response type such as `Score`.\n            model (Optional[str]):\n                The model to use for the task. If not provided, defaults to the `model` provided within\n                the Task's prompt. If the Task's prompt does not have a model, an error will be raised.\n\n        Returns:\n            AgentResponse:\n                The response from the agent after executing the task.\n        \"\"\"\n\n    def execute_prompt(\n        self,\n        prompt: Prompt,\n        output_type: Optional[Any] = None,\n        model: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        \"\"\"Execute a prompt.\n\n        Args:\n            prompt (Prompt):`\n                The prompt to execute.\n            output_type (Optional[Any]):\n                The output type to use for the task. This can either be a Pydantic `BaseModel` class\n                or a supported potato_head response type such as `Score`.\n            model (Optional[str]):\n                The model to use for the task. If not provided, defaults to the `model` provided within\n                the Prompt. If the Prompt does not have a model, an error will be raised.\n\n        Returns:\n            AgentResponse:\n                The response from the agent after executing the task.\n        \"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the agent. This is a random uuid7 that is generated when the agent is created.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Agent.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the agent. This is a random uuid7 that is generated when the agent is created.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Agent.system_instruction","title":"<code>system_instruction</code>  <code>property</code>","text":"<p>The system message to use for the agent. This is a list of Message objects.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Agent.__init__","title":"<code>__init__(provider, system_instruction=None)</code>","text":"<p>Create an Agent object.</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>Provider | str</code> <p>The provider to use for the agent. This can be a Provider enum or a string representing the provider.</p> required <code>system_instruction</code> <code>Optional[str | List[str] | Message | List[Message]]</code> <p>The system message to use for the agent. This can be a string, a list of strings, a Message object, or a list of Message objects. If None, no system message will be used. This is added to all tasks that the agent executes. If a given task contains it's own system message, the agent's system message will be prepended to the task's system message.</p> <code>None</code> <p>Example: <pre><code>    agent = Agent(\n        provider=Provider.OpenAI,\n        system_instruction=\"You are a helpful assistant.\",\n    )\n</code></pre></p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(\n    self,\n    provider: Provider | str,\n    system_instruction: Optional[str | List[str] | Message | List[Message]] = None,\n) -&gt; None:\n    \"\"\"Create an Agent object.\n\n    Args:\n        provider (Provider | str):\n            The provider to use for the agent. This can be a Provider enum or a string\n            representing the provider.\n        system_instruction (Optional[str | List[str] | Message | List[Message]]):\n            The system message to use for the agent. This can be a string, a list of strings,\n            a Message object, or a list of Message objects. If None, no system message will be used.\n            This is added to all tasks that the agent executes. If a given task contains it's own\n            system message, the agent's system message will be prepended to the task's system message.\n\n    Example:\n    ```python\n        agent = Agent(\n            provider=Provider.OpenAI,\n            system_instruction=\"You are a helpful assistant.\",\n        )\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Agent.execute_prompt","title":"<code>execute_prompt(prompt, output_type=None, model=None)</code>","text":"<p>Execute a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>Prompt</code> <p>` The prompt to execute.</p> required <code>output_type</code> <code>Optional[Any]</code> <p>The output type to use for the task. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> <code>None</code> <code>model</code> <code>Optional[str]</code> <p>The model to use for the task. If not provided, defaults to the <code>model</code> provided within the Prompt. If the Prompt does not have a model, an error will be raised.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AgentResponse</code> <code>AgentResponse</code> <p>The response from the agent after executing the task.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def execute_prompt(\n    self,\n    prompt: Prompt,\n    output_type: Optional[Any] = None,\n    model: Optional[str] = None,\n) -&gt; AgentResponse:\n    \"\"\"Execute a prompt.\n\n    Args:\n        prompt (Prompt):`\n            The prompt to execute.\n        output_type (Optional[Any]):\n            The output type to use for the task. This can either be a Pydantic `BaseModel` class\n            or a supported potato_head response type such as `Score`.\n        model (Optional[str]):\n            The model to use for the task. If not provided, defaults to the `model` provided within\n            the Prompt. If the Prompt does not have a model, an error will be raised.\n\n    Returns:\n        AgentResponse:\n            The response from the agent after executing the task.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Agent.execute_task","title":"<code>execute_task(task, output_type=None, model=None)</code>","text":"<p>Execute a task.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>The task to execute.</p> required <code>output_type</code> <code>Optional[Any]</code> <p>The output type to use for the task. This can either be a Pydantic <code>BaseModel</code> class or a supported PotatoHead response type such as <code>Score</code>.</p> <code>None</code> <code>model</code> <code>Optional[str]</code> <p>The model to use for the task. If not provided, defaults to the <code>model</code> provided within the Task's prompt. If the Task's prompt does not have a model, an error will be raised.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AgentResponse</code> <code>AgentResponse</code> <p>The response from the agent after executing the task.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def execute_task(\n    self,\n    task: Task,\n    output_type: Optional[Any] = None,\n    model: Optional[str] = None,\n) -&gt; AgentResponse:\n    \"\"\"Execute a task.\n\n    Args:\n        task (Task):\n            The task to execute.\n        output_type (Optional[Any]):\n            The output type to use for the task. This can either be a Pydantic `BaseModel` class\n            or a supported PotatoHead response type such as `Score`.\n        model (Optional[str]):\n            The model to use for the task. If not provided, defaults to the `model` provided within\n            the Task's prompt. If the Task's prompt does not have a model, an error will be raised.\n\n    Returns:\n        AgentResponse:\n            The response from the agent after executing the task.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AgentResponse","title":"<code>AgentResponse</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class AgentResponse:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the agent response.\"\"\"\n\n    @property\n    def result(self) -&gt; Any:\n        \"\"\"The result of the agent response. This can be a Pydantic BaseModel class or\n        a supported potato_head response type such as `Score`.\n        If neither is provided, the response json will be returned as a dictionary.\n        \"\"\"\n\n    @property\n    def token_usage(self) -&gt; Usage:\n        \"\"\"Returns the token usage of the agent response if supported\"\"\"\n\n    @property\n    def log_probs(self) -&gt; List[\"ResponseLogProbs\"]:\n        \"\"\"Returns the log probabilities of the agent response if supported.\n        This is primarily used for debugging and analysis purposes.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AgentResponse.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the agent response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AgentResponse.log_probs","title":"<code>log_probs</code>  <code>property</code>","text":"<p>Returns the log probabilities of the agent response if supported. This is primarily used for debugging and analysis purposes.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AgentResponse.result","title":"<code>result</code>  <code>property</code>","text":"<p>The result of the agent response. This can be a Pydantic BaseModel class or a supported potato_head response type such as <code>Score</code>. If neither is provided, the response json will be returned as a dictionary.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AgentResponse.token_usage","title":"<code>token_usage</code>  <code>property</code>","text":"<p>Returns the token usage of the agent response if supported</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AudioUrl","title":"<code>AudioUrl</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class AudioUrl:\n    def __init__(\n        self,\n        url: str,\n        kind: Literal[\"audio-url\"] = \"audio-url\",\n    ) -&gt; None:\n        \"\"\"Create an AudioUrl object.\n\n        Args:\n            url (str):\n                The URL of the audio.\n            kind (Literal[\"audio-url\"]):\n                The kind of the content.\n        \"\"\"\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"The URL of the audio.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the audio URL.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the audio URL.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AudioUrl.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the audio URL.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AudioUrl.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AudioUrl.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the audio URL.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AudioUrl.url","title":"<code>url</code>  <code>property</code>","text":"<p>The URL of the audio.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.AudioUrl.__init__","title":"<code>__init__(url, kind='audio-url')</code>","text":"<p>Create an AudioUrl object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the audio.</p> required <code>kind</code> <code>Literal['audio-url']</code> <p>The kind of the content.</p> <code>'audio-url'</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(\n    self,\n    url: str,\n    kind: Literal[\"audio-url\"] = \"audio-url\",\n) -&gt; None:\n    \"\"\"Create an AudioUrl object.\n\n    Args:\n        url (str):\n            The URL of the audio.\n        kind (Literal[\"audio-url\"]):\n            The kind of the content.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.BinaryContent","title":"<code>BinaryContent</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class BinaryContent:\n    def __init__(\n        self,\n        data: bytes,\n        media_type: str,\n        kind: str = \"binary\",\n    ) -&gt; None:\n        \"\"\"Create a BinaryContent object.\n\n        Args:\n            data (bytes):\n                The binary data.\n            media_type (str):\n                The media type of the binary data.\n            kind (str):\n                The kind of the content\n        \"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the binary content.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the binary content.\"\"\"\n\n    @property\n    def data(self) -&gt; bytes:\n        \"\"\"The binary data.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.BinaryContent.data","title":"<code>data</code>  <code>property</code>","text":"<p>The binary data.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.BinaryContent.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the binary content.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.BinaryContent.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.BinaryContent.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the binary content.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.BinaryContent.__init__","title":"<code>__init__(data, media_type, kind='binary')</code>","text":"<p>Create a BinaryContent object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>The binary data.</p> required <code>media_type</code> <code>str</code> <p>The media type of the binary data.</p> required <code>kind</code> <code>str</code> <p>The kind of the content</p> <code>'binary'</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(\n    self,\n    data: bytes,\n    media_type: str,\n    kind: str = \"binary\",\n) -&gt; None:\n    \"\"\"Create a BinaryContent object.\n\n    Args:\n        data (bytes):\n            The binary data.\n        media_type (str):\n            The media type of the binary data.\n        kind (str):\n            The kind of the content\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ChatResponse","title":"<code>ChatResponse</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class ChatResponse:\n    def to_py(self) -&gt; Any:\n        \"\"\"Convert the ChatResponse to it's Python representation.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the ChatResponse.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ChatResponse.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the ChatResponse.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the ChatResponse.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ChatResponse.to_py","title":"<code>to_py()</code>","text":"<p>Convert the ChatResponse to it's Python representation.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def to_py(self) -&gt; Any:\n    \"\"\"Convert the ChatResponse to it's Python representation.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.CompletionTokenDetails","title":"<code>CompletionTokenDetails</code>","text":"<p>Details about the completion tokens used in a model response.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class CompletionTokenDetails:\n    \"\"\"Details about the completion tokens used in a model response.\"\"\"\n\n    @property\n    def accepted_prediction_tokens(self) -&gt; int:\n        \"\"\"The number of accepted prediction tokens used in the response.\"\"\"\n\n    @property\n    def audio_tokens(self) -&gt; int:\n        \"\"\"The number of audio tokens used in the response.\"\"\"\n\n    @property\n    def reasoning_tokens(self) -&gt; int:\n        \"\"\"The number of reasoning tokens used in the response.\"\"\"\n\n    @property\n    def rejected_prediction_tokens(self) -&gt; int:\n        \"\"\"The number of rejected prediction tokens used in the response.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.CompletionTokenDetails.accepted_prediction_tokens","title":"<code>accepted_prediction_tokens</code>  <code>property</code>","text":"<p>The number of accepted prediction tokens used in the response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.CompletionTokenDetails.audio_tokens","title":"<code>audio_tokens</code>  <code>property</code>","text":"<p>The number of audio tokens used in the response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.CompletionTokenDetails.reasoning_tokens","title":"<code>reasoning_tokens</code>  <code>property</code>","text":"<p>The number of reasoning tokens used in the response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.CompletionTokenDetails.rejected_prediction_tokens","title":"<code>rejected_prediction_tokens</code>  <code>property</code>","text":"<p>The number of rejected prediction tokens used in the response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.DocumentUrl","title":"<code>DocumentUrl</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class DocumentUrl:\n    def __init__(\n        self,\n        url: str,\n        kind: Literal[\"document-url\"] = \"document-url\",\n    ) -&gt; None:\n        \"\"\"Create a DocumentUrl object.\n\n        Args:\n            url (str):\n                The URL of the document.\n            kind (Literal[\"document-url\"]):\n                The kind of the content.\n        \"\"\"\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"The URL of the document.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the document URL.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the document URL.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.DocumentUrl.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the document URL.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.DocumentUrl.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.DocumentUrl.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the document URL.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.DocumentUrl.url","title":"<code>url</code>  <code>property</code>","text":"<p>The URL of the document.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.DocumentUrl.__init__","title":"<code>__init__(url, kind='document-url')</code>","text":"<p>Create a DocumentUrl object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the document.</p> required <code>kind</code> <code>Literal['document-url']</code> <p>The kind of the content.</p> <code>'document-url'</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(\n    self,\n    url: str,\n    kind: Literal[\"document-url\"] = \"document-url\",\n) -&gt; None:\n    \"\"\"Create a DocumentUrl object.\n\n    Args:\n        url (str):\n            The URL of the document.\n        kind (Literal[\"document-url\"]):\n            The kind of the content.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Embedder","title":"<code>Embedder</code>","text":"<p>Class for creating embeddings.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Embedder:\n    \"\"\"Class for creating embeddings.\"\"\"\n\n    def __init__(  # type: ignore\n        self,\n        provider: Provider | str,\n        config: Optional[OpenAIEmbeddingConfig | GeminiEmbeddingConfig] = None,\n    ) -&gt; None:\n        \"\"\"Create an Embedder object.\n\n        Args:\n            provider (Provider | str):\n                The provider to use for the embedder. This can be a Provider enum or a string\n                representing the provider.\n            config (Optional[OpenAIEmbeddingConfig | GeminiEmbeddingConfig]):\n                The configuration to use for the embedder. This can be a Pydantic BaseModel class\n                representing the configuration for the provider. If no config is provided,\n                defaults to OpenAI provider configuration.\n        \"\"\"\n\n    def embed(\n        self,\n        input: str | List[str] | PredictRequest,\n    ) -&gt; OpenAIEmbeddingResponse | GeminiEmbeddingResponse | PredictResponse:\n        \"\"\"Create embeddings for input.\n\n        Args:\n            input: The input to embed. Type depends on provider:\n                - OpenAI/Gemini: str | List[str]\n                - Vertex: PredictRequest\n\n        Returns:\n            Provider-specific response type.\n            OpenAIEmbeddingResponse for OpenAI,\n            GeminiEmbeddingResponse for Gemini,\n            PredictResponse for Vertex.\n\n        Examples:\n            ```python\n            ## OpenAI\n            embedder = Embedder(Provider.OpenAI)\n            response = embedder.embed(input=\"Test input\")\n\n            ## Gemini\n            embedder = Embedder(Provider.Gemini, config=GeminiEmbeddingConfig(model=\"gemini-embedding-001\"))\n            response = embedder.embed(input=\"Test input\")\n\n            ## Vertex\n            from potato_head.google import PredictRequest\n            embedder = Embedder(Provider.Vertex)\n            response = embedder.embed(input=PredictRequest(text=\"Test input\"))\n            ```\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Embedder.__init__","title":"<code>__init__(provider, config=None)</code>","text":"<p>Create an Embedder object.</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>Provider | str</code> <p>The provider to use for the embedder. This can be a Provider enum or a string representing the provider.</p> required <code>config</code> <code>Optional[OpenAIEmbeddingConfig | GeminiEmbeddingConfig]</code> <p>The configuration to use for the embedder. This can be a Pydantic BaseModel class representing the configuration for the provider. If no config is provided, defaults to OpenAI provider configuration.</p> <code>None</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(  # type: ignore\n    self,\n    provider: Provider | str,\n    config: Optional[OpenAIEmbeddingConfig | GeminiEmbeddingConfig] = None,\n) -&gt; None:\n    \"\"\"Create an Embedder object.\n\n    Args:\n        provider (Provider | str):\n            The provider to use for the embedder. This can be a Provider enum or a string\n            representing the provider.\n        config (Optional[OpenAIEmbeddingConfig | GeminiEmbeddingConfig]):\n            The configuration to use for the embedder. This can be a Pydantic BaseModel class\n            representing the configuration for the provider. If no config is provided,\n            defaults to OpenAI provider configuration.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Embedder.embed","title":"<code>embed(input)</code>","text":"<p>Create embeddings for input.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str | List[str] | PredictRequest</code> <p>The input to embed. Type depends on provider: - OpenAI/Gemini: str | List[str] - Vertex: PredictRequest</p> required <p>Returns:</p> Type Description <code>OpenAIEmbeddingResponse | GeminiEmbeddingResponse | PredictResponse</code> <p>Provider-specific response type.</p> <code>OpenAIEmbeddingResponse | GeminiEmbeddingResponse | PredictResponse</code> <p>OpenAIEmbeddingResponse for OpenAI,</p> <code>OpenAIEmbeddingResponse | GeminiEmbeddingResponse | PredictResponse</code> <p>GeminiEmbeddingResponse for Gemini,</p> <code>OpenAIEmbeddingResponse | GeminiEmbeddingResponse | PredictResponse</code> <p>PredictResponse for Vertex.</p> <p>Examples:</p> <pre><code>## OpenAI\nembedder = Embedder(Provider.OpenAI)\nresponse = embedder.embed(input=\"Test input\")\n\n## Gemini\nembedder = Embedder(Provider.Gemini, config=GeminiEmbeddingConfig(model=\"gemini-embedding-001\"))\nresponse = embedder.embed(input=\"Test input\")\n\n## Vertex\nfrom potato_head.google import PredictRequest\nembedder = Embedder(Provider.Vertex)\nresponse = embedder.embed(input=PredictRequest(text=\"Test input\"))\n</code></pre> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def embed(\n    self,\n    input: str | List[str] | PredictRequest,\n) -&gt; OpenAIEmbeddingResponse | GeminiEmbeddingResponse | PredictResponse:\n    \"\"\"Create embeddings for input.\n\n    Args:\n        input: The input to embed. Type depends on provider:\n            - OpenAI/Gemini: str | List[str]\n            - Vertex: PredictRequest\n\n    Returns:\n        Provider-specific response type.\n        OpenAIEmbeddingResponse for OpenAI,\n        GeminiEmbeddingResponse for Gemini,\n        PredictResponse for Vertex.\n\n    Examples:\n        ```python\n        ## OpenAI\n        embedder = Embedder(Provider.OpenAI)\n        response = embedder.embed(input=\"Test input\")\n\n        ## Gemini\n        embedder = Embedder(Provider.Gemini, config=GeminiEmbeddingConfig(model=\"gemini-embedding-001\"))\n        response = embedder.embed(input=\"Test input\")\n\n        ## Vertex\n        from potato_head.google import PredictRequest\n        embedder = Embedder(Provider.Vertex)\n        response = embedder.embed(input=PredictRequest(text=\"Test input\"))\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.EventDetails","title":"<code>EventDetails</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class EventDetails:\n    @property\n    def prompt(self) -&gt; Optional[Prompt]:\n        \"\"\"The prompt used for the task.\"\"\"\n\n    @property\n    def response(self) -&gt; Optional[ChatResponse]:\n        \"\"\"The response from the agent after executing the task.\"\"\"\n\n    @property\n    def duration(self) -&gt; Optional[datetime.timedelta]:\n        \"\"\"The duration of the task execution.\"\"\"\n\n    @property\n    def start_time(self) -&gt; Optional[datetime.datetime]:\n        \"\"\"The start time of the task execution.\"\"\"\n\n    @property\n    def end_time(self) -&gt; Optional[datetime.datetime]:\n        \"\"\"The end time of the task execution.\"\"\"\n\n    @property\n    def error(self) -&gt; Optional[str]:\n        \"\"\"The error message if the task failed, otherwise None.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.EventDetails.duration","title":"<code>duration</code>  <code>property</code>","text":"<p>The duration of the task execution.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.EventDetails.end_time","title":"<code>end_time</code>  <code>property</code>","text":"<p>The end time of the task execution.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.EventDetails.error","title":"<code>error</code>  <code>property</code>","text":"<p>The error message if the task failed, otherwise None.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.EventDetails.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>The prompt used for the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.EventDetails.response","title":"<code>response</code>  <code>property</code>","text":"<p>The response from the agent after executing the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.EventDetails.start_time","title":"<code>start_time</code>  <code>property</code>","text":"<p>The start time of the task execution.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ImageUrl","title":"<code>ImageUrl</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class ImageUrl:\n    def __init__(\n        self,\n        url: str,\n        kind: Literal[\"image-url\"] = \"image-url\",\n    ) -&gt; None:\n        \"\"\"Create an ImageUrl object.\n\n        Args:\n            url (str):\n                The URL of the image.\n            kind (Literal[\"image-url\"]):\n                The kind of the content.\n        \"\"\"\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"The URL of the image.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the image URL.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the image URL.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ImageUrl.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the image URL.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ImageUrl.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ImageUrl.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the image URL.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ImageUrl.url","title":"<code>url</code>  <code>property</code>","text":"<p>The URL of the image.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ImageUrl.__init__","title":"<code>__init__(url, kind='image-url')</code>","text":"<p>Create an ImageUrl object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the image.</p> required <code>kind</code> <code>Literal['image-url']</code> <p>The kind of the content.</p> <code>'image-url'</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(\n    self,\n    url: str,\n    kind: Literal[\"image-url\"] = \"image-url\",\n) -&gt; None:\n    \"\"\"Create an ImageUrl object.\n\n    Args:\n        url (str):\n            The URL of the image.\n        kind (Literal[\"image-url\"]):\n            The kind of the content.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.LogProbs","title":"<code>LogProbs</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class LogProbs:\n    @property\n    def tokens(self) -&gt; List[ResponseLogProbs]:\n        \"\"\"The log probabilities of the tokens in the response.\n        This is primarily used for debugging and analysis purposes.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the log probabilities.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.LogProbs.tokens","title":"<code>tokens</code>  <code>property</code>","text":"<p>The log probabilities of the tokens in the response. This is primarily used for debugging and analysis purposes.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.LogProbs.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the log probabilities.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the log probabilities.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Message","title":"<code>Message</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Message:\n    def __init__(self, content: str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl) -&gt; None:\n        \"\"\"Create a Message object.\n\n        Args:\n            content (str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl):\n                The content of the message.\n        \"\"\"\n\n    @property\n    def content(self) -&gt; str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl:\n        \"\"\"The content of the message\"\"\"\n\n    def bind(self, name: str, value: str) -&gt; \"Message\":\n        \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n        will return a new Message object with the context bound.\n\n            Example with Prompt that contains two messages\n\n            ```python\n                prompt = Prompt(\n                    model=\"openai:gpt-4o\",\n                    message=[\n                        \"My prompt variable is ${variable}\",\n                        \"This is another message\",\n                    ],\n                    system_instruction=\"system_prompt\",\n                )\n                bounded_prompt = prompt.message[0].bind(\"variable\", \"hello world\").unwrap() # we bind \"hello world\" to \"variable\"\n            ```\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str):\n                The value to bind the variable to.\n\n        Returns:\n            Message:\n                The message with the context bound.\n        \"\"\"\n\n    def bind_mut(self, name: str, value: str) -&gt; \"Message\":\n        \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n        will modify the current Message object.\n\n            Example with Prompt that contains two messages\n\n            ```python\n                prompt = Prompt(\n                    model=\"openai:gpt-4o\",\n                    message=[\n                        \"My prompt variable is ${variable}\",\n                        \"This is another message\",\n                    ],\n                    system_instruction=\"system_prompt\",\n                )\n                prompt.message[0].bind_mut(\"variable\", \"hello world\") # we bind \"hello world\" to \"variable\"\n            ```\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str):\n                The value to bind the variable to.\n\n        Returns:\n            Message:\n                The message with the context bound.\n        \"\"\"\n\n    def unwrap(self) -&gt; Any:\n        \"\"\"Unwrap the message content.\n\n        Returns:\n            A serializable representation of the message content, which can be a string, list, or dict.\n        \"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Unwrap the message content and serialize it to a dictionary.\n\n        Returns:\n            Dict[str, Any]:\n                The message dictionary with keys \"content\" and \"role\".\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Message.content","title":"<code>content</code>  <code>property</code>","text":"<p>The content of the message</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Message.__init__","title":"<code>__init__(content)</code>","text":"<p>Create a Message object.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl</code> <p>The content of the message.</p> required Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(self, content: str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl) -&gt; None:\n    \"\"\"Create a Message object.\n\n    Args:\n        content (str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl):\n            The content of the message.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Message.bind","title":"<code>bind(name, value)</code>","text":"<p>Bind context to a specific variable in the prompt. This is an immutable operation meaning that it will return a new Message object with the context bound.</p> <pre><code>Example with Prompt that contains two messages\n\n```python\n    prompt = Prompt(\n        model=\"openai:gpt-4o\",\n        message=[\n            \"My prompt variable is ${variable}\",\n            \"This is another message\",\n        ],\n        system_instruction=\"system_prompt\",\n    )\n    bounded_prompt = prompt.message[0].bind(\"variable\", \"hello world\").unwrap() # we bind \"hello world\" to \"variable\"\n```\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> required <code>value</code> <code>str</code> <p>The value to bind the variable to.</p> required <p>Returns:</p> Name Type Description <code>Message</code> <code>Message</code> <p>The message with the context bound.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def bind(self, name: str, value: str) -&gt; \"Message\":\n    \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n    will return a new Message object with the context bound.\n\n        Example with Prompt that contains two messages\n\n        ```python\n            prompt = Prompt(\n                model=\"openai:gpt-4o\",\n                message=[\n                    \"My prompt variable is ${variable}\",\n                    \"This is another message\",\n                ],\n                system_instruction=\"system_prompt\",\n            )\n            bounded_prompt = prompt.message[0].bind(\"variable\", \"hello world\").unwrap() # we bind \"hello world\" to \"variable\"\n        ```\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str):\n            The value to bind the variable to.\n\n    Returns:\n        Message:\n            The message with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Message.bind_mut","title":"<code>bind_mut(name, value)</code>","text":"<p>Bind context to a specific variable in the prompt. This is a mutable operation meaning that it will modify the current Message object.</p> <pre><code>Example with Prompt that contains two messages\n\n```python\n    prompt = Prompt(\n        model=\"openai:gpt-4o\",\n        message=[\n            \"My prompt variable is ${variable}\",\n            \"This is another message\",\n        ],\n        system_instruction=\"system_prompt\",\n    )\n    prompt.message[0].bind_mut(\"variable\", \"hello world\") # we bind \"hello world\" to \"variable\"\n```\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> required <code>value</code> <code>str</code> <p>The value to bind the variable to.</p> required <p>Returns:</p> Name Type Description <code>Message</code> <code>Message</code> <p>The message with the context bound.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def bind_mut(self, name: str, value: str) -&gt; \"Message\":\n    \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n    will modify the current Message object.\n\n        Example with Prompt that contains two messages\n\n        ```python\n            prompt = Prompt(\n                model=\"openai:gpt-4o\",\n                message=[\n                    \"My prompt variable is ${variable}\",\n                    \"This is another message\",\n                ],\n                system_instruction=\"system_prompt\",\n            )\n            prompt.message[0].bind_mut(\"variable\", \"hello world\") # we bind \"hello world\" to \"variable\"\n        ```\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str):\n            The value to bind the variable to.\n\n    Returns:\n        Message:\n            The message with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Message.model_dump","title":"<code>model_dump()</code>","text":"<p>Unwrap the message content and serialize it to a dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: The message dictionary with keys \"content\" and \"role\".</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Unwrap the message content and serialize it to a dictionary.\n\n    Returns:\n        Dict[str, Any]:\n            The message dictionary with keys \"content\" and \"role\".\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Message.unwrap","title":"<code>unwrap()</code>","text":"<p>Unwrap the message content.</p> <p>Returns:</p> Type Description <code>Any</code> <p>A serializable representation of the message content, which can be a string, list, or dict.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def unwrap(self) -&gt; Any:\n    \"\"\"Unwrap the message content.\n\n    Returns:\n        A serializable representation of the message content, which can be a string, list, or dict.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ModelSettings","title":"<code>ModelSettings</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class ModelSettings:\n    def __init__(self, settings: OpenAIChatSettings | GeminiSettings) -&gt; None:\n        \"\"\"ModelSettings for configuring the model.\n\n        Args:\n            settings (OpenAIChatSettings | GeminiSettings):\n                The settings to use for the model. Currently supports OpenAI and Gemini settings.\n        \"\"\"\n\n    @property\n    def settings(self) -&gt; OpenAIChatSettings | GeminiSettings:\n        \"\"\"The settings to use for the model.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"The JSON representation of the model settings.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ModelSettings.settings","title":"<code>settings</code>  <code>property</code>","text":"<p>The settings to use for the model.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ModelSettings.__init__","title":"<code>__init__(settings)</code>","text":"<p>ModelSettings for configuring the model.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>OpenAIChatSettings | GeminiSettings</code> <p>The settings to use for the model. Currently supports OpenAI and Gemini settings.</p> required Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(self, settings: OpenAIChatSettings | GeminiSettings) -&gt; None:\n    \"\"\"ModelSettings for configuring the model.\n\n    Args:\n        settings (OpenAIChatSettings | GeminiSettings):\n            The settings to use for the model. Currently supports OpenAI and Gemini settings.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ModelSettings.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>The JSON representation of the model settings.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"The JSON representation of the model settings.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt","title":"<code>Prompt</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Prompt:\n    def __init__(\n        self,\n        message: (\n            str\n            | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl]\n            | Message\n            | List[Message]\n            | List[Dict[str, Any]]\n        ),\n        model: str,\n        provider: Provider | str,\n        system_instruction: Optional[str | List[str]] = None,\n        model_settings: Optional[ModelSettings | OpenAIChatSettings | GeminiSettings] = None,\n        response_format: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"Prompt for interacting with an LLM API.\n\n        Args:\n            message (str | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl] | Message | List[Message]):\n                The prompt to use.\n            model (str):\n                The model to use for the prompt\n            provider (Provider | str):\n                The provider to use for the prompt.\n            system_instruction (Optional[str | List[str]]):\n                The system prompt to use in the prompt.\n            model_settings (None):\n                The model settings to use for the prompt.\n                Defaults to None which means no model settings will be used\n            response_format (Optional[BaseModel | Score]):\n                The response format to use for the prompt. This is used for Structured Outputs\n                (https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat).\n                Currently, response_format only support Pydantic BaseModel classes and the PotatoHead Score class.\n                The provided response_format will be parsed into a JSON schema.\n\n        \"\"\"\n\n    @property\n    def model(self) -&gt; str:\n        \"\"\"The model to use for the prompt.\"\"\"\n\n    @property\n    def provider(self) -&gt; str:\n        \"\"\"The provider to use for the prompt.\"\"\"\n\n    @property\n    def model_identifier(self) -&gt; Any:\n        \"\"\"Concatenation of provider and model, used for identifying the model in the prompt. This\n        is commonly used with pydantic_ai to identify the model to use for the agent.\n\n        Example:\n            ```python\n                prompt = Prompt(\n                    model=\"gpt-4o\",\n                    message=\"My prompt variable is ${variable}\",\n                    system_instruction=\"system_instruction\",\n                    provider=\"openai\",\n                )\n                agent = Agent(\n                    prompt.model_identifier, # \"openai:gpt-4o\"\n                    system_instructions=prompt.system_instruction[0].unwrap(),\n                )\n            ```\n        \"\"\"\n\n    @property\n    def model_settings(self) -&gt; ModelSettings:\n        \"\"\"The model settings to use for the prompt.\"\"\"\n\n    @property\n    def message(\n        self,\n    ) -&gt; List[Message]:\n        \"\"\"The user message to use in the prompt.\"\"\"\n\n    @property\n    def system_instruction(self) -&gt; List[Message]:\n        \"\"\"The system message to use in the prompt.\"\"\"\n\n    def save_prompt(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"Save the prompt to a file.\n\n        Args:\n            path (Optional[Path]):\n                The path to save the prompt to. If None, the prompt will be saved to\n                the current working directory.\n        \"\"\"\n\n    @staticmethod\n    def from_path(path: Path) -&gt; \"Prompt\":\n        \"\"\"Load a prompt from a file.\n\n        Args:\n            path (Path):\n                The path to the prompt file.\n\n        Returns:\n            Prompt:\n                The loaded prompt.\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"Prompt\":\n        \"\"\"Validate the model JSON.\n\n        Args:\n            json_string (str):\n                The JSON string to validate.\n        Returns:\n            Prompt:\n                The prompt object.\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model to a JSON string.\n\n        Returns:\n            str:\n                The JSON string.\n        \"\"\"\n\n    def bind(\n        self,\n        name: Optional[str] = None,\n        value: Optional[str | int | float | bool | list] = None,\n        **kwargs: Any,\n    ) -&gt; \"Prompt\":\n        \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n        will return a new Prompt object with the context bound. This will iterate over all user messages.\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str | int | float | bool | list):\n                The value to bind the variable to. Must be a JSON serializable type.\n            **kwargs (Any):\n                Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n        Returns:\n            Prompt:\n                The prompt with the context bound.\n        \"\"\"\n\n    def bind_mut(\n        self,\n        name: Optional[str] = None,\n        value: Optional[str | int | float | bool | list] = None,\n        **kwargs: Any,\n    ) -&gt; \"Prompt\":\n        \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n        will modify the current Prompt object. This will iterate over all user messages.\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str | int | float | bool | list):\n                The value to bind the variable to. Must be a JSON serializable type.\n            **kwargs (Any):\n                Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n        Returns:\n            Prompt:\n                The prompt with the context bound.\n        \"\"\"\n\n    @property\n    def response_json_schema(self) -&gt; Optional[str]:\n        \"\"\"The JSON schema for the response if provided.\"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.message","title":"<code>message</code>  <code>property</code>","text":"<p>The user message to use in the prompt.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.model","title":"<code>model</code>  <code>property</code>","text":"<p>The model to use for the prompt.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.model_identifier","title":"<code>model_identifier</code>  <code>property</code>","text":"<p>Concatenation of provider and model, used for identifying the model in the prompt. This is commonly used with pydantic_ai to identify the model to use for the agent.</p> Example <pre><code>    prompt = Prompt(\n        model=\"gpt-4o\",\n        message=\"My prompt variable is ${variable}\",\n        system_instruction=\"system_instruction\",\n        provider=\"openai\",\n    )\n    agent = Agent(\n        prompt.model_identifier, # \"openai:gpt-4o\"\n        system_instructions=prompt.system_instruction[0].unwrap(),\n    )\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.model_settings","title":"<code>model_settings</code>  <code>property</code>","text":"<p>The model settings to use for the prompt.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.provider","title":"<code>provider</code>  <code>property</code>","text":"<p>The provider to use for the prompt.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.response_json_schema","title":"<code>response_json_schema</code>  <code>property</code>","text":"<p>The JSON schema for the response if provided.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.system_instruction","title":"<code>system_instruction</code>  <code>property</code>","text":"<p>The system message to use in the prompt.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.__init__","title":"<code>__init__(message, model, provider, system_instruction=None, model_settings=None, response_format=None)</code>","text":"<p>Prompt for interacting with an LLM API.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl] | Message | List[Message]</code> <p>The prompt to use.</p> required <code>model</code> <code>str</code> <p>The model to use for the prompt</p> required <code>provider</code> <code>Provider | str</code> <p>The provider to use for the prompt.</p> required <code>system_instruction</code> <code>Optional[str | List[str]]</code> <p>The system prompt to use in the prompt.</p> <code>None</code> <code>model_settings</code> <code>None</code> <p>The model settings to use for the prompt. Defaults to None which means no model settings will be used</p> <code>None</code> <code>response_format</code> <code>Optional[BaseModel | Score]</code> <p>The response format to use for the prompt. This is used for Structured Outputs (https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat). Currently, response_format only support Pydantic BaseModel classes and the PotatoHead Score class. The provided response_format will be parsed into a JSON schema.</p> <code>None</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(\n    self,\n    message: (\n        str\n        | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl]\n        | Message\n        | List[Message]\n        | List[Dict[str, Any]]\n    ),\n    model: str,\n    provider: Provider | str,\n    system_instruction: Optional[str | List[str]] = None,\n    model_settings: Optional[ModelSettings | OpenAIChatSettings | GeminiSettings] = None,\n    response_format: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"Prompt for interacting with an LLM API.\n\n    Args:\n        message (str | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl] | Message | List[Message]):\n            The prompt to use.\n        model (str):\n            The model to use for the prompt\n        provider (Provider | str):\n            The provider to use for the prompt.\n        system_instruction (Optional[str | List[str]]):\n            The system prompt to use in the prompt.\n        model_settings (None):\n            The model settings to use for the prompt.\n            Defaults to None which means no model settings will be used\n        response_format (Optional[BaseModel | Score]):\n            The response format to use for the prompt. This is used for Structured Outputs\n            (https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat).\n            Currently, response_format only support Pydantic BaseModel classes and the PotatoHead Score class.\n            The provided response_format will be parsed into a JSON schema.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.bind","title":"<code>bind(name=None, value=None, **kwargs)</code>","text":"<p>Bind context to a specific variable in the prompt. This is an immutable operation meaning that it will return a new Prompt object with the context bound. This will iterate over all user messages.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> <code>None</code> <code>value</code> <code>str | int | float | bool | list</code> <p>The value to bind the variable to. Must be a JSON serializable type.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The prompt with the context bound.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def bind(\n    self,\n    name: Optional[str] = None,\n    value: Optional[str | int | float | bool | list] = None,\n    **kwargs: Any,\n) -&gt; \"Prompt\":\n    \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n    will return a new Prompt object with the context bound. This will iterate over all user messages.\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str | int | float | bool | list):\n            The value to bind the variable to. Must be a JSON serializable type.\n        **kwargs (Any):\n            Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n    Returns:\n        Prompt:\n            The prompt with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.bind_mut","title":"<code>bind_mut(name=None, value=None, **kwargs)</code>","text":"<p>Bind context to a specific variable in the prompt. This is a mutable operation meaning that it will modify the current Prompt object. This will iterate over all user messages.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> <code>None</code> <code>value</code> <code>str | int | float | bool | list</code> <p>The value to bind the variable to. Must be a JSON serializable type.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The prompt with the context bound.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def bind_mut(\n    self,\n    name: Optional[str] = None,\n    value: Optional[str | int | float | bool | list] = None,\n    **kwargs: Any,\n) -&gt; \"Prompt\":\n    \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n    will modify the current Prompt object. This will iterate over all user messages.\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str | int | float | bool | list):\n            The value to bind the variable to. Must be a JSON serializable type.\n        **kwargs (Any):\n            Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n    Returns:\n        Prompt:\n            The prompt with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.from_path","title":"<code>from_path(path)</code>  <code>staticmethod</code>","text":"<p>Load a prompt from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to the prompt file.</p> required <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The loaded prompt.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>@staticmethod\ndef from_path(path: Path) -&gt; \"Prompt\":\n    \"\"\"Load a prompt from a file.\n\n    Args:\n        path (Path):\n            The path to the prompt file.\n\n    Returns:\n        Prompt:\n            The loaded prompt.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model to a JSON string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The JSON string.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model to a JSON string.\n\n    Returns:\n        str:\n            The JSON string.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate the model JSON.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The JSON string to validate.</p> required <p>Returns:     Prompt:         The prompt object.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"Prompt\":\n    \"\"\"Validate the model JSON.\n\n    Args:\n        json_string (str):\n            The JSON string to validate.\n    Returns:\n        Prompt:\n            The prompt object.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Prompt.save_prompt","title":"<code>save_prompt(path=None)</code>","text":"<p>Save the prompt to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>The path to save the prompt to. If None, the prompt will be saved to the current working directory.</p> <code>None</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def save_prompt(self, path: Optional[Path] = None) -&gt; None:\n    \"\"\"Save the prompt to a file.\n\n    Args:\n        path (Optional[Path]):\n            The path to save the prompt to. If None, the prompt will be saved to\n            the current working directory.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PromptTokenDetails","title":"<code>PromptTokenDetails</code>","text":"<p>Details about the prompt tokens used in a request.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class PromptTokenDetails:\n    \"\"\"Details about the prompt tokens used in a request.\"\"\"\n\n    @property\n    def audio_tokens(self) -&gt; int:\n        \"\"\"The number of audio tokens used in the request.\"\"\"\n\n    @property\n    def cached_tokens(self) -&gt; int:\n        \"\"\"The number of cached tokens used in the request.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PromptTokenDetails.audio_tokens","title":"<code>audio_tokens</code>  <code>property</code>","text":"<p>The number of audio tokens used in the request.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PromptTokenDetails.cached_tokens","title":"<code>cached_tokens</code>  <code>property</code>","text":"<p>The number of cached tokens used in the request.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PyTask","title":"<code>PyTask</code>","text":"<p>Python-specific task interface for Task objects and results</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class PyTask:\n    \"\"\"Python-specific task interface for Task objects and results\"\"\"\n\n    @property\n    def prompt(self) -&gt; Prompt:\n        \"\"\"The prompt to use for the task.\"\"\"\n\n    @property\n    def dependencies(self) -&gt; List[str]:\n        \"\"\"The dependencies of the task.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the task.\"\"\"\n\n    @property\n    def agent_id(self) -&gt; str:\n        \"\"\"The ID of the agent that will execute the task.\"\"\"\n\n    @property\n    def status(self) -&gt; TaskStatus:\n        \"\"\"The status of the task.\"\"\"\n\n    @property\n    def result(self) -&gt; Optional[AgentResponse]:\n        \"\"\"The result of the task if it has been executed, otherwise None.\"\"\"\n\n    def __str__(self) -&gt; str: ...\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PyTask.agent_id","title":"<code>agent_id</code>  <code>property</code>","text":"<p>The ID of the agent that will execute the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PyTask.dependencies","title":"<code>dependencies</code>  <code>property</code>","text":"<p>The dependencies of the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PyTask.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PyTask.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>The prompt to use for the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PyTask.result","title":"<code>result</code>  <code>property</code>","text":"<p>The result of the task if it has been executed, otherwise None.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.PyTask.status","title":"<code>status</code>  <code>property</code>","text":"<p>The status of the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ResponseLogProbs","title":"<code>ResponseLogProbs</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class ResponseLogProbs:\n    @property\n    def token(self) -&gt; str:\n        \"\"\"The token for which the log probabilities are calculated.\"\"\"\n\n    @property\n    def logprob(self) -&gt; float:\n        \"\"\"The log probability of the token.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ResponseLogProbs.logprob","title":"<code>logprob</code>  <code>property</code>","text":"<p>The log probability of the token.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.ResponseLogProbs.token","title":"<code>token</code>  <code>property</code>","text":"<p>The token for which the log probabilities are calculated.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Score","title":"<code>Score</code>","text":"<p>A class representing a score with a score value and a reason. This is typically used as a response type for tasks/prompts that require scoring or evaluation of results.</p> <p>Example: <pre><code>    Prompt(\n        model=\"openai:gpt-4o\",\n        message=\"What is the score of this response?\",\n        system_instruction=\"system_prompt\",\n        response_format=Score,\n    )\n</code></pre></p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Score:\n    \"\"\"A class representing a score with a score value and a reason. This is typically used\n    as a response type for tasks/prompts that require scoring or evaluation of results.\n\n    Example:\n    ```python\n        Prompt(\n            model=\"openai:gpt-4o\",\n            message=\"What is the score of this response?\",\n            system_instruction=\"system_prompt\",\n            response_format=Score,\n        )\n    ```\n    \"\"\"\n\n    @property\n    def score(self) -&gt; int:\n        \"\"\"The score value.\"\"\"\n\n    @property\n    def reason(self) -&gt; str:\n        \"\"\"The reason for the score.\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"Score\":\n        \"\"\"Validate the score JSON.\n\n        Args:\n            json_string (str):\n                The JSON string to validate.\n\n        Returns:\n            Score:\n                The score object.\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Score.reason","title":"<code>reason</code>  <code>property</code>","text":"<p>The reason for the score.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Score.score","title":"<code>score</code>  <code>property</code>","text":"<p>The score value.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Score.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate the score JSON.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The JSON string to validate.</p> required <p>Returns:</p> Name Type Description <code>Score</code> <code>Score</code> <p>The score object.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"Score\":\n    \"\"\"Validate the score JSON.\n\n    Args:\n        json_string (str):\n            The JSON string to validate.\n\n    Returns:\n        Score:\n            The score object.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Task","title":"<code>Task</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Task:\n    def __init__(\n        self,\n        agent_id: str,\n        prompt: Prompt,\n        dependencies: List[str] = [],\n        id: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Create a Task object.\n\n        Args:\n            agent_id (str):\n                The ID of the agent that will execute the task.\n            prompt (Prompt):\n                The prompt to use for the task.\n            dependencies (List[str]):\n                The dependencies of the task.\n            id (Optional[str]):\n                The ID of the task. If None, a random uuid7 will be generated.\n        \"\"\"\n\n    @property\n    def prompt(self) -&gt; Prompt:\n        \"\"\"The prompt to use for the task.\"\"\"\n\n    @property\n    def dependencies(self) -&gt; List[str]:\n        \"\"\"The dependencies of the task.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the task.\"\"\"\n\n    @property\n    def status(self) -&gt; TaskStatus:\n        \"\"\"The status of the task.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Task.dependencies","title":"<code>dependencies</code>  <code>property</code>","text":"<p>The dependencies of the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Task.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Task.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>The prompt to use for the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Task.status","title":"<code>status</code>  <code>property</code>","text":"<p>The status of the task.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Task.__init__","title":"<code>__init__(agent_id, prompt, dependencies=[], id=None)</code>","text":"<p>Create a Task object.</p> <p>Parameters:</p> Name Type Description Default <code>agent_id</code> <code>str</code> <p>The ID of the agent that will execute the task.</p> required <code>prompt</code> <code>Prompt</code> <p>The prompt to use for the task.</p> required <code>dependencies</code> <code>List[str]</code> <p>The dependencies of the task.</p> <code>[]</code> <code>id</code> <code>Optional[str]</code> <p>The ID of the task. If None, a random uuid7 will be generated.</p> <code>None</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(\n    self,\n    agent_id: str,\n    prompt: Prompt,\n    dependencies: List[str] = [],\n    id: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Create a Task object.\n\n    Args:\n        agent_id (str):\n            The ID of the agent that will execute the task.\n        prompt (Prompt):\n            The prompt to use for the task.\n        dependencies (List[str]):\n            The dependencies of the task.\n        id (Optional[str]):\n            The ID of the task. If None, a random uuid7 will be generated.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent","title":"<code>TaskEvent</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class TaskEvent:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the event\"\"\"\n\n    @property\n    def workflow_id(self) -&gt; str:\n        \"\"\"The ID of the workflow that the task is part of.\"\"\"\n\n    @property\n    def task_id(self) -&gt; str:\n        \"\"\"The ID of the task that the event is associated with.\"\"\"\n\n    @property\n    def status(self) -&gt; TaskStatus:\n        \"\"\"The status of the task at the time of the event.\"\"\"\n\n    @property\n    def timestamp(self) -&gt; datetime.datetime:\n        \"\"\"The timestamp of the event. This is the time when the event occurred.\"\"\"\n\n    @property\n    def updated_at(self) -&gt; datetime.datetime:\n        \"\"\"The timestamp of when the event was last updated. This is useful for tracking changes to the event.\"\"\"\n\n    @property\n    def details(self) -&gt; EventDetails:\n        \"\"\"Additional details about the event. This can include information such as error messages or other relevant data.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent.details","title":"<code>details</code>  <code>property</code>","text":"<p>Additional details about the event. This can include information such as error messages or other relevant data.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the event</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent.status","title":"<code>status</code>  <code>property</code>","text":"<p>The status of the task at the time of the event.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent.task_id","title":"<code>task_id</code>  <code>property</code>","text":"<p>The ID of the task that the event is associated with.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>The timestamp of the event. This is the time when the event occurred.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent.updated_at","title":"<code>updated_at</code>  <code>property</code>","text":"<p>The timestamp of when the event was last updated. This is useful for tracking changes to the event.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskEvent.workflow_id","title":"<code>workflow_id</code>  <code>property</code>","text":"<p>The ID of the workflow that the task is part of.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskList","title":"<code>TaskList</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class TaskList:\n    def __init__(self) -&gt; None:\n        \"\"\"Create a TaskList object.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.TaskList.__init__","title":"<code>__init__()</code>","text":"<p>Create a TaskList object.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Create a TaskList object.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Usage","title":"<code>Usage</code>","text":"<p>Usage statistics for a model response.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Usage:\n    \"\"\"Usage statistics for a model response.\"\"\"\n\n    @property\n    def completion_tokens(self) -&gt; int:\n        \"\"\"The number of completion tokens used in the response.\"\"\"\n\n    @property\n    def prompt_tokens(self) -&gt; int:\n        \"\"\"The number of prompt tokens used in the request.\"\"\"\n\n    @property\n    def total_tokens(self) -&gt; int:\n        \"\"\"The total number of tokens used in the request and response.\"\"\"\n\n    @property\n    def completion_tokens_details(self) -&gt; CompletionTokenDetails:\n        \"\"\"Details about the completion tokens used in the response.\"\"\"\n\n    @property\n    def prompt_tokens_details(self) -&gt; \"PromptTokenDetails\":\n        \"\"\"Details about the prompt tokens used in the request.\"\"\"\n\n    @property\n    def finish_reason(self) -&gt; str:\n        \"\"\"The reason why the model stopped generating tokens\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Usage.completion_tokens","title":"<code>completion_tokens</code>  <code>property</code>","text":"<p>The number of completion tokens used in the response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Usage.completion_tokens_details","title":"<code>completion_tokens_details</code>  <code>property</code>","text":"<p>Details about the completion tokens used in the response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Usage.finish_reason","title":"<code>finish_reason</code>  <code>property</code>","text":"<p>The reason why the model stopped generating tokens</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Usage.prompt_tokens","title":"<code>prompt_tokens</code>  <code>property</code>","text":"<p>The number of prompt tokens used in the request.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Usage.prompt_tokens_details","title":"<code>prompt_tokens_details</code>  <code>property</code>","text":"<p>Details about the prompt tokens used in the request.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Usage.total_tokens","title":"<code>total_tokens</code>  <code>property</code>","text":"<p>The total number of tokens used in the request and response.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow","title":"<code>Workflow</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class Workflow:\n    def __init__(self, name: str) -&gt; None:\n        \"\"\"Create a Workflow object.\n\n        Args:\n            name (str):\n                The name of the workflow.\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"The name of the workflow.\"\"\"\n\n    @property\n    def task_list(self) -&gt; TaskList:\n        \"\"\"The tasks in the workflow.\"\"\"\n\n    @property\n    def agents(self) -&gt; Dict[str, Agent]:\n        \"\"\"The agents in the workflow.\"\"\"\n\n    @property\n    def is_workflow(self) -&gt; bool:\n        \"\"\"Returns True if the workflow is a valid workflow, otherwise False.\n        This is used to determine if the workflow can be executed.\n        \"\"\"\n\n    def __workflow__(self) -&gt; str:\n        \"\"\"Returns a string representation of the workflow.\"\"\"\n\n    def add_task_output_types(self, task_output_types: Dict[str, Any]) -&gt; None:\n        \"\"\"Add output types for tasks in the workflow. This is primarily used for\n        when loading a workflow as python objects are not serializable.\n\n        Args:\n            task_output_types (Dict[str, Any]):\n                A dictionary mapping task IDs to their output types.\n                This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n        \"\"\"\n\n    def add_task(self, task: Task, output_type: Optional[Any]) -&gt; None:\n        \"\"\"Add a task to the workflow.\n\n        Args:\n            task (Task):\n                The task to add to the workflow.\n            output_type (Optional[Any]):\n                The output type to use for the task. This can either be a Pydantic `BaseModel` class\n                or a supported potato_head response type such as `Score`.\n        \"\"\"\n\n    def add_tasks(self, tasks: List[Task]) -&gt; None:\n        \"\"\"Add multiple tasks to the workflow.\n\n        Args:\n            tasks (List[Task]):\n                The tasks to add to the workflow.\n        \"\"\"\n\n    def add_agent(self, agent: Agent) -&gt; None:\n        \"\"\"Add an agent to the workflow.\n\n        Args:\n            agent (Agent):\n                The agent to add to the workflow.\n        \"\"\"\n\n    def is_complete(self) -&gt; bool:\n        \"\"\"Check if the workflow is complete.\n\n        Returns:\n            bool:\n                True if the workflow is complete, False otherwise.\n        \"\"\"\n\n    def pending_count(self) -&gt; int:\n        \"\"\"Get the number of pending tasks in the workflow.\n\n        Returns:\n            int:\n                The number of pending tasks in the workflow.\n        \"\"\"\n\n    def execution_plan(self) -&gt; Dict[str, List[str]]:\n        \"\"\"Get the execution plan for the workflow.\n\n        Returns:\n            Dict[str, List[str]]:\n                A dictionary where the keys are task IDs and the values are lists of task IDs\n                that the task depends on.\n        \"\"\"\n\n    def run(\n        self,\n        global_context: Optional[Dict[str, Any]] = None,\n    ) -&gt; \"WorkflowResult\":\n        \"\"\"Run the workflow. This will execute all tasks in the workflow and return when all tasks are complete.\n\n        Args:\n            global_context (Optional[Dict[str, Any]]):\n                A dictionary of global context to bind to the workflow.\n                All tasks in the workflow will have this context bound to them.\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the workflow to a JSON string.\n\n        Returns:\n            str:\n                The JSON string.\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str, output_types: Optional[Dict[str, Any]]) -&gt; \"Workflow\":\n        \"\"\"Load a workflow from a JSON string.\n\n        Args:\n            json_string (str):\n                The JSON string to validate.\n            output_types (Optional[Dict[str, Any]]):\n                A dictionary mapping task IDs to their output types.\n                This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n\n        Returns:\n            Workflow:\n                The workflow object.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.agents","title":"<code>agents</code>  <code>property</code>","text":"<p>The agents in the workflow.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.is_workflow","title":"<code>is_workflow</code>  <code>property</code>","text":"<p>Returns True if the workflow is a valid workflow, otherwise False. This is used to determine if the workflow can be executed.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.name","title":"<code>name</code>  <code>property</code>","text":"<p>The name of the workflow.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.task_list","title":"<code>task_list</code>  <code>property</code>","text":"<p>The tasks in the workflow.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.__init__","title":"<code>__init__(name)</code>","text":"<p>Create a Workflow object.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the workflow.</p> required Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __init__(self, name: str) -&gt; None:\n    \"\"\"Create a Workflow object.\n\n    Args:\n        name (str):\n            The name of the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.__workflow__","title":"<code>__workflow__()</code>","text":"<p>Returns a string representation of the workflow.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def __workflow__(self) -&gt; str:\n    \"\"\"Returns a string representation of the workflow.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.add_agent","title":"<code>add_agent(agent)</code>","text":"<p>Add an agent to the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>Agent</code> <p>The agent to add to the workflow.</p> required Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def add_agent(self, agent: Agent) -&gt; None:\n    \"\"\"Add an agent to the workflow.\n\n    Args:\n        agent (Agent):\n            The agent to add to the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.add_task","title":"<code>add_task(task, output_type)</code>","text":"<p>Add a task to the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>The task to add to the workflow.</p> required <code>output_type</code> <code>Optional[Any]</code> <p>The output type to use for the task. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> required Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def add_task(self, task: Task, output_type: Optional[Any]) -&gt; None:\n    \"\"\"Add a task to the workflow.\n\n    Args:\n        task (Task):\n            The task to add to the workflow.\n        output_type (Optional[Any]):\n            The output type to use for the task. This can either be a Pydantic `BaseModel` class\n            or a supported potato_head response type such as `Score`.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.add_task_output_types","title":"<code>add_task_output_types(task_output_types)</code>","text":"<p>Add output types for tasks in the workflow. This is primarily used for when loading a workflow as python objects are not serializable.</p> <p>Parameters:</p> Name Type Description Default <code>task_output_types</code> <code>Dict[str, Any]</code> <p>A dictionary mapping task IDs to their output types. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> required Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def add_task_output_types(self, task_output_types: Dict[str, Any]) -&gt; None:\n    \"\"\"Add output types for tasks in the workflow. This is primarily used for\n    when loading a workflow as python objects are not serializable.\n\n    Args:\n        task_output_types (Dict[str, Any]):\n            A dictionary mapping task IDs to their output types.\n            This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.add_tasks","title":"<code>add_tasks(tasks)</code>","text":"<p>Add multiple tasks to the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[Task]</code> <p>The tasks to add to the workflow.</p> required Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def add_tasks(self, tasks: List[Task]) -&gt; None:\n    \"\"\"Add multiple tasks to the workflow.\n\n    Args:\n        tasks (List[Task]):\n            The tasks to add to the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.execution_plan","title":"<code>execution_plan()</code>","text":"<p>Get the execution plan for the workflow.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict[str, List[str]]: A dictionary where the keys are task IDs and the values are lists of task IDs that the task depends on.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def execution_plan(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Get the execution plan for the workflow.\n\n    Returns:\n        Dict[str, List[str]]:\n            A dictionary where the keys are task IDs and the values are lists of task IDs\n            that the task depends on.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.is_complete","title":"<code>is_complete()</code>","text":"<p>Check if the workflow is complete.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the workflow is complete, False otherwise.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def is_complete(self) -&gt; bool:\n    \"\"\"Check if the workflow is complete.\n\n    Returns:\n        bool:\n            True if the workflow is complete, False otherwise.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the workflow to a JSON string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The JSON string.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the workflow to a JSON string.\n\n    Returns:\n        str:\n            The JSON string.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.model_validate_json","title":"<code>model_validate_json(json_string, output_types)</code>  <code>staticmethod</code>","text":"<p>Load a workflow from a JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The JSON string to validate.</p> required <code>output_types</code> <code>Optional[Dict[str, Any]]</code> <p>A dictionary mapping task IDs to their output types. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> required <p>Returns:</p> Name Type Description <code>Workflow</code> <code>Workflow</code> <p>The workflow object.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str, output_types: Optional[Dict[str, Any]]) -&gt; \"Workflow\":\n    \"\"\"Load a workflow from a JSON string.\n\n    Args:\n        json_string (str):\n            The JSON string to validate.\n        output_types (Optional[Dict[str, Any]]):\n            A dictionary mapping task IDs to their output types.\n            This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n\n    Returns:\n        Workflow:\n            The workflow object.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.pending_count","title":"<code>pending_count()</code>","text":"<p>Get the number of pending tasks in the workflow.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of pending tasks in the workflow.</p> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def pending_count(self) -&gt; int:\n    \"\"\"Get the number of pending tasks in the workflow.\n\n    Returns:\n        int:\n            The number of pending tasks in the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.Workflow.run","title":"<code>run(global_context=None)</code>","text":"<p>Run the workflow. This will execute all tasks in the workflow and return when all tasks are complete.</p> <p>Parameters:</p> Name Type Description Default <code>global_context</code> <code>Optional[Dict[str, Any]]</code> <p>A dictionary of global context to bind to the workflow. All tasks in the workflow will have this context bound to them.</p> <code>None</code> Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>def run(\n    self,\n    global_context: Optional[Dict[str, Any]] = None,\n) -&gt; \"WorkflowResult\":\n    \"\"\"Run the workflow. This will execute all tasks in the workflow and return when all tasks are complete.\n\n    Args:\n        global_context (Optional[Dict[str, Any]]):\n            A dictionary of global context to bind to the workflow.\n            All tasks in the workflow will have this context bound to them.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.WorkflowResult","title":"<code>WorkflowResult</code>","text":"Source code in <code>python/scouter/llm/_llm.pyi</code> <pre><code>class WorkflowResult:\n    @property\n    def tasks(self) -&gt; Dict[str, PyTask]:\n        \"\"\"The tasks in the workflow result.\"\"\"\n\n    @property\n    def events(self) -&gt; List[TaskEvent]:\n        \"\"\"The events that occurred during the workflow execution. This is a list of dictionaries\n        where each dictionary contains information about the event such as the task ID, status, and timestamp.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.WorkflowResult.events","title":"<code>events</code>  <code>property</code>","text":"<p>The events that occurred during the workflow execution. This is a list of dictionaries where each dictionary contains information about the event such as the task ID, status, and timestamp.</p>"},{"location":"docs/api/llm/llm/#scouter.llm._llm.WorkflowResult.tasks","title":"<code>tasks</code>  <code>property</code>","text":"<p>The tasks in the workflow result.</p>"},{"location":"docs/api/llm/openai/","title":"OpenAI","text":""},{"location":"docs/api/llm/openai/#scouter.llm.openai._openai.OpenAIChatSettings","title":"<code>OpenAIChatSettings</code>","text":"<p>OpenAI chat completion settings configuration.</p> <p>This class provides configuration options for OpenAI chat completions, including model parameters, tool usage, and request options.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; settings = OpenAIChatSettings(\n...     temperature=0.7,\n...     max_completion_tokens=1000,\n...     stream=True\n... )\n&gt;&gt;&gt; settings.temperature = 0.5\n</code></pre> Source code in <code>python/scouter/llm/openai/_openai.pyi</code> <pre><code>class OpenAIChatSettings:\n    \"\"\"OpenAI chat completion settings configuration.\n\n    This class provides configuration options for OpenAI chat completions,\n    including model parameters, tool usage, and request options.\n\n    Examples:\n        &gt;&gt;&gt; settings = OpenAIChatSettings(\n        ...     temperature=0.7,\n        ...     max_completion_tokens=1000,\n        ...     stream=True\n        ... )\n        &gt;&gt;&gt; settings.temperature = 0.5\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        max_completion_tokens: Optional[int] = None,\n        temperature: Optional[float] = None,\n        top_p: Optional[float] = None,\n        top_k: Optional[int] = None,\n        frequency_penalty: Optional[float] = None,\n        timeout: Optional[float] = None,\n        parallel_tool_calls: Optional[bool] = None,\n        seed: Optional[int] = None,\n        logit_bias: Optional[Dict[str, int]] = None,\n        stop_sequences: Optional[List[str]] = None,\n        logprobs: Optional[bool] = None,\n        audio: Optional[AudioParam] = None,\n        metadata: Optional[Dict[str, str]] = None,\n        modalities: Optional[List[str]] = None,\n        n: Optional[int] = None,\n        prediction: Optional[Prediction] = None,\n        presence_penalty: Optional[float] = None,\n        prompt_cache_key: Optional[str] = None,\n        reasoning_effort: Optional[str] = None,\n        safety_identifier: Optional[str] = None,\n        service_tier: Optional[str] = None,\n        store: Optional[bool] = None,\n        stream: Optional[bool] = None,\n        stream_options: Optional[StreamOptions] = None,\n        tool_choice: Optional[ToolChoice] = None,\n        tools: Optional[List[Tool]] = None,\n        top_logprobs: Optional[int] = None,\n        verbosity: Optional[str] = None,\n        extra_body: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"Initialize OpenAI chat settings.\n\n        Args:\n            max_completion_tokens (Optional[int]):\n                Maximum number of tokens to generate\n            temperature (Optional[float]):\n                Sampling temperature (0.0 to 2.0)\n            top_p (Optional[float]):\n                Nucleus sampling parameter\n            top_k (Optional[int]):\n                Top-k sampling parameter\n            frequency_penalty (Optional[float]):\n                Frequency penalty (-2.0 to 2.0)\n            timeout (Optional[float]):\n                Request timeout in seconds\n            parallel_tool_calls (Optional[bool]):\n                Whether to enable parallel tool calls\n            seed (Optional[int]):\n                Random seed for deterministic outputs\n            logit_bias (Optional[Dict[str, int]]):\n                Token bias modifications\n            stop_sequences (Optional[List[str]]):\n                Sequences where generation should stop\n            logprobs (Optional[bool]):\n                Whether to return log probabilities\n            audio (Optional[AudioParam]):\n                Audio generation parameters\n            metadata (Optional[Dict[str, str]]):\n                Additional metadata for the request\n            modalities (Optional[List[str]]):\n                List of modalities to use\n            n (Optional[int]):\n                Number of completions to generate\n            prediction (Optional[Prediction]):\n                Prediction configuration\n            presence_penalty (Optional[float]):\n                Presence penalty (-2.0 to 2.0)\n            prompt_cache_key (Optional[str]):\n                Key for prompt caching\n            reasoning_effort (Optional[str]):\n                Reasoning effort level\n            safety_identifier (Optional[str]):\n                Safety configuration identifier\n            service_tier (Optional[str]):\n                Service tier to use\n            store (Optional[bool]):\n                Whether to store the conversation\n            stream (Optional[bool]):\n                Whether to stream the response\n            stream_options (Optional[StreamOptions]):\n                Streaming configuration options\n            tool_choice (Optional[ToolChoice]):\n                Tool choice configuration\n            tools (Optional[List[Tool]]):\n                Available tools for the model\n            top_logprobs (Optional[int]):\n                Number of top log probabilities to return\n            verbosity (Optional[str]):\n                Verbosity level for the response\n            extra_body (Optional[Any]):\n                Additional request body parameters\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the settings.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/openai/#scouter.llm.openai._openai.OpenAIChatSettings.__init__","title":"<code>__init__(*, max_completion_tokens=None, temperature=None, top_p=None, top_k=None, frequency_penalty=None, timeout=None, parallel_tool_calls=None, seed=None, logit_bias=None, stop_sequences=None, logprobs=None, audio=None, metadata=None, modalities=None, n=None, prediction=None, presence_penalty=None, prompt_cache_key=None, reasoning_effort=None, safety_identifier=None, service_tier=None, store=None, stream=None, stream_options=None, tool_choice=None, tools=None, top_logprobs=None, verbosity=None, extra_body=None)</code>","text":"<p>Initialize OpenAI chat settings.</p> <p>Parameters:</p> Name Type Description Default <code>max_completion_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens to generate</p> <code>None</code> <code>temperature</code> <code>Optional[float]</code> <p>Sampling temperature (0.0 to 2.0)</p> <code>None</code> <code>top_p</code> <code>Optional[float]</code> <p>Nucleus sampling parameter</p> <code>None</code> <code>top_k</code> <code>Optional[int]</code> <p>Top-k sampling parameter</p> <code>None</code> <code>frequency_penalty</code> <code>Optional[float]</code> <p>Frequency penalty (-2.0 to 2.0)</p> <code>None</code> <code>timeout</code> <code>Optional[float]</code> <p>Request timeout in seconds</p> <code>None</code> <code>parallel_tool_calls</code> <code>Optional[bool]</code> <p>Whether to enable parallel tool calls</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed for deterministic outputs</p> <code>None</code> <code>logit_bias</code> <code>Optional[Dict[str, int]]</code> <p>Token bias modifications</p> <code>None</code> <code>stop_sequences</code> <code>Optional[List[str]]</code> <p>Sequences where generation should stop</p> <code>None</code> <code>logprobs</code> <code>Optional[bool]</code> <p>Whether to return log probabilities</p> <code>None</code> <code>audio</code> <code>Optional[AudioParam]</code> <p>Audio generation parameters</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[str, str]]</code> <p>Additional metadata for the request</p> <code>None</code> <code>modalities</code> <code>Optional[List[str]]</code> <p>List of modalities to use</p> <code>None</code> <code>n</code> <code>Optional[int]</code> <p>Number of completions to generate</p> <code>None</code> <code>prediction</code> <code>Optional[Prediction]</code> <p>Prediction configuration</p> <code>None</code> <code>presence_penalty</code> <code>Optional[float]</code> <p>Presence penalty (-2.0 to 2.0)</p> <code>None</code> <code>prompt_cache_key</code> <code>Optional[str]</code> <p>Key for prompt caching</p> <code>None</code> <code>reasoning_effort</code> <code>Optional[str]</code> <p>Reasoning effort level</p> <code>None</code> <code>safety_identifier</code> <code>Optional[str]</code> <p>Safety configuration identifier</p> <code>None</code> <code>service_tier</code> <code>Optional[str]</code> <p>Service tier to use</p> <code>None</code> <code>store</code> <code>Optional[bool]</code> <p>Whether to store the conversation</p> <code>None</code> <code>stream</code> <code>Optional[bool]</code> <p>Whether to stream the response</p> <code>None</code> <code>stream_options</code> <code>Optional[StreamOptions]</code> <p>Streaming configuration options</p> <code>None</code> <code>tool_choice</code> <code>Optional[ToolChoice]</code> <p>Tool choice configuration</p> <code>None</code> <code>tools</code> <code>Optional[List[Tool]]</code> <p>Available tools for the model</p> <code>None</code> <code>top_logprobs</code> <code>Optional[int]</code> <p>Number of top log probabilities to return</p> <code>None</code> <code>verbosity</code> <code>Optional[str]</code> <p>Verbosity level for the response</p> <code>None</code> <code>extra_body</code> <code>Optional[Any]</code> <p>Additional request body parameters</p> <code>None</code> Source code in <code>python/scouter/llm/openai/_openai.pyi</code> <pre><code>def __init__(\n    self,\n    *,\n    max_completion_tokens: Optional[int] = None,\n    temperature: Optional[float] = None,\n    top_p: Optional[float] = None,\n    top_k: Optional[int] = None,\n    frequency_penalty: Optional[float] = None,\n    timeout: Optional[float] = None,\n    parallel_tool_calls: Optional[bool] = None,\n    seed: Optional[int] = None,\n    logit_bias: Optional[Dict[str, int]] = None,\n    stop_sequences: Optional[List[str]] = None,\n    logprobs: Optional[bool] = None,\n    audio: Optional[AudioParam] = None,\n    metadata: Optional[Dict[str, str]] = None,\n    modalities: Optional[List[str]] = None,\n    n: Optional[int] = None,\n    prediction: Optional[Prediction] = None,\n    presence_penalty: Optional[float] = None,\n    prompt_cache_key: Optional[str] = None,\n    reasoning_effort: Optional[str] = None,\n    safety_identifier: Optional[str] = None,\n    service_tier: Optional[str] = None,\n    store: Optional[bool] = None,\n    stream: Optional[bool] = None,\n    stream_options: Optional[StreamOptions] = None,\n    tool_choice: Optional[ToolChoice] = None,\n    tools: Optional[List[Tool]] = None,\n    top_logprobs: Optional[int] = None,\n    verbosity: Optional[str] = None,\n    extra_body: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"Initialize OpenAI chat settings.\n\n    Args:\n        max_completion_tokens (Optional[int]):\n            Maximum number of tokens to generate\n        temperature (Optional[float]):\n            Sampling temperature (0.0 to 2.0)\n        top_p (Optional[float]):\n            Nucleus sampling parameter\n        top_k (Optional[int]):\n            Top-k sampling parameter\n        frequency_penalty (Optional[float]):\n            Frequency penalty (-2.0 to 2.0)\n        timeout (Optional[float]):\n            Request timeout in seconds\n        parallel_tool_calls (Optional[bool]):\n            Whether to enable parallel tool calls\n        seed (Optional[int]):\n            Random seed for deterministic outputs\n        logit_bias (Optional[Dict[str, int]]):\n            Token bias modifications\n        stop_sequences (Optional[List[str]]):\n            Sequences where generation should stop\n        logprobs (Optional[bool]):\n            Whether to return log probabilities\n        audio (Optional[AudioParam]):\n            Audio generation parameters\n        metadata (Optional[Dict[str, str]]):\n            Additional metadata for the request\n        modalities (Optional[List[str]]):\n            List of modalities to use\n        n (Optional[int]):\n            Number of completions to generate\n        prediction (Optional[Prediction]):\n            Prediction configuration\n        presence_penalty (Optional[float]):\n            Presence penalty (-2.0 to 2.0)\n        prompt_cache_key (Optional[str]):\n            Key for prompt caching\n        reasoning_effort (Optional[str]):\n            Reasoning effort level\n        safety_identifier (Optional[str]):\n            Safety configuration identifier\n        service_tier (Optional[str]):\n            Service tier to use\n        store (Optional[bool]):\n            Whether to store the conversation\n        stream (Optional[bool]):\n            Whether to stream the response\n        stream_options (Optional[StreamOptions]):\n            Streaming configuration options\n        tool_choice (Optional[ToolChoice]):\n            Tool choice configuration\n        tools (Optional[List[Tool]]):\n            Available tools for the model\n        top_logprobs (Optional[int]):\n            Number of top log probabilities to return\n        verbosity (Optional[str]):\n            Verbosity level for the response\n        extra_body (Optional[Any]):\n            Additional request body parameters\n    \"\"\"\n</code></pre>"},{"location":"docs/api/llm/openai/#scouter.llm.openai._openai.OpenAIChatSettings.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of the settings.</p> Source code in <code>python/scouter/llm/openai/_openai.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the settings.\"\"\"\n</code></pre>"},{"location":"docs/api/llm/openai/#scouter.llm.openai._openai.OpenAIEmbeddingConfig","title":"<code>OpenAIEmbeddingConfig</code>","text":"<p>OpenAI embedding configuration settings.</p> Source code in <code>python/scouter/llm/openai/_openai.pyi</code> <pre><code>class OpenAIEmbeddingConfig:\n    \"\"\"OpenAI embedding configuration settings.\"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        dimensions: Optional[int] = None,\n        encoding_format: Optional[str] = None,\n        user: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Initialize OpenAI embedding configuration.\n\n        Args:\n            model (str):\n                The embedding model to use.\n            dimensions (Optional[int]):\n                The output dimensionality of the embeddings.\n            encoding_format (Optional[str]):\n                The encoding format to use for the embeddings.\n                Can be either \"float\" or \"base64\".\n            user (Optional[str]):\n                The user ID for the embedding request.\n        \"\"\"\n\n    @property\n    def model(self) -&gt; str: ...\n    @property\n    def dimensions(self) -&gt; Optional[int]: ...\n    @property\n    def encoding_format(self) -&gt; Optional[str]: ...\n    @property\n    def user(self) -&gt; Optional[str]: ...\n</code></pre>"},{"location":"docs/api/llm/openai/#scouter.llm.openai._openai.OpenAIEmbeddingConfig.__init__","title":"<code>__init__(model, dimensions=None, encoding_format=None, user=None)</code>","text":"<p>Initialize OpenAI embedding configuration.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The embedding model to use.</p> required <code>dimensions</code> <code>Optional[int]</code> <p>The output dimensionality of the embeddings.</p> <code>None</code> <code>encoding_format</code> <code>Optional[str]</code> <p>The encoding format to use for the embeddings. Can be either \"float\" or \"base64\".</p> <code>None</code> <code>user</code> <code>Optional[str]</code> <p>The user ID for the embedding request.</p> <code>None</code> Source code in <code>python/scouter/llm/openai/_openai.pyi</code> <pre><code>def __init__(\n    self,\n    model: str,\n    dimensions: Optional[int] = None,\n    encoding_format: Optional[str] = None,\n    user: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Initialize OpenAI embedding configuration.\n\n    Args:\n        model (str):\n            The embedding model to use.\n        dimensions (Optional[int]):\n            The output dimensionality of the embeddings.\n        encoding_format (Optional[str]):\n            The encoding format to use for the embeddings.\n            Can be either \"float\" or \"base64\".\n        user (Optional[str]):\n            The user ID for the embedding request.\n    \"\"\"\n</code></pre>"},{"location":"docs/monitoring/","title":"Overview","text":"<p>Out of the box, Scouter provides functionality to create drift profiles and perform real-time monitoring. </p>"},{"location":"docs/monitoring/#drift-profiles","title":"Drift Profiles","text":"<p>Drift profiles are created using the <code>Drifter</code> class, which provides a simple interface for creating and managing drift profiles. The <code>Drifter</code> class supports multiple drift detection methods, including: - Population Stability Index (PSI) \u2013 A standard approach for detecting distribution shifts. - Statistical Process Control (SPC) \u2013 A proven method widely used in manufacturing and operations. - Custom Metrics \u2013 Define your own drift detection method to match your specific needs.</p>"},{"location":"docs/monitoring/#scouter-queues","title":"Scouter Queues","text":"<p>Scouter Queues allow you to capture the data being sent to your model during inference. This captured data is then sent to the Scouter server, where it will be stored and used in the future to detect any potential drift and notify you and your team based on your configuration.</p>"},{"location":"docs/monitoring/#alerting","title":"Alerting","text":"<p>Based on the drift profile you configure, a scheduled job periodically checks for data drift using the captured inference data. If drift is detected, an alert is triggered and sent via your preferred method to notify the relevant team.</p>"},{"location":"docs/monitoring/#supported-data-types","title":"Supported Data Types","text":"<p>Scouter supports a variety of data types, including: - Pandas DataFrames: Scouter can handle Pandas DataFrames, making it easy to integrate with existing data processing pipelines. - Numpy Arrays: Out of the box support for 2D arrays. - Polars DataFrames: For users who prefer Polars, Scouter supports this data format as well, allowing for efficient data processing and analysis. - Custom Metrics: Scouter allows you to define your own custom metrics for drift detection, giving you the flexibility to tailor the monitoring process to your specific needs.</p>"},{"location":"docs/monitoring/#getting-started-client-quickstart","title":"Getting Started (Client Quickstart)","text":""},{"location":"docs/monitoring/#installation","title":"Installation","text":"<pre><code>pip install scouter-ml\n</code></pre>"},{"location":"docs/monitoring/#configuration","title":"Configuration","text":"<p>To register profiles and use Scouter queues, set the Scouter server URI as an environment variable:</p> <pre><code>export SCOUTER_SERVER_URI=your_SCOUTER_SERVER_URI\n</code></pre>"},{"location":"docs/monitoring/#creating-a-drift-profile","title":"Creating a Drift Profile","text":"<p>To detect model drift, we first need to create a drift profile using your baseline dataset, this is typically done at the time of training your model.</p> <p>The following example is taken directly from the examples/psi/api.py file in the Scouter repository. It demonstrates how to create a drift profile using the <code>Drifter</code> class and register it with the Scouter server and then use the Scouter queues to send data to the Scouter server for drift detection.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport uvicorn\nfrom fastapi import FastAPI, Request\nfrom pydantic import BaseModel\nfrom scouter import (  # type: ignore\n    CommonCrons,\n    Drifter,\n    HTTPConfig,\n    PsiAlertConfig,\n    PsiDriftConfig,\n    ScouterClient,\n    ScouterQueue,\n)\nfrom scouter.util import FeatureMixin\n\nclass Response(BaseModel):\n    message: str\n\n\nclass PredictRequest(BaseModel, FeatureMixin): #(1)\n    feature_1: float\n    feature_2: float\n    feature_3: float\n\n\ndef generate_data() -&gt; pd.DataFrame:\n    \"\"\"Create a fake data frame for testing\"\"\"\n    n = 10_000\n    X_train = np.random.normal(-4, 2.0, size=(n, 4))\n    col_names = []\n    for i in range(0, X_train.shape[1]):\n        col_names.append(f\"feature_{i}\")\n    X = pd.DataFrame(X_train, columns=col_names)\n    return X\n\n\ndef create_psi_profile() -&gt; Path:\n    \"\"\"Create a PSI profile\n\n    The following example shows how to:\n\n    1. Instantiate the Drifter class and connect to the Scouter client\n    2. Create a fake dataframe\n    3. Create a PSI profile using the Drifter class\n    4. Register the profile with the Scouter client and set it as active\n    (this will tell the server to schedule the profile for alerting)\n    5. Save the profile to a json file (we'll use this to load it in the api for demo purposes)\n    \"\"\"\n    # Drifter class for creating drift profiles\n    drifter = Drifter() #(2)\n\n    # Simple client to register drift profiles (scouter client must be running)\n    client = ScouterClient() #(3)\n\n    # create fake data\n    data = generate_data()\n\n    # create psi configuration\n    psi_config = PsiDriftConfig( #(4)\n        space=\"scouter\",\n        name=\"psi_test\",\n        version=\"0.0.1\",\n        alert_config=PsiAlertConfig(\n            schedule=CommonCrons.Every6Hours,\n            features_to_monitor=[\n                \"feature_1\",\n                \"feature_2\",\n            ],\n        ),\n    )\n\n    # create psi profile\n    psi_profile = drifter.create_drift_profile(data, psi_config)\n\n    # register profile\n    client.register_profile(profile=psi_profile, set_active=True) #(5)\n\n    # save profile to json (for example purposes)\n    return psi_profile.save_to_json()\n\n\nif __name__ == \"__main__\":\n    # Create a PSI profile and get its path\n    profile_path = create_psi_profile()\n\n\n    # Setup api lifespan\n    @asynccontextmanager\n    async def lifespan(fast_app: FastAPI):\n\n        fast_app.state.queue = ScouterQueue.from_path( #(6)\n            path={\"psi\": profile_path},\n            transport_config=HTTPConfig(), #(7)\n        )\n        yield\n\n        # Shutdown the queue\n        fast_app.state.queue.shutdown()\n        fast_app.state.queue = None\n\n    app = FastAPI(lifespan=lifespan)\n\n    @app.post(\"/predict\", response_model=Response)\n    async def predict(request: Request, payload: PredictRequest) -&gt; Response:\n        request.app.state.queue[\"psi\"].insert(payload.to_features()) #(8)\n        return Response(message=\"success\")\n\n    uvicorn.run(app, host=\"0.0.0.0\", port=8888)\n</code></pre> <ol> <li>The <code>FeatureMixin</code> class is used to convert the input data into a <code>Features</code> object that is inserted into the Scouter queue. You can also do this manually by using the <code>Feature</code> and <code>Features</code> classes directly. Refer to the Scouter Queues section for more information</li> <li>The <code>Drifter</code> class is used to create drift profiles</li> <li>The <code>ScouterClient</code> class is used to register the drift profile with the Scouter server</li> <li><code>DriftConfig</code> is a required argument to all drift types. It helps define how the drift profile is created and how the drift detection job is scheduled. Refer to the DriftConfig section for more information</li> <li>The <code>register_profile</code> method is used to register the drift profile with the Scouter server. The <code>set_active</code> argument tells the server to schedule the drift detection job based on the configuration in the <code>DriftConfig</code> object. If set to <code>False</code>, the profile will not be scheduled for drift detection. You can always set this to true later</li> <li>Here we setup the ScouterQueue within our FastApi lifespan and attach it to the application's state. You can load and set as many queues as you like. Each profile is given an alias that you can use to access later on</li> <li>The <code>HTTPConfig</code> class sets the transport configuration to send direct HTTP requests to the Scouter server from items in the queue. In production, you may want to use a different transport configuration, such as <code>KafkaConfig</code> or <code>RabbitMQ</code>, depending on your needs.</li> <li>Insert data into the ScouterQueue using a specific alias</li> </ol> <p>Success</p> <p>That's it! While there's a few details to iron out, you now know how to configure real-time monitoring and alerting using Scouter. Please see refer to the rest of the documentation for more details on how to use Scouter and the Scouter server. If you have any questions, please feel free to reach out to us on Slack or create an issue on GitHub.</p>"},{"location":"docs/monitoring/inference/","title":"Inference","text":"<p>After you've saved and registered your profile with the Scouter Server, you're all set to go with real-time model monitoring. All you need is your profile, a ScouterQueue and some data to send. Below is a simple example showing how you can integrate Scouter into a <code>FastAPI</code> application.</p>"},{"location":"docs/monitoring/inference/#loading-your-profile","title":"Loading your Profile","text":"<p>It is expected that you have already created and registered your profile with the Scouter Server. In addition, your profile should either be saved or downloaded to a local path. The ScouterQueue will load the profile from the local path and use it to setup the background queue and producer.</p>"},{"location":"docs/monitoring/inference/#setting-up-the-scouterqueue","title":"Setting up the ScouterQueue","text":"<p>In this step we will attach the ScouterQueue to the FastAPI app state via the lifespan</p> <pre><code>from contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom scouter import ScouterQueue, HTTPConfig\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    app.state.queue = ScouterQueue.from_path( #(1)\n        path={\"psi\": profile_path},\n        transport_config=HTTPConfig(), #(2)\n    )\n    yield\n    # Shutdown the queue\n    fast_app.state.queue.shutdown() #(3)\n    fast_app.state.queue = None\n\napp = FastAPI(lifespan=lifespan)\n</code></pre> <ol> <li>The ScouterQueue <code>from_path</code> staticmethod expect's a dictionary of paths where keys are aliases and values are paths to the local profile. </li> <li>The transport config is used to setup the specific transport producer for the queue (kafka, rabbitmq, etc.). In this case we are using the HTTP transport config.</li> <li>The shutdown method will stop the background queue and producer. It is important to call this method when the application is shutting down to ensure that all events are processed and sent to the Scouter server.</li> </ol>"},{"location":"docs/monitoring/inference/#available-transport-configs","title":"Available Transport Configs","text":"<p>In addition to the HTTP transport config, Scouter also support the following transport/producers:</p> <ul> <li>Kafka: <code>from_path(path, transport_config=KafkaConfig())</code></li> <li>RabbitMQ: <code>from_path(path, transport_config=RabbitMQConfig())</code></li> <li>Redis: <code>from_path(path, transport_config=RedisConfig())</code></li> </ul> <p>For more information on how to configure these transports, please refer to the queue documentation and the server documentation.</p>"},{"location":"docs/monitoring/inference/#inserting-data","title":"Inserting data","text":"<p>There are a variety of ways in which you can configure your api to send data. In this case, we're going to keep it simple and add the insertion logic in with the api prediction route.</p> <pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom scouter import Features, Feature\n\n\nclass Response(BaseModel):\n    value: float\n\n\nclass PredictRequest(BaseModel):\n    feature_1: float\n    feature_2: float\n    feature_3: float\n\n    def to_features(self, target: float) -&gt; Features:  # (1)\n        model = self.model_dump()\n        model[\"target\"] = target\n        return Features(features=model)\n\n\napp = FastAPI(lifespan=lifespan)\n\n@app.post(\"/predict\", response_model=Response)\nasync def predict(request: Request, payload: PredictRequest) -&gt; Response:\n    #... existing prediction logic\n    request.app.state.queue[\"psi\"].insert(payload.to_features()) #(2)\n    return Response(value=prediction)\n</code></pre> <ol> <li>The queue expects either a <code>Features</code> object or a <code>Metrics</code> object (when inserting custom metrics). In this case we are manually implementing the features logic by passing a dictionary to the <code>Features</code> class. There are a variety of ways to create features, which are shown in the <code>Feature</code> docstring. You can also use the <code>FeatureMixin</code> to automatically convert a Pydantic model to features. <pre><code>from scouter import FeatureMixin\nclass PredictRequest(FeatureMixin, BaseModel):\n    feature_1: float\n    feature_2: float\n    feature_3: float\n\nrequest.to_features()\n</code></pre></li> <li>Access the queue from the app state using the assigned alias and insert</li> </ol> <p>In the above logic, we access the queue via the <code>request.app.state</code> and the corresponding alias (\"psi\"). We then call the insert method with the features we want to send to the Scouter server. This is a simple exchange of data, as the ScouterQueue will pass the features through a channel to a background worker that is running independently on a separate thread. In our benchmarks, inserting data is extremely fast (&lt;1us), so you can expect minimal overhead in your API response time. However, if you want to move the insertion logic to a background task, you can use the <code>BackgroundTasks</code> from FastAPI to do so.</p>"},{"location":"docs/monitoring/inference/#what-queues-expect","title":"What Queues Expect","text":"<p>As you can see in the above example, the <code>ScouterQueue</code> expects either a <code>Features</code> object, a <code>Metrics</code> object or an <code>LLMRecord</code> object. Both of these objects are designed to be flexible and can be created in a variety of ways. </p>"},{"location":"docs/monitoring/inference/#when-to-use-features-vs-metrics-vs-llmrecord","title":"When to use <code>Features</code> vs <code>Metrics</code> vs <code>LLMRecord</code>?","text":"<code>type</code> <code>Description</code> <code>Associated Profiles</code> <code>Features</code> Used for PSI and SPC monitoring, where you are monitoring 'features' <code>PsiDriftProfile</code>, <code>SpcDriftProfile</code> <code>Metrics</code> Used for custom metrics that you want to monitor <code>CustomMetricProfile</code> <code>LLMRecord</code> Used for LLM monitoring, where you are monitoring the performance of LLM services <code>LLMDriftProfile</code>"},{"location":"docs/monitoring/inference/#how-to-create-features-metrics-and-llmrecord-objects","title":"How to create <code>Features</code>, <code>Metrics</code> and <code>LLMRecord</code> objects?","text":""},{"location":"docs/monitoring/inference/#features","title":"Features","text":"<p>The <code>Features</code> object can be created from a dictionary of key-value pairs, where the keys are the feature names (string) and the values are the feature values (float, int, string). Note - these types should correspond to the types that were inferred while creating a drift profile (i.e. if <code>feat1</code> was inferred as a <code>float</code>, then you should pass a <code>float</code> value for <code>feat1</code> when inserting data). You can also create a <code>Features</code> object by passing a list of <code>Feature</code> objects, where each <code>Feature</code> object represents a single feature with a name and value.</p> <p>Using a list of features</p> <pre><code>from scouter.queue import Features, Feature\n# Passing a list of features\nfeatures = Features(\n    features=[\n        Feature(\"feature_1\", 1),\n        Feature(\"feature_2\", 2.0),\n        Feature(\"feature_3\", \"value\"),\n    ]\n)\n</code></pre> <p>Using a dictionary (pydantic model)</p> <pre><code># Passing a dictionary (pydantic model) of features\nclass MyFeatures(BaseModel):\n    feature1: int\n    feature2: float\n    feature3: str\n\nmy_features = MyFeatures(\n    feature1=1,\n    feature2=2.0,\n    feature3=\"value\",\n)\n\nfeatures = Features(my_features.model_dump())\n</code></pre> <p>Using a FeatureMixin</p> <p><code>Scouter</code> also comes with a <code>FeatureMixin</code>, that can be used to automatically convert a Pydantic model to a <code>Features</code> object. This is useful when you want to send the entire model as features without manually creating the <code>Features</code> object</p> <pre><code>from scouter.util import FeatureMixin\n\nclass MyFeatures(FeatureMixin, BaseModel):\n    feature1: int\n    feature2: float\n    feature3: str\n\nmy_features = MyFeatures(\n    feature1=1,\n    feature2=2.0,\n    feature3=\"value\",\n)\n\nfeatures = my_features.to_features()\n</code></pre>"},{"location":"docs/monitoring/inference/#metrics","title":"Metrics","text":"<p><code>Metrics</code> also follow a similar pattern to <code>Features</code>.</p> <p>Using a list of metrics</p> <pre><code>from scouter.queue import Metrics, Metric\n\n# Supply a list of metrics\nMetrics(\n    [\n        Metric(\"metric_1\", 1),\n        Metric(\"metric_2\", 2.0),\n    ]\n)\n</code></pre> <p>Using a dictionary (pydantic model)</p> <p>When using a dictionary, the key should match the metric name in your profile.</p> <pre><code>from scouter.queue import Metrics, Metric\nfrom pydantic import BaseModel  \n\nclass MyMetrics(BaseModel):\n    mae: int\n    mape: float\n\nmy_metrics = MyMetrics(mae=1, mape=2.0)\nMetrics(my_metrics.model_dump())\n</code></pre>"},{"location":"docs/monitoring/inference/#llmrecord","title":"LLMRecord","text":"<p>The <code>LLMRecord</code> object is used to send LLM records to the Scouter server for monitoring. It contains the input, response, and context of the LLM service. You can create an <code>LLMRecord</code> object by passing the input, response, and context as parameters.</p> <p>Note</p> <p>Input, response and context should be serializable types (i.e. strings, numbers, lists, dictionaries). If you want to send more complex objects, you can use the <code>to_json</code> method to convert them to a JSON string. In addition, all of these fields will be injected into your LLM metric prompts on the server side, so if your prompts expect <code>${input}</code> or <code>${response}</code>, you can use these fields to populate them.</p> <pre><code>record = LLMRecord(\n    input=\"What is the capital of France?\",\n    response=\"Paris is the capital of France.\",\n    context={\"foo\": \"bar\"}\n)\n</code></pre> <p>LLMRecord Arguments</p> <code>Argument</code> <code>Type</code> <code>Description</code> <code>input</code> <code>str | int | float | dict | list</code> The input to the LLM service. This could be something like a user question <code>response</code> <code>str | int | float | dict | list</code> The response from the LLM service. This could be something like the answer to the user question <code>context</code> <code>Dict[str, Any]</code> The context for the LLM service (if any). The keys should map to the context variables in your LLM metric prompts <code>prompt</code> <code>Prompt str | int | float | dict | list</code> The prompt used to generate the response"},{"location":"docs/monitoring/inference/#ready-to-go","title":"Ready to go!","text":"<p>And that's all you need to get started for real-time model monitoring with Scouter. For more technical discussion on the ScouterQueue, please refer to the ScouterQueue documentation.</p>"},{"location":"docs/monitoring/custom/quickstart/","title":"Overview","text":"<p>While Scouter comes packed with powerful drift detection tools, we understand that no single solution fits every use case. You might find yourself needing a drift detection method that isn\u2019t natively supported\u2014don\u2019t worry, we\u2019ve got you covered. Scouter provides built-in support for custom metric tracking, allowing you to define your own metrics and baseline values. We\u2019ll handle the heavy lifting of saving inference data and detecting drift over time.</p> <ul> <li>Setting up a Custom drift profile</li> <li>Configuring real-time notifications for model drift detection</li> <li>Using scouter queues and fastapi integrations allowing you to send data to scouter server at the time of model inference</li> </ul>"},{"location":"docs/monitoring/custom/quickstart/#creating-a-drift-profile","title":"Creating a Drift Profile","text":"<p>To detect model drift, we first need to create a drift profile using your baseline dataset, this is typically done at the time of training your model. <pre><code>from scouter.alert import SlackDispatchConfig\nfrom scouter.client import ScouterClient\nfrom scouter.drift import Drifter, CustomMetric, CustomMetricDriftConfig, CommonCrons\nfrom sklearn import datasets\n\nif __name__ == \"__main__\":\n\n    # Define custom metrics\n    metrics = [  #(1)\n        CustomMetric(\n            name=\"mae\",\n            value=1,\n            alert_threshold=AlertThreshold.Outside,\n            alert_threshold_value=0.5,\n        ),\n        CustomMetric(\n            name=\"mape\",\n            value=2,\n            alert_threshold=AlertThreshold.Outside,\n            alert_threshold_value=0.5,\n        ),\n    ]\n\n    # Define the drift config\n    drift_config = CustomMetricDriftConfig(\n        space=\"scouter\",\n        name=\"custom_metric\",\n        version=semver,\n        sample_size=25,  #(2)\n        alert_config=CustomMetricAlertConfig(\n            schedule=\"*/5 * * * * *\",  # every 5 minutes\n        ),\n    )\n\n    # Drifter class for creating drift profiles\n    drifter = Drifter()\n\n    profile = drifter.create_drift_profile(data=metrics, config=drift_config)\n    client.register_profile(profile)\n</code></pre></p> <ol> <li>Instead of data, you provide the Drifter with a list of <code>CustomMetric</code> objects. Each metric has a name, value, and alert threshold.</li> <li>The sample size is the number of samples to use for drift detection. This is the number of samples that will be used to calculate the drift score. The default value is 25, but you can adjust this based on your needs. It is generally recommended to not use a sample size of less than 25, as drift alerting is computed from the sampled value. If sample size is 1, an alert will be triggered every time the value surpasses the defined threshold.</li> </ol>"},{"location":"docs/monitoring/custom/quickstart/#custommetric","title":"CustomMetric","text":"<p>The <code>CustomMetric</code> class is used to define a custom metric for drift detection. It contains the following properties:</p> Argument Type Description <code>name</code> string The name to assign to the metric <code>value</code> float The value of the metric <code>alert_threshold</code> <code>AlertThreshold</code> The condition used to determine when an alert should be triggered. <code>alert_threshold_value</code> float (optional) The threshold value for the alert. This is the value that will be used to determine if an alert should be triggered."},{"location":"docs/monitoring/custom/quickstart/#alertthreshold","title":"AlertThreshold","text":"<p>Enum representing different alert conditions for monitoring metrics.</p> Enum Value Description <code>Below</code> Indicates that an alert should be triggered when the metric is below a threshold <code>Above</code> Indicates that an alert should be triggered when the metric is above a threshold. <code>Outside</code> Indicates that an alert should be triggered when the metric is outside a specified range."},{"location":"docs/monitoring/custom/quickstart/#custommetricdriftconfig","title":"CustomMetricDriftConfig","text":"<p>The <code>CustomMetricDriftConfig</code> class is used to define the configuration for a custom metric drift profile. It contains the following properties:</p> Argument Type Description <code>space</code> string The name of the model space <code>name</code> string The name of the model <code>version</code> string The version of the model <code>sample_size</code> int The number of samples to use for drift detection. This is the number of samples that will be used to calculate the drift score. The default value is 25, but you can adjust this based on your needs. It is generally recommended to not use a sample size of less than 25, as drift alerting is computed from the sampled value. If sample size is 1, an alert will be triggered every time the value surpasses the defined threshold <code>alert_config</code> <code>CustomMetricAlertConfig</code> The alert configuration for the drift profile. This is an instance of the <code>CustomMetricAlertConfig</code> class."},{"location":"docs/monitoring/custom/quickstart/#custommetricalertconfig","title":"CustomMetricAlertConfig","text":"<p>The <code>CustomMetricAlertConfig</code> class is used to define the alert configuration for a custom metric drift profile. It contains the following properties:</p> Argument Type Description <code>schedule</code> string The schedule for the drift detection job. This is a cron expression that defines when the job should run. <code>dispatch_config</code> <code>DispatchConfig</code> The dispatch configuration for the drift profile. This is an instance of the <code>DispatchConfig</code> class."},{"location":"docs/monitoring/llm/evaluation/","title":"Evaluation","text":""},{"location":"docs/monitoring/llm/evaluation/#llm-evaluation","title":"LLM Evaluation","text":"<p>In addition to real-time or online monitoring of LLMs, Scouter provides you with tools to run offline LLM evaluations. This is is often useful for when you (1) want to compare and benchmark various prompts, and (2) you want to evaluate different versions of prompts and LLM services that you may already be using in production.</p>"},{"location":"docs/monitoring/llm/evaluation/#getting-started","title":"Getting Started","text":"<p>To run and LLM evaluation, you will first need to obtain your evaluation data and construct a list of <code>LLMEvalRecord</code> instances. Each <code>LLMEvalRecord</code> represents a single evaluation instance, containing the metadata you wish to evaluate. Note, we have left this intentionally flexible so that you can evaluate any type of metadata you wish.</p>"},{"location":"docs/monitoring/llm/evaluation/#example-evaluating-a-prompt-for-query-reformulation","title":"Example: Evaluating a Prompt for Query Reformulation","text":""},{"location":"docs/monitoring/llm/evaluation/#step-1-example-workflow-setup","title":"Step 1: Example Workflow Setup","text":"<p>Let's say you have a use case where you want to evaluate how well a prompt reformulates user search queries and how relevant the answers are to the original user query. The prompts used for this task are shown below and does the following things:</p> <ul> <li>Takes a bound parameter <code>${user_query}</code> which is the original user search query.</li> <li>Reformulates the query to be more feature-rich and keyword-dense, while preserving the original</li> <li>Takes the <code>${reformulated_query}</code> and injects it into an answer prompt to get an answer.</li> </ul> <p><pre><code>reformulation_prompt = Prompt(\n    message=(\n        \"You are an expert at query reformulation. Your task is to take a user's original search query \"\n        \"and rewrite it to be more feature-rich and keyword-dense, so it better aligns with the user's intent \"\n        \"and improves search results.\\n\\n\"\n        \"Guidelines:\\n\"\n        \"- Expand abbreviations and clarify ambiguous terms.\\n\"\n        \"- Add relevant synonyms, related concepts, and specific features.\\n\"\n        \"- Preserve the original intent, but make the query more explicit and comprehensive.\\n\"\n        \"- Do not change the meaning of the query.\\n\"\n        \"- Return only the reformulated query.\\n\\n\"\n        \"User Query:\\n\"\n        \"${user_query}\\n\\n\"\n        \"Reformulated Query:\"\n    ),\n    model=\"gemini-2.5-flash-lite\",\n    provider=\"gemini\",\n    model_settings=GeminiSettings(\n        generation_config=GenerationConfig(\n            thinking_config=ThinkingConfig(thinking_budget=0),\n        ),\n    ),\n)\n\nanswer_prompt = Prompt(\n    message=(\"You are a helpful assistant that can answer any question!\" \n             \"Please provide an answer to the following user query.\\n\\n\"\n             \"Question:\\n\"\n             \"${reformulated_query}\\n\\n\"\n             \"Answer:\"\n            ),\n    model=\"gemini-2.5-flash-lite\",\n    provider=\"gemini\",\n)\n</code></pre> The overall flow for using the prompt would look like the following:</p> <pre><code>flowchart TD\nsubgraph A[\"Question Answer Agent\"]\n    direction LR\n    User_Query --&gt; Reformulation_Prompt\n    Reformulation_Prompt --&gt; Reformulated_Query\n    Reformulated_Query --&gt; Answer_Prompt\n    Answer_Prompt --&gt; Answer\nend</code></pre>"},{"location":"docs/monitoring/llm/evaluation/#step-2-create-an-llmevalmetric-to-evaluate-the-prompt","title":"Step 2: Create an <code>LLMEvalMetric</code> to Evaluate the Prompt","text":"<p>Now say you want to (1) evaluate how well the prompt reformulates user queries into better-structured queries and (2) how relevant the provided answer is to the user input. In this scenario, imagine you already have a dataset of user queries, their reformulated queries and the returned answers (this could be from an experiment you ran in production). Now, to evaluate the prompts and Agent, you would create a list of <code>LLMEvalRecords</code> containing the <code>user_query</code>, <code>reformulated_query</code> and <code>answer</code> context as well as an <code>LLMEvalMetric</code> that defines how you want to evaluate the prompt using an <code>LLM as a judge</code> workflow.</p> <p>Note: The <code>LLMEvalMetric</code> differs from the <code>LLMDriftMetric</code> in that the <code>LLMDriftMetric</code> is used when setting up real-time LLM monitoring and requires more configuration and setup. For offline evaluations, the <code>LLMEvalMetric</code> is simpler to use and requires less configuration. It requires only a name and eval prompt.</p> <pre><code>from scouter.llm import Prompt, Score\nfrom scouter.evaluate import LLMEvalMetric, LLMEvalRecord, evaluate_llm\n\nreformulation_eval_prompt = Prompt(\n    message=(\n        \"You are an expert evaluator of search query relevance. \\n\"\n        \"You will be given a user query and its reformulated version. \\n\"\n        \"You task is to assess how relevant the reformulated query is to the information needs of the user. \\n\"\n        \"Consider the following criteria:\\n\"\n        \"- Does the query contain relevant keywords and concepts?\\n\"\n        \"- Is the query clear and unambiguous?\\n\"\n        \"- Does the query adequately express the user's intent?\\n\\n\"\n        \"Provide your evaluation as a JSON object with the following attributes:\\n\"\n        \"- score: An integer from 1 (poor) to 5 (excellent) indicating the overall reformulation score.\\n\"\n        \"- reason: A brief explanation for your score.\\n\\n\"\n        \"Format your response as:\\n\"\n        \"{\\n\"\n        '  \"score\": &lt;integer 1-5&gt;,\\n'\n        '  \"reason\": \"&lt;your explanation&gt;\"\\n'\n        \"}\\n\\n\"\n        \"User Query:\\n\"\n        \"${user_query}\\n\\n\" #(1)\n        \"Reformulated Query:\\n\"\n        \"${reformulated_query}\\n\\n\" #(2)\n        \"Evaluation:\"\n    ),\n    model=\"gemini-2.5-flash-lite-preview-06-17\",\n    provider=\"gemini\",\n    response_format=Score, #(3)\n)\n\nasnwer_eval_prompt = Prompt(\n    message=(\n        \"You are an expert evaluator of answer relevance. \\n\"\n        \"You will be given a user query and an answer generated from a reformulated version of that query. \\n\"\n        \"Your task is to assess how relevant and accurate the answer is in addressing the user's original information needs. \\n\"\n        \"Consider the following criteria:\\n\"\n        \"- Does the answer directly address the user's query?\\n\"\n        \"- Is the information provided accurate and reliable?\\n\"\n        \"- Is the answer clear, concise, and well-structured?\\n\\n\"\n        \"Provide your evaluation as a JSON object with the following attributes:\\n\"\n        \"- score: An integer from 1 (poor) to 5 (excellent) indicating the overall answer quality score.\\n\"\n        \"- reason: A brief explanation for your score.\\n\\n\"\n        \"Format your response as:\\n\"\n        \"{\\n\"\n        '  \"score\": &lt;integer 1-5&gt;,\\n'\n        '  \"reason\": \"&lt;your explanation&gt;\"\\n'\n        \"}\\n\\n\"\n        \"User Query:\\n\"\n        \"${user_query}\\n\\n\" #(1)\n        \"Answer:\\n\"\n        \"${answer}\\n\\n\" #(2)\n        \"Evaluation:\"\n    ),\n    model=\"gemini-2.5-flash-lite-preview-06-17\",\n    provider=\"gemini\",\n    response_format=Score, #(3)\n)\n\neval_metrics = [\n    LLMEvalMetric(\n        name=\"reformulation_quality\",\n        prompt=reformulation_eval_prompt,\n    ),\n    LLMEvalMetric(\n        name=\"answer_relevance\",\n        prompt=answer_eval_prompt,\n    )\n]\n\nflight_record = LLMEvalRecord(\n    context={\n        \"user_query\": \"cheap flights to Europe next month\",\n        \"reformulated_query\": \"affordable airfare to Europe next month\",\n        \"answer\": \"I found several options for cheap flights to Europe next month.\"\n    },\n    id=\"record_1\",\n)\n\ntechnical_record = LLMEvalRecord(\n    context={\n        \"user_query\": \"why won't my laptop turn on\",\n        \"reformulated_query\": \"laptop computer won't boot power issues troubleshooting steps hardware failure battery power supply diagnostic repair\",\n        \"answer\": \"If your laptop won't turn on, try these troubleshooting steps: 1) Check power connections - ensure the charger is plugged in securely and the power outlet works. 2) Remove the battery (if removable) and hold the power button for 30 seconds, then reconnect and try again. 3) Look for LED indicators on the laptop or charger. 4) Try a different power adapter if available. 5) Check for physical damage to ports or cables. 6) If these steps don't work, the issue may be hardware-related (motherboard, RAM, or hard drive failure) requiring professional repair\"\n    },\n    id=\"record_2\",\n)\n\ncooking_record = LLMEvalRecord(\n    context={\n        \"user_query\": \"easy dinner recipes with chicken\",\n        \"reformulated_query\": \"simple quick chicken dinner recipes healthy family-friendly weeknight meals\",\n        \"answer\": \"Here are some easy chicken dinner recipes: 1) Baked Lemon Garlic Chicken - Marinate chicken breasts in lemon juice, garlic, olive oil, and herbs, then bake until cooked through. 2) One-Pan Chicken and Veggies - Saut\u00e9 chicken pieces with mixed vegetables in a skillet with olive oil and your favorite seasonings. 3) Chicken Stir-Fry - Cook sliced chicken with colorful veggies in a wok or large pan, adding soy sauce and ginger for flavor. 4) Chicken Tacos - Season shredded chicken with taco seasoning and serve in tortillas with your favorite toppings. 5) Chicken Alfredo Pasta - Toss cooked pasta with grilled chicken and a creamy Alfredo sauce for a quick and satisfying meal.\"\n    },\n    id=\"record_3\",\n)\n\nrecords = [flight_record, technical_record, cooking_record]\n\nresults = evaluate_llm(\n    records=records,\n    metrics=eval_metrics,\n)\n</code></pre> <ol> <li><code>${user_query}</code> is a bound parameter that will be populated from the <code>LLMEvalRecord</code> context</li> <li><code>${reformulated_query}</code> is a bound parameter that will be populated from the <code>LLMEvalRecord</code> context</li> <li><code>LLMEvalMetrics</code> currently require all prompts to return a <code>Score</code> object. This is critical as the score object allows us to extract a numerical score for evaluation.</li> </ol>"},{"location":"docs/monitoring/llm/evaluation/#eval-metric-flow","title":"Eval Metric Flow","text":"<p>As you can see from the above example, the overall flow for evaluating an LLM using <code>LLMEvalMetric</code> is as follows:</p> <ol> <li>Define the evaluation metrics using <code>LLMEvalMetric</code>, providing the necessary prompts for each metric.</li> <li>Create <code>LLMEvalRecord</code> instances for each record you want to evaluate, populating the context with the relevant information that will be injected into the prompts.</li> <li>Call the <code>evaluate_llm</code> function with the records and metrics to obtain the evaluation results.</li> </ol>"},{"location":"docs/monitoring/llm/evaluation/#step-3-evaluation-configuration","title":"Step 3: Evaluation Configuration","text":"<p>By default, the above <code>evaulate_llm</code> function will execute without any additional configuration. It will extract the defined metric prompts, bind the context variables from each record, and execute the prompts against the defined LLM provider and model and then extract the scores. However, if you want a more robust evaluation, we recommend you provide an <code>EvaluationConfig</code> configured to your needs.</p> <p>EvaluationConfig allows you to customize the evaluation process in several ways:</p> <ul> <li>Specify which fields from the <code>LLMEvalRecord</code> context should be embedded. These embedding will be used to calculate means and similarity scores.</li> <li>Indicate whether you want to compute similarity scores between the embedded fields.</li> <li>Enable clustering to identify patterns in the evaluation results.</li> <li>Enable histogram computations to generate histograms for all numerical fields.</li> </ul> <p>EvaluationConfig documentation</p> <pre><code>from scouter.evaluate import EvaluationConfig\nfrom scouter.llm.openai import OpenAIEmbeddingConfig\nfrom scouter.llm import Embedder, Provider\n\n#(previous code)...\n\nembedder = Embedder( #(1)\n    Provider.OpenAI,\n    config=OpenAIEmbeddingConfig(\n        model=\"text-embedding-3-small\",\n        dimensions=512,\n    ),\n)\n\nresults = evaluate_llm(\n    records=records,\n    metrics=eval_metrics,\n    config=EvaluationConfig( #(2)\n        embedder=embedder,\n        embedding_targets=[\"user_query\", \"answer\"], #(3)\n        compute_similarity=True, #(4)\n        cluster=True, #(5)\n        compute_histograms=True, #(6)\n    ),\n)\n</code></pre> <ol> <li>Create an <code>Embedder</code> instance to generate embeddings for the evaluation records. This is useful for similarity computations and clustering. Here, we are using OpenAI's embedding model.</li> <li>Pass an <code>EvaluationConfig</code> instance to the <code>evaluate_llm</code> function to customize the evaluation process.</li> <li>Specify which fields from the <code>LLMEvalRecord</code> context should be embedded. In this case, we are embedding both the <code>user_query</code> and <code>answer</code>. These embedding will be used to calculate means and similarity scores.</li> <li>Indicate that we want to compute similarity scores between the embedded fields.</li> <li>If clustering is enabled, Scouter will execute a dbscan with all numerical values (scores, similarity scores, embeddings etc.) to identify clusters of similar records. This can help identify patterns in the evaluation results</li> <li>Enable histogram computations to generate histograms for all numerical fields</li> </ol>"},{"location":"docs/monitoring/llm/evaluation/#step-4-analyzing-the-results","title":"Step 4: Analyzing the Results","text":"<p>The results object (<code>LLMEvalResults</code>) returned from the <code>evaluate_llm</code> function contains a wealth of information about the evaluation. You can access individual record results, overall metrics, and any errors that occurred during the evaluation process.</p> <pre><code># Assess individual record results\nresults = evaluate_llm(...)\n\n\nrecord1_metrics = results[\"record_1\"].metric\nprint(f\"Record 1 Reformulation Quality Score: {record1_metrics['reformulation_quality'].score}\")\nprint(f\"Record 1 Reformulation Quality Reason: {record1_metrics['reformulation_quality'].reason}\")\n\nprint(f\"Record 1 Answer Relevance Score: {record1_metrics['answer_relevance'].score}\")\nprint(f\"Record 1 Answer Relevance Reason: {record1_metrics['answer_relevance'].reason}\")\n\n# Create a dataframe for easier analysis\ndf = results.to_dataframe() # pandas\nprint(df.head())\n\ndf = results.to_dataframe(polars=True) # polars\nprint(df.head())\n\n# Access histograms\nhistograms = results.histograms\nfor field, histogram in histograms.items():\n    print(f\"Histogram for {field}: {histogram}\")\n</code></pre> <p>Please refer to the LLMEvalResults documentation for more details on how to work with the results object.</p>"},{"location":"docs/monitoring/llm/overview/","title":"Overview","text":""},{"location":"docs/monitoring/llm/overview/#creating-llm-drift-profiles","title":"Creating LLM Drift Profiles","text":"<p>LLM Drift Profiles in Scouter provide a robust and flexible way to monitor the performance and stability of Large Language Models (LLMs) over time. By defining custom metrics, prompts, and workflows, you can detect drift and set up alerting tailored to your use case.</p>"},{"location":"docs/monitoring/llm/overview/#what-is-an-llm-drift-profile","title":"What is an LLM Drift Profile?","text":"<p>An LLM Drift Profile encapsulates:</p> <ul> <li>The configuration for drift monitoring (LLMDriftConfig)</li> <li>The metrics to evaluate (LLMDriftMetric)</li> <li>Optionally, a custom workflow (Workflow) for advanced scenarios</li> </ul> <p>This profile can be used to monitor LLMs for changes in output quality, relevance, or any other custom metric you define.</p>"},{"location":"docs/monitoring/llm/overview/#steps-to-create-an-llm-drift-profile","title":"Steps to Create an LLM Drift Profile","text":""},{"location":"docs/monitoring/llm/overview/#1-define-llm-metrics","title":"1. Define LLM Metrics","text":"<p>The <code>LLMDriftMetric</code> class represents a single metric for LLM drift detection.</p> <p>Arguments:</p> Argument Type Required Description <code>name</code> <code>str</code> Yes Name of the metric (e.g., \"accuracy\", \"relevance\") <code>value</code> <code>float</code> Yes Baseline value for the metric <code>alert_threshold</code> <code>AlertThreshold</code> Yes Condition for triggering an alert (e.g., <code>Above</code>, <code>Below</code>) <code>alert_threshold_value</code> <code>float</code>, optional No Threshold value for alerting <code>prompt</code> <code>Prompt</code>, optional No Prompt associated with the metric (required if not using workflow) <p>Example: <pre><code>from scouter.llm import AlertThreshold, Prompt, Score\nfrom scouter.drift import LLMDriftMetric\n\nreformulation_prompt = (\n    \"You are an expert evaluator of search query reformulations. \"\n    \"Given the original user query and its reformulated version, your task is to assess how well the reformulation improves the query. \"\n    \"Consider the following criteria:\\n\"\n    \"- Does the reformulation make the query more explicit and comprehensive?\\n\"\n    \"- Are relevant synonyms, related concepts, or specific features added?\\n\"\n    \"- Is the original intent preserved without changing the meaning?\\n\"\n    \"- Is the reformulation clear and unambiguous?\\n\\n\"\n    \"Provide your evaluation as a JSON object with the following attributes:\\n\"\n    \"- score: An integer from 1 (poor) to 5 (excellent) indicating the overall quality of the reformulation.\\n\"\n    \"- reason: A brief explanation for your score.\\n\\n\"\n    \"Format your response as:\\n\"\n    \"{\\n\"\n    '  \"score\": &lt;integer 1-5&gt;,\\n'\n    '  \"reason\": \"&lt;your explanation&gt;\"\\n'\n    \"}\\n\\n\"\n    \"Original Query:\\n\"\n    \"${user_query}\\n\\n\"\n    \"Reformulated Query:\\n\"\n    \"${response}\\n\\n\"\n    \"Evaluation:\"\n)\n\nmetric = LLMDriftMetric(\n    name=\"reformulation\",\n    value=5.0,\n    alert_threshold=AlertThreshold.Below,\n    alert_threshold_value=2.0,  # Alert if score is below 3 or less (5.0 - 2.0)\n    prompt=Prompt(\n        message=reformulation_prompt,\n        model=\"gpt-4o\",\n        provider=\"openai\",\n        response_format=Score\n    )\n)\n</code></pre></p>"},{"location":"docs/monitoring/llm/overview/#prompt-requirements","title":"Prompt Requirements","text":"<p>When defining prompts for LLM metrics, ensure they include the following:</p> <ul> <li> <p>Input Parameters: </p> <ul> <li>Each prompt must include at least one named parameter. An error will be raised if the prompt does not include a parameter (e.g., <code>${input}</code>, <code>${response}</code>, <code>${user_query}</code>). This is what you will insert into the <code>ScouterQueue</code> at runtime as context and will be bound to your prompt.</li> <li>Named parameters must follow the <code>${parameter_name}</code> format.</li> </ul> </li> <li> <p>Score Response Format:     All evaluation prompts must use the <code>Score</code> response format. The prompt should instruct the model to return a JSON object matching the <code>Score</code> schema:</p> <ul> <li><code>score</code>: An integer value (typically 1\u20135) representing the evaluation result.</li> <li><code>reason</code>: A brief explanation for the score.</li> </ul> </li> </ul>"},{"location":"docs/monitoring/llm/overview/#2-create-an-llm-drift-config","title":"2. Create an LLM Drift Config","text":"<p>The <code>LLMDriftConfig</code> class defines the configuration for drift monitoring.</p> <p>Arguments:</p> Argument Type Required Description <code>space</code> <code>str</code> No Model space (default: <code>\"__missing__\"</code>) <code>name</code> <code>str</code> No Model name (default: <code>\"__missing__\"</code>) <code>version</code> <code>str</code> No Model version (default: <code>\"0.1.0\"</code>) <code>sample_rate</code> <code>int</code> No Sample rate for drift detection (default: 5 (1 out of 5)) <code>alert_config</code> <code>LLMAlertConfig</code> No Alert configuration <p>Example: <pre><code>from scouter.llm import LLMDriftConfig\n\nconfig = LLMDriftConfig(\n    space=\"my_space\",\n    name=\"my_model\",\n    version=\"1.0.0\",\n    sample_rate=10  #(1)\n)\n</code></pre></p> <ol> <li>The <code>sample_rate</code> determines how often drift events are recorded. A value of 10 means 1 out of every 10 requests will be recorded for drift monitoring.</li> </ol>"},{"location":"docs/monitoring/llm/overview/#3-optional-define-a-custom-workflow","title":"3. (Optional) Define a Custom Workflow","text":"<p>For advanced scenarios, you can provide a custom <code>Workflow</code> to evaluate complex pipelines or multi-step tasks.</p> <ul> <li>All metric names must match the final task names in the workflow.</li> <li>Final tasks must use the <code>Score</code> response type.</li> <li>You will still need to define metrics, but you will not need to provide prompts for each metric if you use a workflow, as it is expected the workflow will contains the necessary prompts.</li> </ul> <p>Example: <pre><code>from scouter.llm import Workflow, Task, Score, Agent, Prompt\nfrom scouter.drift import LLMDriftConfig, LLMDriftMetric\n\n# Relevance prompt\nrelevance_prompt = Prompt(\n    message=(\n        \"Given the following input and response, rate the relevance of the response to the input on a scale of 1 to 5.\\n\\n\"\n        \"Input: ${input}\\n\" # (1)\n        \"Response: ${response}\\n\\n\"\n        \"Provide a brief reason for your rating.\"\n    ),\n    system_instruction=\"You are a helpful assistant that evaluates relevance.\",\n    response_format=Score\n)\n\n# Coherence prompt\ncoherence_prompt = Prompt(\n    message=(\n        \"Given the following response, rate its coherence and logical consistency on a scale of 1 to 5.\\n\\n\"\n        \"Response: ${response}\\n\\n\"\n        \"Provide a brief reason for your rating.\"\n    ),\n    system_instruction=\"You are a helpful assistant that evaluates coherence.\",\n    response_format=Score\n)\n\nfinal_eval_prompt = Prompt(\n    message=(\n        \"Given the previous relevance and coherence scores for a model response, \"\n        \"determine if the response should PASS or FAIL quality control.\\n\\n\"\n        \"If both scores are 4 or higher, return a score of 1 and reason 'Pass'. \"\n        \"If either score is below 4, return a score of 0 and reason 'Fail'.\\n\\n\"\n        \"Respond with a JSON object matching the Score schema.\"\n    ),\n    system_instruction=\"You are a strict evaluator that only passes high-quality responses.\",\n    response_format=Score\n)\n\nopen_agent = Agent(\"openai\")\nworkflow = Workflow(name=\"test_workflow\")\n\nworkflow.add_agent(open_agent)\nworkflow.add_tasks( # (2)\n    [\n        Task(\n            prompt=relevance_prompt,\n            agent_id=open_agent.id,\n            id=\"relevance\",\n        ),\n        Task(\n            prompt=coherence_prompt,\n            agent_id=open_agent.id,\n            id=\"coherence\",\n        ),\n        Task(\n            prompt=final_eval_prompt,\n            agent_id=open_agent.id,\n            id=\"final_evaluation\",\n            depends_on=[\"relevance\", \"coherence\"],\n        ),\n    ]\n)\n\nmetric = LLMDriftMetric( # (3)\n    name=\"final_evaluation\",\n    value=1,\n    alert_threshold=AlertThreshold.Below,\n)\n\nprofile = LLMDriftProfile(\n    config=LLMDriftConfig(),\n    workflow=workflow,\n    metrics=[metric],\n)\n</code></pre></p> <ol> <li>The <code>${input}</code> and <code>${response}</code> variables will be fed in by Scouter when you record a drift event. Evaluation prompts must include at least one named parameter. <code>${input}</code> and <code>${response}</code>. It could easily be <code>${user_query}</code> or similar, depending on your use case. The important part is that the first tasks in the workflow must include these parameters, so they can be evaluated against the model's output.</li> <li>Here we are creating a directed graph of tasks. The <code>relevance</code> and <code>coherence</code> tasks are the first tasks, and the <code>final_evaluation</code> task depends on them. The final task must return a <code>Score</code> type, which is used to extract the metric value on the Scouter server.</li> <li>The metric name must match the final task name in the workflow. The <code>value</code> is the baseline score for this metric, and the <code>alert_threshold</code> defines when an alert should be triggered based on the metric's value.</li> </ol>"},{"location":"docs/monitoring/llm/overview/#4-create-the-llm-drift-profile","title":"4. Create the LLM Drift Profile","text":"<p>Use the <code>LLMDriftProfile</code> class to create a drift profile by combining your config, metrics, and (optionally) workflow.</p> <p>Arguments:</p> Argument Type Required Description <code>config</code> <code>LLMDriftConfig</code> Yes Drift configuration <code>metrics</code> <code>List[LLMDriftMetric]</code> Yes List of metrics to monitor <code>workflow</code> <code>Workflow</code>, optional No Custom workflow for advanced evaluation (optional) <p>Example (metrics only): <pre><code>from scouter.llm import LLMDriftProfile\n\nprofile = LLMDriftProfile(\n    config=config,\n    metrics=[metric]\n)\n</code></pre></p>"},{"location":"docs/monitoring/llm/overview/#prompt-requirements-noted-above","title":"Prompt Requirements (noted above)","text":"<p>When creating prompts for LLM Drift Profiles and workflows, the following requirements must be met:</p> <ul> <li>Input Parameters: </li> </ul> <p>-Each evaluation prompt must include at least one named parameter that will be injected at runtime.  </p> <ul> <li> <p>Score Response Format:   All evaluation prompts must use the <code>Score</code> response format. The prompt should instruct the model to return a JSON object matching the <code>Score</code> schema:</p> <ul> <li><code>score</code>: An integer value (typically 1\u20135) representing the evaluation result.</li> <li><code>reason</code>: A brief explanation for the score.</li> </ul> </li> <li> <p>Workflow Tasks: </p> <ul> <li>The first tasks in a workflow must use prompts that include a named parameter.</li> <li>The final tasks in a workflow must return a <code>Score</code> object as their response.</li> </ul> </li> </ul> <p>Example Score JSON: <pre><code>{\n  \"score\": 5,\n  \"reason\": \"The response is highly relevant and coherent.\"\n}\n</code></pre></p>"},{"location":"docs/monitoring/llm/overview/#inserting-llm-drift-data","title":"Inserting LLM Drift Data","text":"<p>For a general detailed guide on the <code>ScouterQueue</code>, and how to insert data for real-time monitoring in your service, please refer to the Inference documentation. While the general insertion logic is similar for all drift types, there are a few specific considerations for LLM drift profiles.</p>"},{"location":"docs/monitoring/llm/overview/#llm-drift-data-insertion","title":"LLM Drift Data Insertion","text":"<p>To insert data for LLM drift profiles, you first create an <code>LLMRecord</code>, which takes the following parameters:</p> Argument Type Required Description <code>context</code> <code>dict</code> or pydantic <code>BaseModel</code> Yes Context to provide to your metrics During evaluation, this will be injected into your metric workflow and bound to the named parameters within your prompts. So if you're evaluation prompts expect ${user_query}, you would pass {\"user_query\": \"my user query\"} as context. <code>prompt</code> Prompt or<code>str</code> No Optional prompt configuration associated with this record. Can be a <code>Potatohead</code> Prompt or a JSON-serializable type. We don't current use this field for drift detection, but we may add analysis capabilities in the future. <p>Example: <pre><code>from scouter.queue import LLMRecord\n\nrecord = LLMRecord(\n    context={\"input\": \"How do I find live music in my area?\"}\n)\n\n# insert into the ScouterQueue\nqueue[\"my_llm_service\"].insert(record)\n</code></pre></p>"},{"location":"docs/monitoring/llm/overview/#how-are-the-metrics-calculated","title":"How are the metrics calculated?","text":"<p>Scouter is designed to evaluate LLM metrics asynchronously on the server, ensuring your application's performance is not impacted. Here\u2019s how the process works:</p> <ol> <li> <p>Record Ingestion:    When you insert an <code>LLMRecord</code>, it is sent to the Scouter server.</p> </li> <li> <p>Profile Retrieval:    Upon receiving the record, the server retrieves the associated drift profile, which specifies the metrics and workflow to execute.</p> </li> <li> <p>Prompt Injection &amp; Workflow Execution:    The server injects the <code>context</code> from the <code>LLMRecord</code> into the prompts defined in the workflow. It then runs the workflow according to your configuration.</p> </li> <li> <p>Metric Extraction:    After executing the workflow, the server extracts the <code>Score</code> object from the relevant tasks as defined by your <code>LLMDriftMetric</code>s.</p> </li> <li> <p>Result Storage &amp; Alerting:    The results are stored in the llm metric table. The system then periodically polls these results based on your alerting schedule. If a score falls below the defined threshold, Scouter triggers an alert and sends it to your configured alerting channel.</p> </li> </ol> <p>This asynchronous evaluation ensures that metric calculation is robust and does not interfere with your service\u2019s real-time performance.</p>"},{"location":"docs/monitoring/llm/overview/#architecture-overview","title":"Architecture Overview","text":""},{"location":"docs/monitoring/llm/overview/#what-scouter-doesnt-do-for-llms","title":"What Scouter Doesn't Do for LLMs","text":"<p>Scouter is meant to be a generic monitoring system for LLM services, meaning we provide you with the basic building blocks to define how you want to monitor your services, so that you can integrate it with any framework. In addition, Scouter is not an observability platform, so it does not provide things like LLM tracing. In our experience, tracing != monitoring, and is primarily used for debugging purposes. If you want to trace your LLM services (or any general service), we recommend using a tool like OpenTelemetry or similar.</p>"},{"location":"docs/monitoring/llm/overview/#examples","title":"Examples","text":"<p>Check out the examples directory for more detailed examples of creating and using LLM Drift Profiles in Scouter.</p>"},{"location":"docs/monitoring/psi/drift_config/","title":"Drift Config","text":""},{"location":"docs/monitoring/psi/drift_config/#psi-drift-configuration","title":"PSI Drift Configuration","text":"<p>All models that create a <code>PsiDriftProfile</code> will require a <code>PsiDriftConfig</code> object.</p> <pre><code>from scouter.alert import PsiAlertConfig\nfrom scouter.drift import PsiDriftConfig\n\nPsiDriftConfig(\n    name=\"wine_model\",\n    space=\"wine_model\",\n    version=\"0.0.1\",\n    alert_config=PsiAlertConfig()\n    categorical_features = [\"feature_1\", \"feature_2\"],  # (1)\n)\n</code></pre> <ol> <li>To ensure accurate PSI calculations, categorical features must be explicitly specified.</li> </ol>"},{"location":"docs/monitoring/psi/drift_config/#parameters","title":"Parameters","text":"Parameter Type Description Example name <code>str</code> The name of the model or dataset being monitored. Defaults to '__missing__' if not provided. <code>config.name \u2192 \"wine_model\"</code> space <code>str</code> The space where the model or dataset is stored. Defaults to '__missing__' if not provided. <code>config.space \u2192 \"wine_model\"</code> version <code>str</code> The version of the model or dataset being monitored. Defaults to '0.0.1' if not provided. <code>config.version \u2192 \"0.0.1\"</code> alert_config <code>PsiAlertConfig</code> Configuration for alerting when drift is detected. Defaults to the default implementation of PsiAlertConfig if not provided. <code>config.alert_config \u2192 *Instance of PsiAlertConfig*</code> targets <code>list[str]</code> List of target features, typically the dependent variable(s). <code>config.targets \u2192 [\"churn\"]</code> config_path <code>Optional[Path]</code> Path to a pre existing PsiDriftConfig. Defaults to None if not provided <code>config.config_path \u2192 Path(\"/configs/drift.yaml\")</code> categorical_features <code>Optional[list[str]]</code> To ensure accurate PSI calculations, categorical features must be explicitly specified. <code>config.categorical_features \u2192 [\"feature_1\", \"feature_2\"]</code>"},{"location":"docs/monitoring/psi/drift_config/#properties","title":"Properties","text":"Property Type Description Example <code>name</code> <code>str</code> The name of the model or dataset being monitored. <code>config.name</code> \u2192 <code>\"wine_model\"</code> <code>space</code> <code>str</code> The space where the model or dataset is stored. <code>config.space</code> \u2192 <code>\"wine_model\"</code> <code>version</code> <code>str</code> The version of the model or dataset being monitored. <code>config.version</code> \u2192 <code>\"0.0.1\"</code> <code>feature_map</code> <code>FeatureMap</code> When a non-numeric covariate is detected, each unique value is assigned a corresponding numeric value. This mapping is represented by feature_map. <code>config.feature_map</code> \u2192 <code>Instance of FeatureMap</code> <code>targets</code> <code>list[str]</code> List of target features, typically the dependent variable(s). <code>config.targets</code> \u2192 <code>label</code> <code>alert_config</code> <code>PsiAlertConfig</code> Configuration for alerting when drift is detected. <code>config.alert_config</code> \u2192 <code>Instance of PsiAlertConfig</code> <code>drift_type</code> <code>DriftType</code> Type of drift profile. <code>config.drift_type</code> \u2192 <code>DriftType.Psi</code> <code>categorical_features</code> <code>Optional[list[str]]</code> List of categorical features <code>config.categorical_features \u2192 [\"feature_1\", \"feature_2\"]</code>"},{"location":"docs/monitoring/psi/drift_config/#methods","title":"Methods","text":""},{"location":"docs/monitoring/psi/drift_config/#load_from_json_file-static-method","title":"<code>load_from_json_file()</code> (static method)","text":"<p>Loads a <code>PsiDriftConfig</code> instance from a JSON file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (<code>Path</code>): The path to the JSON configuration file. This is required to locate and read the configuration file from disk.</li> </ul> </li> <li>Returns: A <code>PsiDriftConfig</code> instance.</li> <li>Return Type: <code>PsiDriftConfig</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_config/#model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Serializes the <code>PsiDriftConfig</code> instance to a JSON string.</p> <ul> <li>Parameters: None</li> <li>Returns: A JSON string representation of the instance.</li> <li>Return Type: <code>str</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_config/#update_config_args","title":"<code>update_config_args()</code>","text":"<p>Updates the configuration of the instance with new values.</p> <ul> <li>Parameters:<ul> <li><code>space</code> (<code>Optional[str]</code>): The space name, if updating.</li> <li><code>name</code> (<code>Optional[str]</code>): The new name for the configuration, if provided.</li> <li><code>version</code> (<code>Optional[str]</code>): The version to set, if specified.</li> <li><code>targets</code> (<code>Optional[List[str]]</code>): A list of target identifiers, if updating.</li> <li><code>alert_config</code> (<code>Optional[PsiAlertConfig]</code>): The alert configuration, if provided.</li> </ul> </li> <li>Returns: <code>None</code></li> <li>Return Type: <code>None</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_config/#alert-configuration","title":"Alert Configuration","text":"<p>An <code>AlertConfig</code> can also be provided to the <code>PsiDriftConfig</code> to specify how you and your team want to be alerted in the event of model drift. The <code>PsiAlertConfig</code> class allows you to configure the alerting mechanism, including the dispatch method (e.g., Slack, OpsGenie), the schedule for drift detection job and even what kind of threshold to use.</p> <pre><code>from scouter.alert import PsiAlertConfig, SlackDispatchConfig\nfrom scouter.types import CommonCrons\n\nPsiAlertConfig(\n    dispatch_config=SlackDispatchConfig(channel='my-team-channel'),\n    schedule=CommonCrons.Every6Hours, # (1)\n    features_to_monitor=['feature_1', 'feature_2', ...],\n    threshold=PsiNormalThreshold() # (2)\n)\n</code></pre> <ol> <li>Scouter comes with a set of built-in cron schedules that you can use to configure the schedule for your drift detection job. You can also specify your own custom cron schedule if needed.</li> <li>With the <code>PsiAlertConfig</code>, you can also specify a threshold config that accepts <code>PsiNormalThreshold</code>, <code>PsiChiSquareThreshold</code>, or <code>PsiFixedThreshold</code>.</li> </ol>"},{"location":"docs/monitoring/psi/drift_config/#parameters_1","title":"Parameters","text":"Parameter Type Description Example dispatch_config <code>SlackDispatchConfig | OpsGenieDispatchConfig                                                        | None</code> An optional dispatch configuration used to configure how alerts are routed, if None is provided a default internal dispatch type of Console will be used to log alerts to the conosole of the scouter server. <code>config.dispatch_config -&gt; SlackDispatchConfig()</code> schedule <code>str                 | CommonCrons                                                                   | None</code> Schedule to run drift detection job. Defaults to daily at midnigh. You can use the builtin CommonCron options or specify your own custom cron. <code>config.schedule \u2192 CommonCrons.Every6Hours</code> features_to_monitor <code>list[str]</code> List of features to monitor. Defaults to empty list, which means all features <code>config.features_to_monitor \u2192 ['feature_1, feature_2, ...']</code> threshold <code>PsiNormalThreshold | PsiChiSquareThreshold | PsiFixedThreshold</code> The type of threshold to use. <code>PsiNormalThreshold()</code>"},{"location":"docs/monitoring/psi/drift_config/#threshold-types","title":"Threshold Types","text":"<p>Out of the box, Scouter provides three types of threshold that can be use with PSI</p>"},{"location":"docs/monitoring/psi/drift_config/#psifixedthreshold","title":"PsiFixedThreshold","text":"<p><code>PsiFixedThreshold</code> is the simplest threshold type that allows you to specify a fixed threshold value for drift detection. In a lot of industry settings, this is typically set between 0.10 and 0.25, but you can adjust it based on your specific use case. Note: This is not the most scientific way to detect drift, but it is offered given that most users of PSI are familiar with this approach. However, we recommend using the <code>PsiNormalThreshold</code> or <code>PsiChiSquareThreshold</code> for more robust drift detection.</p>"},{"location":"docs/monitoring/psi/drift_config/#psinormalthreshold","title":"PsiNormalThreshold","text":"<p><code>PsiNormalThreshold</code> uses the asymptotic normal distribution of PSI to calculate the threshold for drift detection. This is determined at runtime during drift detection and is based on the over sample size of observed bin data.</p> <p>The basic premise is that the PSI statistic can be approximated by a normal distribution when there's no drift. Thus, using an observed sample size and pre-defined significance level, we can calculate the critical value for PSI and compare is against the observed PSI value providing us a more dynamic and scientific way to detect drift.</p>"},{"location":"docs/monitoring/psi/drift_config/#psichisquarethreshold","title":"PsiChiSquareThreshold","text":"<p><code>PsiChiSquareThreshold</code> is similar to <code>PsiNormalThreshold</code>, but uses the Chi-Square distribution to calculate the threshold for drift detection.</p>"},{"location":"docs/monitoring/psi/drift_profile/","title":"PSI Drift Profile","text":"<p>The <code>PsiDriftProfile</code> is the returned object from the <code>create_drift_profile</code> function found on the <code>Drifter</code> object. This object contains the drift profile for your data and is used as the source of truth for drift detection.</p>"},{"location":"docs/monitoring/psi/drift_profile/#properties","title":"Properties","text":"Property Type Description Example <code>scouter_version</code> <code>str</code> The version of scouter that was used to create your PSI drift profile. <code>psi_profile.scouter_version</code> \u2192 <code>\"1.0.0\"</code> <code>features</code> <code>dict[str, PsiFeatureDriftProfile]</code> A mapping of feature names to their respective drift profiles. <code>psi_profile.features['feature_name']</code> \u2192 <code>*Instance of PsiFeatureDriftProfile*</code> <code>config</code> <code>PsiDriftConfig</code> The drift config defined at the time of profile creationg. <code>psi_profile.config</code> \u2192 <code>*Instance of PsiDriftConfig*</code>"},{"location":"docs/monitoring/psi/drift_profile/#methods","title":"Methods","text":""},{"location":"docs/monitoring/psi/drift_profile/#model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Serializes the <code>PsiDriftProfile</code> instance to a JSON string.</p> <ul> <li>Parameters: None</li> <li>Returns: A JSON string representation of the instance.</li> <li>Return Type: <code>str</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_profile/#model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of the drift profile.</p> <ul> <li>Parameters: None</li> <li>Returns: <code>dict[str, Any]</code> representation of the instance.</li> <li>Return Type: <code>dict[str, Any]</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_profile/#save_to_json","title":"<code>save_to_json()</code>","text":"<p>Save drift profile to json file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (<code>Optional[Path]</code>): Optional path to save the drift profile. If None, outputs to drift_profile.json.</li> </ul> </li> <li>Returns: <code>None</code></li> <li>Return Type: <code>None</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_profile/#update_config_args","title":"<code>update_config_args()</code>","text":"<p>Inplace operation that updates config args.</p> <ul> <li>Parameters:<ul> <li><code>space</code> (<code>Optional[str]</code>): Name of the model space.</li> <li><code>name</code> (<code>Optional[str]</code>): Name of the model.</li> <li><code>version</code> (<code>Optional[str]</code>): Version of the model.</li> <li><code>targets</code> (<code>Optional[str]</code>): Target(s) of the model / Dependant variable(s).</li> <li><code>alert_config</code> (<code>Optional[PsiAlertConfig]</code>): Instance of <code>PsiAlertConfig</code>.</li> </ul> </li> <li>Returns: <code>None</code></li> <li>Return Type: <code>None</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_profile/#model_validate_json-static-method","title":"<code>model_validate_json()</code> (static method)","text":"<p>Validate a JSON string representation of a saved profile.</p> <ul> <li>Parameters:<ul> <li><code>json_string</code> (<code>str</code>): PsiDriftProfile in JSON string format.</li> </ul> </li> <li>Returns: <code>PsiDriftProfile</code></li> <li>Return Type: <code>PsiDriftProfile</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_profile/#from_file-static-method","title":"<code>from_file()</code> (static method)","text":"<p>Load a <code>PsiDriftProfile</code> from file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (<code>Path</code>): Path to the file.</li> </ul> </li> <li>Returns: <code>PsiDriftProfile</code></li> <li>Return Type: <code>PsiDriftProfile</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_profile/#model_validate-static-method","title":"<code>model_validate()</code> (static method)","text":"<p>Validate a dict representation of a saved profile.</p> <ul> <li>Parameters:<ul> <li><code>data</code> (<code>Dict[str, Any]</code>): dict representation of your PsiDriftProfile.</li> </ul> </li> <li>Returns: <code>PsiDriftProfile</code></li> <li>Return Type: <code>PsiDriftProfile</code></li> </ul>"},{"location":"docs/monitoring/psi/drift_profile/#features","title":"Features","text":""},{"location":"docs/monitoring/psi/drift_profile/#psifeaturedriftprofile","title":"<code>PsiFeatureDriftProfile</code>","text":"<p>The <code>PsiFeatureDriftProfile</code> is assigned to each feature when creating a <code>PsiDriftProfile</code>. The <code>PsiFeatureDriftProfile</code> will contain information about the bins constructed per the decile formula.</p>"},{"location":"docs/monitoring/psi/drift_profile/#properties_1","title":"Properties","text":"Property Type Description Example <code>id</code> <code>str</code> The name of the feature. <code>profile.name</code> \u2192 <code>\"feature_1\"</code> <code>bins</code> <code>list[Bin]</code> List of the bins assigned to the feature. <code>profile.bins</code> \u2192 <code>\"[*Instance of Bin*]\"</code> <code>timestamp</code> <code>str</code> Time of creation. <code>profile.timestamp</code> \u2192 <code>\"2025-03-13T14:30:00Z\"</code> <code>bin_type</code> <code>BinType</code> A bin can be either Categorical, Numeric, or Binary. <code>profile.bin_type</code> \u2192 <code>BinType.Numeric</code>"},{"location":"docs/monitoring/psi/quickstart/","title":"Quickstart","text":"<p>Population Stability Index (PSI) is one of the most common ways to monitor ML models in production. The following sections will walk you through:</p> <ul> <li>Setting up a PSI drift profile</li> <li>Configuring real-time notifications for model drift detection</li> </ul>"},{"location":"docs/monitoring/psi/quickstart/#creating-a-drift-profile","title":"Creating a Drift Profile","text":"<p>To detect model drift, we first need to create a drift profile using your baseline dataset, this is typically done at the time of training your model. <pre><code>from scouter.alert import PsiAlertConfig, SlackDispatchConfig\nfrom scouter.client import ScouterClient\nfrom scouter.drift import Drifter, PsiDriftConfig\nfrom scouter.types import CommonCrons\nfrom sklearn import datasets\n\n# Prepare data\nX, y = datasets.load_wine(return_X_y=True, as_frame=True)\n\n# Drifter class for creating drift profiles\nscouter = Drifter()\n\n# Specify the alert configuration\nalert_config = PsiAlertConfig(\n    features_to_monitor=[\"malic_acid\", \"total_phenols\", \"color_intensity\"], # Defaults to all features if left empty\n    schedule=CommonCrons.EveryDay, # Run drift detection job once daily\n    dispatch_config=SlackDispatchConfig(channel=\"test_channel\"), # Notify my team Slack channel if drift is detected\n    # psi_threshold=0.25  # (default) adjust if needed\n)\n\n# Create drift config\npsi_config = PsiDriftConfig(\n    name=\"wine_model\",\n    space=\"wine_model\",\n    version=\"0.0.1\",\n    alert_config=alert_config\n)\n\n# Create the drift profile\npsi_profile = scouter.create_drift_profile(X, psi_config) # (1)\n\n# Register your profile with scouter server\nclient = ScouterClient()\n\n# set_active must be set to True if you want scouter server to run the drift detection job\n# You can always set this later\nclient.register_profile(profile=psi_profile, set_active=True)\n</code></pre></p> <ol> <li>The data you pass to <code>create_drift_profile</code> should be the baseline dataset used to train your model. It is recommended to use a representative sample of your training data. It is also expected that the data is free of missing values, nans and infinities, or else the drift profile creation may fail or give unexpected results.</li> </ol> <p>Note</p> <p>Your drift profile is now registered with the <code>Scouter</code> server and is ready to be used. To run real-time monitoring, refer to the Scouter Queues section for more information on how to set up your queues and send data to the Scouter server.</p>"},{"location":"docs/monitoring/psi/theory/","title":"Theory","text":""},{"location":"docs/monitoring/psi/theory/#population-stability-indexreference","title":"Population Stability Index(reference)","text":""},{"location":"docs/monitoring/psi/theory/#introduction","title":"Introduction","text":"<p>Population Stability Index (PSI) is a statistical metric used to measure the distribution shift between two datasets. It is commonly used in model monitoring to detect data drift over time. A high PSI value indicates a significant change in the data distribution, potentially signaling model degradation.</p>"},{"location":"docs/monitoring/psi/theory/#why-use-psi","title":"Why Use PSI?","text":"<p>PSI is particularly useful in machine learning and data science for:</p> <ul> <li> <p>Monitoring model input distributions to detect data drift.</p> </li> <li> <p>Validating that training and production data remain similar.</p> </li> <li> <p>Ensuring model predictions remain stable over time.</p> </li> <li> <p>Detecting changes in customer behavior, economic conditions, or market trends.</p> </li> </ul>"},{"location":"docs/monitoring/psi/theory/#mathematical-definition-of-psi","title":"Mathematical Definition of PSI","text":"<p>PSI is calculated using the formula:</p> \\[ \\text{PSI}(Y_b, Y, B) = \\sum_{i=1}^{B} \\left( y_i - y_{b_i} \\right) \\ln\\left( \\frac{y_i}{y_{b_i}} \\right) \\] <p>where: - \\(y_1, . . . , y_B\\) are the proportions of the \\(i_{th}\\) bin collected during the time of inference</p> <ul> <li> <p>\\(y_{b_1}, . . . , y_{b_B}\\) are the proportions of the \\(i_{th}\\) bin collected during the time of training</p> </li> <li> <p>\\(B\\) represents number of bins</p> </li> </ul>"},{"location":"docs/monitoring/psi/theory/#interpreting-psi-values","title":"Interpreting PSI Values","text":"<p>The rule of thumb for interpreting PSI values is:</p> PSI Value Interpretation <code>&lt; 0.1</code> No significant change <code>0.1 - 0.25</code> Moderate shift, monitor closely <code>&gt; 0.25</code> Significant shift, investigate"},{"location":"docs/monitoring/psi/theory/#how-psi-works","title":"How PSI Works","text":"<ol> <li>Bin the Data: Define bins (e.g., equal-width or quantile-based) for both the expected and observed distributions.</li> <li>Calculate Proportions: Compute \\( p_i \\) and \\( q_i \\) for each bin.</li> <li>Apply PSI Formula: Sum the PSI contributions across all bins.</li> <li>Analyze Results: If PSI is high, investigate the underlying cause of the drift.</li> </ol>"},{"location":"docs/monitoring/psi/theory/#example-calculation","title":"Example Calculation","text":"<p>Consider an expected distribution and an observed distribution with the following bin frequencies:</p> Bin Range Expected Count Observed Count <code>0-10</code> <code>1000</code> <code>800</code> <code>10-20</code> <code>1500</code> <code>1400</code> <code>20-30</code> <code>1200</code> <code>1600</code> <code>30-40</code> <code>1300</code> <code>1200</code> <p>Convert these into proportions:</p> Bin Range Expected Proportion Observed Proportion <code>0-10</code> <code>0.2</code> <code>0.16</code> <code>10-20</code> <code>0.3</code> <code>0.28</code> <code>20-30</code> <code>0.24</code> <code>0.32</code> <code>30-40</code> <code>0.26</code> <code>0.24</code> <p>Applying the PSI formula:</p> \\[PSI = (0.2 - 0.16) \\ln\\left(\\frac{0.2}{0.16}\\right) + (0.3 - 0.28) \\ln\\left(\\frac{0.3}{0.28}\\right) + (0.24 - 0.32) \\ln\\left(\\frac{0.24}{0.32}\\right) + (0.26 - 0.24) \\ln\\left(\\frac{0.26}{0.24}\\right)\\]"},{"location":"docs/monitoring/psi/theory/#binning-strategies","title":"Binning Strategies","text":"<p>Currently, scouter PSI supports the decile binning approach, which is widely recognized as an industry standard and has shown to provide optimal performance in most use cases. We are actively working on expanding the library to support additional binning strategies, offering more flexibility to handle various scenarios.</p>"},{"location":"docs/monitoring/psi/theory/#conclusion","title":"Conclusion","text":"<p>PSI is a powerful tool for detecting data drift in production models. By regularly monitoring PSI values, data scientists and engineers can proactively maintain model performance and stability.</p>"},{"location":"docs/monitoring/spc/drift_config/","title":"SPC Drift Configuration","text":"<p>All models that create a <code>SpcDriftProfile</code> will require a <code>SpcDriftConfig</code> object.</p> <pre><code>from scouter.alert import SpcAlertConfig\nfrom scouter.drift import SpcDriftConfig\n\nSpcDriftConfig(\n    name=\"wine_model\",\n    space=\"wine_model\",\n    version=\"0.0.1\",\n    alert_config=SpcAlertConfig(),\n    sample_size=1000\n)\n</code></pre>"},{"location":"docs/monitoring/spc/drift_config/#parameters","title":"Parameters","text":"Parameter Type Description Example name <code>str</code> The name of the model or dataset being monitored. Defaults to '__missing__' if not provided. <code>config.name \u2192 \"wine_model\"</code> space <code>str</code> The space where the model or dataset is stored. Defaults to '__missing__' if not provided. <code>config.space \u2192 \"wine_model\"</code> version <code>str</code> The version of the model or dataset being monitored. Defaults to '0.0.1' if not provided. <code>config.version \u2192 \"0.0.1\"</code> alert_config <code>SpcAlertConfig</code> Configuration for alerting when drift is detected. Defaults to the default implementation of SpcAlertConfig if not provided. <code>config.alert_config \u2192 *Instance of SpcAlertConfig*</code> targets <code>list[str]</code> List of target features, typically the dependent variable(s). <code>config.targets \u2192 [\"churn\"]</code> config_path <code>Optional[Path]</code> Path to a pre existing SpcDriftConfig. Defaults to None if not provided <code>config.config_path \u2192 Path(\"/configs/drift.yaml\")</code> sample <code>bool</code> Specifies whether sampling should be applied when calculating SPC metrics. Defaults to True. <code>config.sample \u2192 True</code> sample_size <code>int</code> Defines the number of data points to include in the sample when sampling is enabled for SPC metric computation. Defaults to 25 <code>config.sample \u2192 True</code>"},{"location":"docs/monitoring/spc/drift_config/#properties","title":"Properties","text":"Property Type Description Example <code>name</code> <code>str</code> The name of the model or dataset being monitored. <code>config.name</code> \u2192 <code>\"wine_model\"</code> <code>space</code> <code>str</code> The space where the model or dataset is stored. <code>config.space</code> \u2192 <code>\"wine_model\"</code> <code>version</code> <code>str</code> The version of the model or dataset being monitored. <code>config.version</code> \u2192 <code>\"0.0.1\"</code> <code>feature_map</code> <code>FeatureMap</code> When a non-numeric covariate is detected, each unique value is assigned a corresponding numeric value. This mapping is represented by feature_map. <code>config.feature_map</code> \u2192 <code>Instance of FeatureMap</code> <code>targets</code> <code>list[str]</code> List of target features, typically the dependent variable(s). <code>config.targets</code> \u2192 <code>label</code> <code>alert_config</code> <code>SpclertConfig</code> Configuration for alerting when drift is detected. <code>config.alert_config</code> \u2192 <code>Instance of SpcAlertConfig</code> <code>drift_type</code> <code>DriftType</code> Type of drift profile. <code>config.drift_type</code> \u2192 <code>DriftType.Spc</code> <code>sample_size</code> <code>int</code> Defines the number of data points to include in the sample when sampling is enabled for SPC metric computation. <code>config.sample_size</code> \u2192 <code>1000</code> <code>sample</code> <code>bool</code> Specifies whether sampling should be applied when calculating SPC metrics. <code>config.sample</code> \u2192 <code>True</code>"},{"location":"docs/monitoring/spc/drift_config/#methods","title":"Methods","text":""},{"location":"docs/monitoring/spc/drift_config/#load_from_json_file-static-method","title":"<code>load_from_json_file()</code> (static method)","text":"<p>Loads a <code>SpcDriftConfig</code> instance from a JSON file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (<code>Path</code>): The path to the JSON configuration file. This is required to locate and read the configuration file from disk.</li> </ul> </li> <li>Returns: A <code>SpcDriftConfig</code> instance.</li> <li>Return Type: <code>SpcDriftConfig</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_config/#model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Serializes the <code>SpcDriftConfig</code> instance to a JSON string.</p> <ul> <li>Parameters: None</li> <li>Returns: A JSON string representation of the instance.</li> <li>Return Type: <code>str</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_config/#update_config_args","title":"<code>update_config_args()</code>","text":"<p>Updates the configuration of the instance with new values.</p> <ul> <li>Parameters:<ul> <li><code>space</code> (<code>Optional[str]</code>): The space name, if updating.</li> <li><code>name</code> (<code>Optional[str]</code>): The new name for the configuration, if provided.</li> <li><code>version</code> (<code>Optional[str]</code>): The version to set, if specified.</li> <li><code>targets</code> (<code>Optional[List[str]]</code>): A list of target identifiers, if updating.</li> <li><code>alert_config</code> (<code>Optional[SpcAlertConfig]</code>): The alert configuration, if provided.</li> <li><code>sample</code> (<code>Optional[bool]</code>): Opt in or out of the sampling strategy.</li> <li><code>sample_size</code> (<code>Optional[int]</code>): Adjust the sample size.</li> </ul> </li> <li>Returns: <code>None</code></li> <li>Return Type: <code>None</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_config/#alert-configuration","title":"Alert Configuration","text":"<p>An <code>AlertConfig</code> can also be provided to the <code>SpcDriftConfig</code> to specify how you and your team want to be alerted in the event of model drift. The <code>SpcAlertConfig</code> class allows you to configure the alerting mechanism, including the dispatch method (e.g., Slack, OpsGenie) and the schedule for drift detection jobs.</p> <pre><code>from scouter.alert import SpcAlertConfig, OpsGenieDispatchConfig, SpcAlertRule\nfrom scouter.types import CommonCrons\n\nSpcAlertConfig(\n    rule=SpcAlertRule(rule=\"16 32 4 8 2 4 1 1\"),\n    dispatch_config=OpsGenieDispatchConfig(team='the-ds-team'),\n    schedule=CommonCrons.EveryDay,\n    features_to_monitor=['feature_1', 'feature_2', ...],\n)\n</code></pre>"},{"location":"docs/monitoring/spc/drift_config/#parameters_1","title":"Parameters","text":"Parameter Type Description Example dispatch_config <code>SlackDispatchConfig | OpsGenieDispatchConfig                                                        | None</code> An optional dispatch configuration used to configure how alerts are routed, if None is provided a default internal dispatch type of Console will be used to log alerts to the conosole of the scouter server. <code>config.dispatch_config -&gt; SlackDispatchConfig()</code> schedule <code>str                 | CommonCrons                                                                   | None</code> Schedule to run drift detection job. Defaults to daily at midnigh. You can use the builtin CommonCron options or specify your own custom cron. <code>config.schedule \u2192 CommonCrons.Every6Hours</code> features_to_monitor <code>list[str]</code> List of features to monitor. Defaults to empty list, which means all features <code>config.features_to_monitor \u2192 ['feature_1, feature_2, ...']</code> rule <code>SpcAlertRule</code> Defines the conditions for triggering alerts based on patterns observed in the control chart. Defaults to \"8 16 4 8 2 4 1 1\", where each digit specifies a threshold for detecting instability within each control zone (Zone 1 to Zone 4). Can be customized for more or less sensitivity. <code>config.rule \u2192 *Instance of SpcAlertRule*</code>"},{"location":"docs/monitoring/spc/drift_config/#properties_1","title":"Properties","text":"Property Type Description Example <code>dispatch_type</code> <code>str</code> String representation of what type of dispatch are you using to send alerts. <code>config.dispatch_type</code> \u2192 <code>\"Slack\"</code> <code>dispatch_Config</code> <code>SlackDispatchConfig | OpsGenieDispatchConfig                                                        | None</code> Dispatch configuration used to configure how alerts are routed. <code>config.dispatch_config -&gt; SlackDispatchConfig()</code> <code>schedule</code> <code>str</code> The schedule that is used to determine when your drift detecion job should run. <code>config.schedule</code> \u2192 <code>\"0 0 0 * * SUN\"</code> <code>features_to_monitor</code> <code>list[str]</code> List of features to monitor. <code>config.features_to_monitor \u2192 ['feature_1, feature_2, ...']</code> <code>rule</code> <code>SpcAlertRule</code> Defines the conditions for triggering alerts based on patterns observed in the control chart. Defaults to \"8 16 4 8 2 4 1 1\", where each digit specifies a threshold for detecting instability within each control zone (Zone 1 to Zone 4). Can be customized for more or less sensitivity. <code>config.rule \u2192 *Instance of SpcAlertRule*</code>"},{"location":"docs/monitoring/spc/drift_config/#alertrule","title":"AlertRule","text":"<p>The <code>SpcAlertRule</code> class is used to define the conditions for triggering alerts based on patterns observed in the control chart. The rule is represented as a string of digits, where each digit specifies a threshold for detecting instability within each control zone (Zone 1 to Zone 4). The default rule is \"8 16 4 8 2 4 1 1\", which can be customized for more or less sensitivity.</p> <pre><code>rom scouter.alert import SpcAlertRule, AlertZone\n\nSpcAlertRule(\n    rule=\"8 16 4 8 2 4 1 1\",\n    zones_to_monitor=[AlertZone.Zone1, AlertZone.Zone2, AlertZone.Zone3, AlertZone.Zone4]\n)\n</code></pre>"},{"location":"docs/monitoring/spc/drift_config/#parameters_2","title":"Parameters","text":"Parameter Type Description Example rule <code>str</code> Rule to use for alerting. Eight digit integer string. Defaults to '8 16 4 8 2 4 1 1 <code>alert_rule.rule -&gt; \"8 16 4 8 2 4 1 1\"</code> zones_to_monitor <code>list[AlertZone]</code> List of zones to monitor. Defaults to all zones. <code>alert_rule.zones \u2192 [AlertZone.Zone1, AlertZone.Zone2]</code>"},{"location":"docs/monitoring/spc/drift_config/#properties_2","title":"Properties","text":"Property Type Description Example rule <code>str</code> Rule to use for alerting. Eight digit integer string. Defaults to '8 16 4 8 2 4 1 1 <code>alert_rule.rule -&gt; \"8 16 4 8 2 4 1 1\"</code> zones_to_monitor <code>list[AlertZone]</code> List of zones to monitor. Defaults to all zones. <code>alert_rule.zones \u2192 [AlertZone.Zone1, AlertZone.Zone2]</code>"},{"location":"docs/monitoring/spc/drift_profile/","title":"Spc Drift Profile","text":"<p>The <code>SpcDriftProfile</code> serves as the core component for monitoring model drift in production.</p>"},{"location":"docs/monitoring/spc/drift_profile/#properties","title":"Properties","text":"Property Type Description Example <code>scouter_version</code> <code>str</code> The version of scouter that was used to create your SPC drift profile. <code>spc_profile.scouter_version</code> \u2192 <code>\"1.0.0\"</code> <code>features</code> <code>dict[str, SpcFeatureDriftProfile]</code> A mapping of feature names to their respective drift profiles. <code>spc_profile.features['feature_name']</code> \u2192 <code>*Instance of SpcFeatureDriftProfile*</code> <code>config</code> <code>SpcDriftConfig</code> The drift config defined at the time of profile creationg. <code>spc_profile.config</code> \u2192 <code>*Instance of SpcDriftConfig*</code>"},{"location":"docs/monitoring/spc/drift_profile/#methods","title":"Methods","text":""},{"location":"docs/monitoring/spc/drift_profile/#model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Serializes the <code>SpcDriftProfile</code> instance to a JSON string.</p> <ul> <li>Parameters: None</li> <li>Returns: A JSON string representation of the instance.</li> <li>Return Type: <code>str</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_profile/#model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of the drift profile.</p> <ul> <li>Parameters: None</li> <li>Returns: <code>dict[str, Any]</code> representation of the instance.</li> <li>Return Type: <code>dict[str, Any]</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_profile/#save_to_json","title":"<code>save_to_json()</code>","text":"<p>Save drift profile to json file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (<code>Optional[Path]</code>): Optional path to save the drift profile. If None, outputs to drift_profile.json.</li> </ul> </li> <li>Returns: <code>None</code></li> <li>Return Type: <code>None</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_profile/#update_config_args","title":"<code>update_config_args()</code>","text":"<p>Inplace operation that updates config args.</p> <ul> <li>Parameters:<ul> <li><code>space</code> (<code>Optional[str]</code>): Name of the model space.</li> <li><code>name</code> (<code>Optional[str]</code>): Name of the model.</li> <li><code>version</code> (<code>Optional[str]</code>): Version of the model.</li> <li><code>targets</code> (<code>Optional[str]</code>): Target(s) of the model / Dependant variable(s).</li> <li><code>sample</code> (<code>Optional[bool]</code>): Whether to use sampling or not.</li> <li><code>sample_size</code> (<code>Optional[bool]</code>): Size of the samples you want to use.</li> <li><code>alert_config</code> (<code>Optional[SpcAlertConfig]</code>): Instance of <code>SpcAlertConfig</code></li> </ul> </li> <li>Returns: <code>None</code></li> <li>Return Type: <code>None</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_profile/#model_validate_json-static-method","title":"<code>model_validate_json()</code> (static method)","text":"<p>Validate a JSON string representation of a saved profile.</p> <ul> <li>Parameters:<ul> <li><code>json_string</code> (<code>str</code>): <code>SpcDriftProfile</code> in JSON string format.</li> </ul> </li> <li>Returns: <code>SpcDriftProfile</code></li> <li>Return Type: <code>SpcDriftProfile</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_profile/#from_file-static-method","title":"<code>from_file()</code> (static method)","text":"<p>Load a <code>SpcDriftProfile</code> from file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (<code>Path</code>): Path to the file.</li> </ul> </li> <li>Returns: <code>SpcDriftProfile</code></li> <li>Return Type: <code>SpcDriftProfile</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_profile/#model_validate-static-method","title":"<code>model_validate()</code> (static method)","text":"<p>Validate a dict representation of a saved profile.</p> <ul> <li>Parameters:<ul> <li><code>data</code> (<code>Dict[str, Any]</code>): dict representation of your <code>SpcDriftProfile</code>.</li> </ul> </li> <li>Returns: <code>SpcDriftProfile</code></li> <li>Return Type: <code>SpcDriftProfile</code></li> </ul>"},{"location":"docs/monitoring/spc/drift_profile/#features","title":"Features","text":""},{"location":"docs/monitoring/spc/drift_profile/#spcfeaturedriftprofile","title":"<code>SpcFeatureDriftProfile</code>","text":"<p>The <code>SpcFeatureDriftProfile</code> is assigned to each feature when creating a <code>SpcDriftProfile</code>. The <code>SpcFeatureDriftProfile</code> will contain information about your features's center and zone control limits.</p>"},{"location":"docs/monitoring/spc/drift_profile/#properties_1","title":"Properties","text":"Property Type Description Example <code>id</code> <code>str</code> The name of the feature. <code>profile.name</code> \u2192 <code>\"feature_1\"</code> <code>center</code> <code>float</code> Mean of the sample for the feature. <code>profile.center</code> \u2192 <code>.6</code> <code>one_ucl</code> <code>float</code> Zone 1 upper control limit. <code>profile.one_ucl</code> \u2192 <code>.1</code> <code>one_lcl</code> <code>float</code> Zone 1 lower control limit. <code>profile.one_lcl</code> \u2192 <code>.2</code> <code>two_ucl</code> <code>float</code> Zone 2 upper control limit. <code>profile.two_ucl</code> \u2192 <code>.3</code> <code>two_lcl</code> <code>float</code> Zone 2 lower control limit. <code>profile.two_lcl</code> \u2192 <code>.4</code> <code>three_ucl</code> <code>float</code> Zone 3 upper control limit. <code>profile.three_ucl</code> \u2192 <code>.5</code> <code>three_lcl</code> <code>float</code> Zone 3 lower control limit. <code>profile.three_lcl</code> \u2192 <code>.6</code> <code>timestamp</code> <code>str</code> Time of creation. <code>profile.timestamp</code> \u2192 <code>\"2025-03-13T14:30:00Z\"</code>"},{"location":"docs/monitoring/spc/quickstart/","title":"Quickstart","text":"<p>Statistical Process Control (SPC) is a powerful tool for monitoring and controlling processes. In this guide, we will walk you through the steps to set up SPC for your model using Scouter.</p>"},{"location":"docs/monitoring/spc/quickstart/#creating-a-drift-profile","title":"Creating a Drift Profile","text":"<p>To detect model drift, we first need to create a drift profile using your training data, but before doing that we will define a custom SPC alert rule.</p> <pre><code>from scouter.alert import SlackDispatchConfig, SpcAlertConfig, SpcAlertRule\nfrom scouter.client import ScouterClient\nfrom scouter.drift import Drifter, SpcDriftConfig\nfrom scouter.types import CommonCrons\nfrom sklearn import datasets\n\nif __name__ == \"__main__\":\n    # Prepare data\n    X, y = datasets.load_wine(return_X_y=True, as_frame=True)\n\n    # Drifter class to create drift profiles\n    scouter = Drifter()\n\n    # Specify the alert configuration\n    alert_config = SpcAlertConfig(\n        features_to_monitor=[\"malic_acid\", \"total_phenols\", \"color_intensity\"], # Defaults to all features if left empty\n        schedule=CommonCrons.EveryDay, # Run drift detection job once daily\n        dispatch_config=SlackDispatchConfig(channel=\"test_channel\"), # Notify my team Slack channel if drift is detected\n        rule=SpcAlertRule(rule=\"16 32 4 8 2 4 1 1\"), # See the spc theory doc for additional info\n    )\n\n    # Set up SPC drift config with a custom sample size\n    spc_config = SpcDriftConfig(name=\"wine_model\", space=\"wine_model\", version=\"0.0.1\", alert_config=alert_config, sample_size=1000)\n\n    # Create the drift profile\n    spc_profile = scouter.create_drift_profile(X, spc_config)\n\n    # Register your profile with scouter server\n    client = ScouterClient()\n    # set_active must be set to True if you want scouter server to run the drift detection job\n    client.register_profile(profile=spc_profile, set_active=True)\n</code></pre> <p>Note</p> <p>Your drift profile is now registered with the <code>Scouter</code> server and is ready to be used. To run real-time monitoring, refer to the Scouter Queues section for more information on how to set up your queues and send data to the Scouter server in real-time.</p>"},{"location":"docs/monitoring/spc/theory/","title":"Theory","text":""},{"location":"docs/monitoring/spc/theory/#statistical-process-control-reference","title":"Statistical Process Control (reference)","text":"<p>The basic idea of statistical process control is to compare current process output/data to previous/expected output/data. To do this from an modeling perspective, we take a snapshot of the model's data and predictions at the time of model creation and create a <code>DriftProfile</code>. This is done by sampling the data and calculating a series of means and standard deviations in order to approximate the population distribution. From this grand mean and standard deviation, we can calculate the upper and lower control limits for the data.</p> <p>Reference for grand mean and standard deviation calculations: link</p>"},{"location":"docs/monitoring/spc/theory/#formulas","title":"Formulas","text":"<p>Sample mean and standard deviation:</p> \\[ \\overline{x}_i = \\frac{1}{n}\\sum_{i=1}^n x_i \\] \\[ \\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i-\\overline{x})^2} \\] <p>Grand sample mean and standard deviation:</p> \\[ \\overline{\\overline{x}}=\\frac{1}{n}\\sum_{i=1}^n\\overline{x}_i \\] \\[ \\overline{s}=\\frac{1}{n}\\sum_{i=1}^n{\\sigma}_i \\] \\[ \\hat\\sigma{}=\\frac{\\overline{s}}{c_4} \\] <p>Where \\(c_4\\) is the bias correction factor for the sample standard deviation. The bias correction factor is given by:</p> \\[ c_4 = \\sqrt{\\frac{2-1}{n}} {\\frac{(\\frac{n}{2} - 1)!}{(\\frac{n-1}{2} - 1)!}} \\] <p>Control limits:</p> \\[ UCL = \\overline{\\overline{x}} + k\\hat\\sigma{} \\] \\[ LCL = \\overline{\\overline{x}} - k\\hat\\sigma{} \\] <p>Where \\(k\\) is the number of standard deviations from the grand mean. Typically, \\(k=3\\) is used for the upper and lower control limits. Note: the calculation of control limits in <code>Scouter</code> uses \\(\\hat\\sigma{}\\). In some text books you will see \\(\\frac{\\hat\\sigma{}}{\\sqrt{n}}\\). <code>Scouter</code> uses the former in order to widen the control limits and reduce false positives.</p>"},{"location":"docs/monitoring/spc/theory/#control-limits","title":"Control Limits","text":"<p>Out of the box, <code>Scouter</code> will calculate the center line and control limits for 3 zones (\\(\\pm{1}\\), \\(\\pm{2}\\) and \\(\\pm{3}\\)). This is based on the 3 sigma rule in process control. The resulting chart and zones would appear as follows if plotted:</p> <p>Each dot on the chart represents the mean of a sample from the process being monitored</p> <p>Zone specifications are as follows:</p> <ul> <li>Zone 1: 1 LCL -&gt; 1 UCL</li> <li>Zone 2: 2 LCL -&gt; 2 UCL</li> <li>Zone 3: 3 LCL -&gt; 3 UCL</li> </ul>"},{"location":"docs/monitoring/spc/theory/#alerting","title":"Alerting","text":"<p>When new data comes in, we can compare the new data to calculated control limits to see if the process is stable. If it's not, we can generate alerts. So what does stable mean? In process control, a process is considered stable if the data points fall within the control limits and follow a non-repeating patten. There is great room for flexibility in this definition, which allows data scientists and engineers to customize their alerts rules.</p> <p>By default, <code>Scouter</code> follows an 8 digit rule for process control. The default rule follows WECO rules with some modification, which is defined as \"8 16 4 8 2 4 1 1\".</p>"},{"location":"docs/monitoring/spc/theory/#rule-breakdown","title":"Rule breakdown","text":"<code>First digit</code> Zone 1 - 8 points in n + 1 observations on one side of the center line in Zone 1 or greater <code>Second digit</code> Zone 1 - 16 points in n + 1 observations on alternating sides of the center line in Zone 1 or greater <code>Third digit</code> Zone 2 - 4 points in n + 1 observations on one side of the center line in Zone 2 or greater <code>Fourth digit</code> Zone 2 - 8 points in n + 1 observations on alternating sides of the center line in Zone 2 or greater <code>Fifth digit</code> Zone 3 - 2 points in n + 1 observations on one side of the center line in Zone 3 or greater <code>Sixth digit</code> Zone 3 - 4 points in n + 1 observations on alternating sides of the center line in Zone 3 or greater <code>Seventh digit</code> Zone 4 (Out of Control) - 1 points in n + 1 observations on one side of the center line greater than Zone 3 <code>Eighth digit</code> Zone 4 (Out of Control) - 1 points in n + 1 observations on alternating sides of the center line greater than Zone 3 <p>In addition to the 8 digit rule, <code>Scouter</code> will also check for a consecutive trend of 7 increasing or decreasing points and return an alert if one is detected.</p>"},{"location":"docs/monitoring/spc/theory/#example-alert","title":"Example Alert","text":""},{"location":"docs/monitoring/spc/theory/#custom-alerts","title":"Custom Alerts","text":"<p><code>Scouter</code> provides the ability to create your own custom 8 digit rules. Below is an example of how to create a custom rule:</p> <pre><code>from scouter.alert import SlackDispatchConfig, SpcAlertConfig, SpcAlertRule\nfrom scouter.drift import SpcDriftConfig\n\n# Create a custom rule\ncustom_rule = SpcAlertRule(rule=\"16 32 4 8 2 4 1 1\")  # create your custom rule here\n\n# Create a drift config\nconfig = SpcDriftConfig(\n    name=\"model\",\n    space=\"scouter\",\n    version=\"0.1.0\",\n    alert_config=SpcAlertConfig(rule=custom_rule, dispatch_config=SlackDispatchConfig(channel=\"test_channel\")),\n)\n</code></pre>"},{"location":"docs/profiling/overview/","title":"Data Profile","text":"<p>In addition to monitoring, <code>Scouter</code> also provides data profiling tools to create feature distribution profiles to associate with your data.</p>"},{"location":"docs/profiling/overview/#supported-data-types","title":"Supported Data Types","text":"<p>Scouter supports a variety of data types, including:</p> <ul> <li>Pandas DataFrames: Scouter can handle Pandas DataFrames, making it easy to integrate with existing data processing pipelines.</li> <li>Numpy Arrays: Out of the box support for 2D arrays.</li> <li>Polars DataFrames: For users who prefer Polars, Scouter supports this data format as well, allowing for efficient data processing and analysis.</li> </ul>"},{"location":"docs/profiling/overview/#create-a-profile","title":"Create a Profile","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom scouter import DataProfile, DataProfiler  # type: ignore[attr-defined]\n\n\ndef generate_data() -&gt; pd.DataFrame:\n    \"\"\"Create a fake data frame for testing\"\"\"\n    n = 10_000\n    X_train = np.random.normal(-4, 2.0, size=(n, 4))\n    col_names = []\n    for i in range(0, X_train.shape[1]):\n        col_names.append(f\"feature_{i}\")\n    X = pd.DataFrame(X_train, columns=col_names)\n\n    # create string column (with 10 unique values)\n    X[\"categorical_feature\"] = np.random.choice(\n        [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"], size=n\n    )\n\n    return X\n\n\ndata = generate_data()\n\n# create data profiler\nprofiler = DataProfiler()\n\n# create data profile\nprofile: DataProfile = profiler.create_data_profile(data)\n\n# Save (provide a path or leave blank)\nprofile.save_to_json()\n\nprint(profile)\n</code></pre> Output <pre><code>    {\n    \"features\": {\n        \"categorical_feature\": {\n        \"id\": \"categorical_feature\",\n        \"numeric_stats\": null,\n        \"string_stats\": {\n            \"distinct\": {\n            \"count\": 10,\n            \"percent\": 0.1\n            },\n            \"char_stats\": {\n            \"min_length\": 1,\n            \"max_length\": 1,\n            \"median_length\": 1,\n            \"mean_length\": 1.0\n            },\n            \"word_stats\": {\n            \"words\": {\n                \"d\": {\n                \"count\": 1021,\n                \"percent\": 0.1021\n                },\n                \"b\": {\n                \"count\": 998,\n                \"percent\": 0.0998\n                },\n                \"i\": {\n                \"count\": 989,\n                \"percent\": 0.0989\n                },\n                \"c\": {\n                \"count\": 1015,\n                \"percent\": 0.1015\n                },\n                \"f\": {\n                \"count\": 1007,\n                \"percent\": 0.1007\n                },\n                \"a\": {\n                \"count\": 987,\n                \"percent\": 0.0987\n                },\n                \"h\": {\n                \"count\": 982,\n                \"percent\": 0.0982\n                },\n                \"g\": {\n                \"count\": 988,\n                \"percent\": 0.0988\n                },\n                \"j\": {\n                \"count\": 1020,\n                \"percent\": 0.102\n                },\n                \"e\": {\n                \"count\": 993,\n                \"percent\": 0.0993\n                }\n            }\n            }\n        },\n        \"timestamp\": \"2025-04-28T18:19:33.987594Z\",\n        \"correlations\": null\n        },\n        \"feature_0\": {\n        \"id\": \"feature_0\",\n        \"numeric_stats\": {\n            \"mean\": -4.003965640199899,\n            \"stddev\": 2.0178515177174448,\n            \"min\": -11.084430177884318,\n            \"max\": 3.375571168173134,\n            \"distinct\": {\n            \"count\": 10000,\n            \"percent\": 1.0\n            },\n            \"quantiles\": {\n            \"q25\": -5.348060765665304,\n            \"q50\": -3.9960621892367625,\n            \"q75\": -2.6379431350112723,\n            \"q99\": 0.7695557247479057\n            },\n            \"histogram\": {\n            \"bins\": [\n                -11.084430177884318,\n                -10.361430110581445,\n                -9.638430043278573,\n                -8.9154299759757,\n                -8.192429908672828,\n                -7.469429841369955,\n                -6.7464297740670816,\n                -6.023429706764209,\n                -5.300429639461337,\n                -4.577429572158464,\n                -3.8544295048555917,\n                -3.1314294375527183,\n                -2.408429370249845,\n                -1.6854293029469734,\n                -0.9624292356441,\n                -0.2394291683412284,\n                0.48357089896164496,\n                1.2065709662645183,\n                1.92957103356739,\n                2.6525711008702633\n            ],\n            \"bin_counts\": [\n                8,\n                14,\n                53,\n                120,\n                228,\n                444,\n                706,\n                1006,\n                1300,\n                1399,\n                1404,\n                1159,\n                914,\n                599,\n                352,\n                153,\n                81,\n                39,\n                17,\n                4\n            ]\n            }\n        },\n        \"string_stats\": null,\n        \"timestamp\": \"2025-04-28T18:19:34.035699Z\",\n        \"correlations\": null\n        },\n        \"feature_1\": {\n        \"id\": \"feature_1\",\n        \"numeric_stats\": {\n            \"mean\": -3.997238711617275,\n            \"stddev\": 1.9969030204031852,\n            \"min\": -11.2143596931969,\n            \"max\": 3.5233542660216592,\n            \"distinct\": {\n            \"count\": 10000,\n            \"percent\": 1.0\n            },\n            \"quantiles\": {\n            \"q25\": -5.331856994963132,\n            \"q50\": -3.9985892307105217,\n            \"q75\": -2.6720412739258803,\n            \"q99\": 0.7018279512701495\n            },\n            \"histogram\": {\n            \"bins\": [\n                -11.2143596931969,\n                -10.477473995235973,\n                -9.740588297275044,\n                -9.003702599314117,\n                -8.266816901353188,\n                -7.529931203392261,\n                -6.7930455054313335,\n                -6.056159807470405,\n                -5.319274109509477,\n                -4.582388411548549,\n                -3.8455027135876207,\n                -3.1086170156266935,\n                -2.371731317665766,\n                -1.634845619704837,\n                -0.8979599217439098,\n                -0.16107422378298075,\n                0.5758114741779465,\n                1.3126971721388738,\n                2.049582870099803,\n                2.78646856806073\n            ],\n            \"bin_counts\": [\n                7,\n                18,\n                42,\n                93,\n                218,\n                425,\n                706,\n                1015,\n                1345,\n                1431,\n                1430,\n                1216,\n                866,\n                580,\n                340,\n                158,\n                72,\n                20,\n                13,\n                5\n            ]\n            }\n        },\n        \"string_stats\": null,\n        \"timestamp\": \"2025-04-28T18:19:34.035702Z\",\n        \"correlations\": null\n        },\n        \"feature_2\": {\n        \"id\": \"feature_2\",\n        \"numeric_stats\": {\n            \"mean\": -3.9985933460650362,\n            \"stddev\": 1.9872554303247896,\n            \"min\": -11.298088188584437,\n            \"max\": 3.7792120832159224,\n            \"distinct\": {\n            \"count\": 10000,\n            \"percent\": 1.0\n            },\n            \"quantiles\": {\n            \"q25\": -5.3669588658728955,\n            \"q50\": -3.991356640189083,\n            \"q75\": -2.6604527797988693,\n            \"q99\": 0.716291352460563\n            },\n            \"histogram\": {\n            \"bins\": [\n                -11.298088188584437,\n                -10.54422317499442,\n                -9.7903581614044,\n                -9.036493147814383,\n                -8.282628134224364,\n                -7.528763120634347,\n                -6.774898107044329,\n                -6.021033093454311,\n                -5.267168079864293,\n                -4.513303066274275,\n                -3.7594380526842563,\n                -3.005573039094239,\n                -2.2517080255042217,\n                -1.4978430119142025,\n                -0.7439779983241852,\n                0.00988701526583391,\n                0.7637520288558513,\n                1.5176170424458686,\n                2.2714820560358877,\n                3.025347069625905\n            ],\n            \"bin_counts\": [\n                3,\n                11,\n                36,\n                109,\n                222,\n                423,\n                744,\n                1114,\n                1321,\n                1487,\n                1454,\n                1193,\n                853,\n                530,\n                284,\n                120,\n                52,\n                29,\n                13,\n                2\n            ]\n            }\n        },\n        \"string_stats\": null,\n        \"timestamp\": \"2025-04-28T18:19:34.035703Z\",\n        \"correlations\": null\n        },\n        \"feature_3\": {\n        \"id\": \"feature_3\",\n        \"numeric_stats\": {\n            \"mean\": -3.996914164800711,\n            \"stddev\": 1.9930422779448296,\n            \"min\": -11.140741264279484,\n            \"max\": 2.876859924322919,\n            \"distinct\": {\n            \"count\": 10000,\n            \"percent\": 1.0\n            },\n            \"quantiles\": {\n            \"q25\": -5.332108894837108,\n            \"q50\": -3.9894123025713193,\n            \"q75\": -2.639771809727505,\n            \"q99\": 0.531352688455816\n            },\n            \"histogram\": {\n            \"bins\": [\n                -11.140741264279484,\n                -10.439861204849365,\n                -9.738981145419244,\n                -9.038101085989123,\n                -8.337221026559003,\n                -7.636340967128883,\n                -6.935460907698763,\n                -6.234580848268643,\n                -5.533700788838523,\n                -4.832820729408403,\n                -4.131940669978283,\n                -3.4310606105481627,\n                -2.7301805511180426,\n                -2.0293004916879234,\n                -1.3284204322578024,\n                -0.6275403728276814,\n                0.07333968660243784,\n                0.774219746032557,\n                1.475099805462678,\n                2.175979864892799\n            ],\n            \"bin_counts\": [\n                3,\n                22,\n                37,\n                79,\n                218,\n                385,\n                557,\n                870,\n                1214,\n                1333,\n                1422,\n                1216,\n                1002,\n                759,\n                422,\n                251,\n                146,\n                42,\n                16,\n                6\n            ]\n            }\n        },\n        \"string_stats\": null,\n        \"timestamp\": \"2025-04-28T18:19:34.035704Z\",\n        \"correlations\": null\n        }\n    }\n}\n</code></pre>"},{"location":"docs/server/","title":"Overview","text":"<p>The Scouter server is a rust-based server that is designed to be run independent of the python client. The server is responsible for handling the event system (via Kafka, RabbitMQ or the default queue system), database CRUD operations, and alerting.</p> <p>Features:</p> <ul> <li>Event System - Scouter supports various third-party event systems such as Kafka and RabbitMQ. The event system is used to send events to the Scouter server for processing</li> <li>Database Storage - The Scouter server leverages Postgres (sqlx) for short-term data storage and DataFusion for long-term data storage</li> <li>Alerting - Integrates with OpsGenie and Slack for alerting</li> <li>Data Retention and Partitioning - Built-in data retention and partitioning strategies to keep your database clean and performant</li> <li>Authentication - Built-in authentication system for users</li> </ul>"},{"location":"docs/server/#getting-started","title":"Getting Started","text":"<p>There are a few different ways to get up an running with the Scouter server.</p>"},{"location":"docs/server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Scouter relies on a Postgres database for storing and retrieving data. You will need to have a Postgres database up and running before you can use Scouter. Scouter currently supports Postgres 16.3 and above.</li> </ul> <p>Once you have a Postgres database up and running, set the following environment variable before starting the Scouter server:</p> <pre><code>export DATABASE_URI={your_postgres_uri}\n</code></pre> <p>The default database URI is <code>postgresql://postgres:postgres@localhost:5432/postgres</code>. You can change this to point to your own Postgres database.</p>"},{"location":"docs/server/#docker","title":"Docker","text":"<p>It is recommended to use one of our pre-built Docker images to get up and running quickly. New docker images are built and tagged on every version release and currently build for the following platforms:</p> <p>Amd64 (x86_64-unknown-linux-gnu)</p> Image Tag Suffix Features ubuntu ubuntu (kafka, RabbitMQ) alpine alpine (kafka, RabbitMQ) scratch scratch (kafka, RabbitMQ) debian debian (kafka, RabbitMQ) distroless distroless (kafka, RabbitMQ) <p>Arm64 (aarch64-unknown-linux-gnu)</p> Image Tag Suffix Features ubuntu ubuntu (kafka, RabbitMQ) alpine alpine (kafka, RabbitMQ) scratch scratch (kafka, RabbitMQ) debian debian (kafka, RabbitMQ) distroless distroless (kafka, RabbitMQ)"},{"location":"docs/server/#pull-your-image","title":"Pull your image","text":"<pre><code>docker pull demml/scouter:ubuntu-amd64-kafka-latest\n</code></pre>"},{"location":"docs/server/#run-your-image","title":"Run your image","text":"<pre><code>docker run -d --name scouter -p 8080:8080 demml/scouter:ubuntu-amd64-kafka-latest\n</code></pre>"},{"location":"docs/server/#execute-prebuilt-binary","title":"Execute prebuilt binary","text":"<p>Binaries for various architectures are published on every release. You can find them on the github release page, download and execute the binary.</p> <p>Binaries can be found here</p>"},{"location":"docs/server/#build-from-source","title":"Build from source","text":"<p>To build the Scouter server from source, you will need to have the following dependencies installed:</p> <ul> <li>Rust (with Cargo) link</li> </ul> <p>Then you can build the server using the following command:</p> <pre><code>cargo build scouter-server --release\n</code></pre>"},{"location":"docs/server/#feature-flags","title":"Feature Flags","text":"<p>Scouter server is built with a few feature flags that can be enabled or disabled at build time. The following feature flags are available:</p> <ul> <li><code>kafka</code> - Installs the necessary dependencies to use Kafka as the event system (<code>rdkafka</code> crate)</li> </ul> <pre><code>cargo build scouter-server --release --features \"kafka\"\n</code></pre> <ul> <li><code>rabbitmq</code> - Installs the necessary dependencies to use RabbitMQ as the event system (<code>lapin</code> crate)</li> </ul> <pre><code>cargo build scouter-server --release --features \"rabbitmq\"\n</code></pre>"},{"location":"docs/server/#environment-variables","title":"Environment Variables","text":"<p>You can set a variety of environment variables to configure the Scouter server to your needs.</p>"},{"location":"docs/server/#database-variables","title":"Database Variables","text":"Variable Description Feature Default <code>DATABASE_URI</code> Database connection URL <code>All</code> <code>postgresql://postgres:postgres@localhost:5432/postgres</code> <code>MAX_POOL_SIZE</code> Maximum number of database connections in the pool <code>All</code> <code>30</code> <code>DATA_RETENTION_PERIOD</code> Number of days to retain data in the database. After this time, data will be pushed to long-term storage via <code>DataFusion</code> <code>All</code> <code>30</code>"},{"location":"docs/server/#polling-variables-for-background-drift-detection","title":"Polling Variables (For background drift detection)","text":"Variable Description Feature Default <code>POLLING_WORKER_COUNT</code> Number of polling workers for processing scheduled tasks and alerting <code>All</code> <code>4</code>"},{"location":"docs/server/#kafka-variables-if-enabled-for-record-consumption","title":"Kafka Variables (if enabled, for record consumption)","text":"Variable Description Feature Default <code>KAFKA_BROKERS</code> Comma-separated list of Kafka broker addresses <code>Kafka</code> <code>localhost:9092</code> <code>KAFKA_TOPIC</code> Kafka topic for sending data <code>Kafka</code> <code>scouter_monitoring</code> <code>KAFKA_GROUP</code> Kafka consumer group ID <code>Kafka</code> <code>scouter</code> <code>KAFKA_OFFSET_RESET</code> Kafka offset reset policy <code>Kafka</code> <code>earliest</code> <code>KAFKA_USERNAME</code> Kafka username for authentication <code>Kafka</code> <code>None</code> <code>KAFKA_PASSWORD</code> Kafka password for authentication <code>Kafka</code> <code>None</code> <code>KAFKA_SECURITY_PROTOCOL</code> Kafka security protocol (e.g., <code>PLAINTEXT</code>, <code>SSL</code>, <code>SASL_PLAINTEXT</code>, <code>SASL_SSL</code>) <code>Kafka</code> <code>SASL_SSL</code> <code>KAFKA_SASL_MECHANISM</code> Kafka SASL mechanism <code>Kafka</code> <code>PLAIN</code> <code>KAFKA_CERT_LOCATION</code> Path to the Kafka CA certificate file <code>Kafka</code> <code>None</code>"},{"location":"docs/server/#rabbitmq-variables-if-enabled-for-record-consumption","title":"RabbitMQ Variables (if enabled, for record consumption)","text":"Variable Description Feature Default <code>RABBITMQ_CONSUMER_COUNT</code> Number of RabbitMQ consumers <code>RabbitMQ</code> <code>3</code> <code>RABBITMQ_PREFETCH_COUNT</code> Number of messages to prefetch per consumer <code>RabbitMQ</code> <code>10</code> <code>RABBITMQ_ADDR</code> RabbitMQ server address <code>RabbitMQ</code> <code>amqp://guest:guest@127.0.0.1:5672/%2f</code> <code>RABBITMQ_QUEUE</code> RabbitMQ queue name <code>RabbitMQ</code> <code>scouter_monitoring</code> <code>RABBITMQ_CONSUMER_TAG</code> RabbitMQ consumer tag <code>RabbitMQ</code> <code>scouter</code>"},{"location":"docs/server/#authentication","title":"Authentication","text":"<p>Scouter has built-in authentication support for JWT tokens. You can set the following environment variables to enable authentication:</p> <ul> <li><code>SCOUTER_ENCRYPT_SECRET</code>: Secret key used to sign JWT tokens. If not set, scouter will use a default deterministic key. This is not recommended for production use cases. Scouter requires a pbdkdf2::HmacSha256 key with a length of 32 bytes.</li> <li><code>SCOUTER_REFRESH_SECRET</code>: Secret key used to sign refresh tokens. If not set, scouter will use a default deterministic key. This is not recommended for production use cases. Scouter requires a pbdkdf2::HmacSha256 key with a length of 32 bytes.</li> <li><code>SCOUTER_BOOTSTRAP_KEY</code>: Secret key used to bootstrap the server. This is used to create the initial admin user and should be set to a strong random value. If not set, scouter will use a default. This is also a pbdkdf2::HmacSha256 key with a length of 32 bytes. This can be used as a shared key for integration work as well. For example, when setting up an opsml server, you can user this key to sync user accounts between the two servers.</li> </ul>"},{"location":"docs/server/#objectstore-variables-for-long-term-storage","title":"ObjectStore Variables (For long-term storage)","text":"Variable Description Feature Default <code>SCOUTER_STORAGE_URI</code> The URI of the object store to use for long-term storage. The default is <code>./scouter_storage</code>. Currently, gcs, s3, azure and local storage are supported. If using cloud storage, provide the appropriate prefix and bucket (e.g. gs://scouter, s3://scouter, az://scouter) <code>ObjectStore</code> <code>./scouter_storage</code> <code>AWS_REGION</code> The AWS region to use for S3 storage. The default is <code>us-east-1</code> <code>ObjectStore</code> <code>us-east-1</code> <code>GOOGLE_ACCOUNT_JSON_BASE64</code> The base64 encoded JSON key file to use for GCS storage. This is an optional environment variable that can be used in addition to how the <code>object-store</code> GoogleCloudStorageBuilder retrieves credentials <code>ObjectStore</code> <code>None</code>"},{"location":"docs/server/#object-store-providers","title":"Object Store Providers","text":"<p>Scouter leverage's the object-store crate for writing to object stores. The following object stores are supported. Please refer to the object-store crate for more information on how to configure each object store.</p> <p>Providers:</p> <ul> <li><code>google_cloud_storage</code> - link</li> <li><code>aws_s3</code> - link</li> <li><code>azure</code> - link</li> </ul>"},{"location":"docs/server/postgres/","title":"Setting up postgres","text":"<p>By default, Scouter-Server uses postgres and is configured to run with both <code>pg_partman</code> and <code>pg_cron</code> extensions in order to manage partitions and schedule tasks. For an example of setting this up with a local postgres instance, see the docker-compose.yml and Dockerfile files.</p>"},{"location":"docs/server/postgres/#user-roles-and-db-config","title":"User Roles and DB Config","text":"<p>Upon application startup, Scouter-Server will attempt to run an initial migration to setup database tables, partitioning and cron configurations. Prior to application startup, you will need to create the <code>scouter</code> schema, as well as the <code>pg_partman</code> and <code>pg_cron</code> extensions and create a user and database for Scouter-Server to use (unless you are using a superuser). If using a non-superuser when running the application, the user will need to have a variety of permissions on the database and the <code>scouter</code> and <code>cron</code> schemas.</p>"},{"location":"docs/server/postgres/#this-must-be-run-by-a-superuser-when-the-database-is-created","title":"This must be run by a superuser when the database is created","text":"<pre><code>CREATE SCHEMA if not exists scouter;\nCREATE EXTENSION if not exists pg_partman SCHEMA scouter;\nCREATE EXTENSION if not exists pg_cron;\n</code></pre>"},{"location":"docs/server/postgres/#example-non-superuser-permissions","title":"Example non-superuser permissions","text":"<ul> <li>This was tested on cloudsql with postgres 15</li> </ul> <pre><code>-- create user\nCREATE USER my_user WITH PASSWORD 'my_pass';\n\n-- scouter schema\nGRANT ALL ON SCHEMA scouter TO my_user;\nGRANT ALL ON ALL TABLES IN SCHEMA scouter TO my_user;\nGRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA scouter to my_user;\nGRANT EXECUTE ON ALL PROCEDURES IN SCHEMA scouter TO my_user;\nGRANT ALL PRIVILEGES ON TABLE scouter.part_config_sub TO my_user;\nGRANT ALL PRIVILEGES ON TABLE scouter.part_config TO my_user;\n\n-- pg cron\nGRANT USAGE ON SCHEMA cron TO my_user;\nGRANT ALL ON ALL TABLES IN SCHEMA cron TO my_user;\n</code></pre>"},{"location":"docs/specs/Readme/","title":"Technical Specifications","text":"<p>This directory contains various technical specifications for Scouter. It is an on-going effort to document the architecture, design decisions, changes, and other important aspects of the project. It is NOT feature complete and is subject to change as the project evolves.</p> <p>Note: Specifications are written in markdown format and should be easy to read and understand. And while they are recommended for big changes, they are not mandatory.</p>"},{"location":"docs/specs/Readme/#writing-specifications","title":"Writing Specifications","text":"<p>When writing specifications, please follow these guidelines for structure:</p> <pre><code># Title\n\n## Overview\nSimple and concise overview of the specification, including its purpose and scope.\n\n## Key Changes: A brief overview of the specification, including its purpose and scope.\n\n## Implementation Details\n- Detailed description of the implementation, including code snippets and examples.\n- Explanation of any design decisions, trade-offs, and alternatives considered.\n- This part is more flexible and is up to the author to decide how to structure it as long as it is clear and easy to understand.\n\n\n---\n*Version: 1.0*  \n*Last Updated: [date- YYY-MM-DD]*  \n*Author: [Your name]*\n</code></pre>"},{"location":"docs/specs/Readme/#naming-conventions","title":"Naming Conventions","text":""},{"location":"docs/specs/Readme/#feature-based-specifications","title":"Feature-based Specifications","text":"<ul> <li>Feature-based specifications should be named after the feature they are describing. For example, if you are writing a specification for a new feature called \"FeatureX\", the file name should be <code>ts-feature-feature_x.md</code>. This will help in organizing and locating specifications easily.</li> <li>Format: <code>ts-feature-feature_name.md</code></li> </ul>"},{"location":"docs/specs/Readme/#component-based-specifications","title":"Component-based Specifications","text":"<ul> <li>Component-based specifications should be named after the component they are describing. For example, if you are writing a specification for a component called \"ComponentY\", the file name should be <code>ts-component-component_y.md</code>. This will help in organizing and locating specifications easily.</li> <li>Format: <code>ts-component-component_name.md</code></li> </ul>"},{"location":"docs/specs/Readme/#issue-based-specifications","title":"Issue-based Specifications","text":"<ul> <li>Issue-based specifications should be named after the issue they are describing. For example, if you are writing a specification for an issue number 1234, the file name should be <code>ts-issue-1234.md</code>. This will help in organizing and locating specifications easily.</li> <li>Format: <code>ts-issue-number.md</code></li> </ul>"},{"location":"docs/specs/ts-component-data-archive/","title":"Technical Component Specification: Data Archive","text":""},{"location":"docs/specs/ts-component-data-archive/#overview","title":"Overview","text":"<p>The data archive component and architecture is meant to provide a way to maintain database performance, while retaining data in a long-term storage solution.  Importantly, Scouter focuses on providing real-time monitoring capabilities and alerting. And while most of this relies on having short-term data (defined as 60 days), there are some use cases where a user may want to visualize or audit data from longer periods of time.  This component is meant to provide a way to do that.</p> <p>TLDR: Scouter deletes all records &gt; 60 days old in order to maintain database performance, so we need a retention strategy for expired data in the event a user needs access to it.</p>"},{"location":"docs/specs/ts-component-data-archive/#how-it-works","title":"How it works","text":"<p><code>ScouterServerConfig</code> will now load a default <code>ObjectStorageSettings</code> struct on startup. This struct serves as a configuration for the object storage provider.</p> <pre><code>pub struct ObjectStorageSettings {\n    pub storage_uri: String,\n    pub storage_type: StorageType,\n    pub region: String, // this is aws specific\n}\n</code></pre> <p>Accepted environment variables are: - <code>SCOUTER_STORAGE_URI</code>: The URI for the object storage provider. This must be one of the following:   - <code>s3://&lt;bucket-name&gt;</code> for AWS S3   - <code>gs://&lt;bucket-name&gt;</code> for Google Cloud Storage   - <code>az://&lt;container-name&gt;</code> for Azure Blob Storage   -  <code>./scouter-storage</code> for local storage (default if not set)</p> <ul> <li><code>AWS_REGION</code>: The AWS region for the object storage provider. This is only required if the <code>SCOUTER_STORAGE_URI</code> is set to <code>s3://&lt;bucket-name&gt;</code>. It defaults to <code>us-east-1</code> if not set.</li> </ul> <p>In addition to <code>ObjectStorageSettings</code>, <code>DatabaseSettings</code> now takes on an additional environment variable <code>DATA_RETENTION_PERIOD</code> which indicates how long data should be retained in the database before moving it to long-term storage. Note this is only for copying data to long-term storage. The actual deletion of data is still handled by <code>pgCron</code>. The default value is 60 days.</p>"},{"location":"docs/specs/ts-component-data-archive/#component-architecture","title":"Component Architecture","text":""},{"location":"docs/specs/ts-component-data-archive/#implementation-details","title":"Implementation Details","text":"<p>The data archive component itself is comprised of a few key parts:</p> <ol> <li>Scouter Dataframe: This is a crate that defines the arrow datafusion, parquet and object store interfaces for reading and writing data to an from long-term storage. It also contains drift-specific logic that is implement via traits.</li> </ol>"},{"location":"docs/specs/ts-component-data-archive/#primary-interface","title":"Primary Interface","text":"<pre><code>pub enum ParquetDataFrame {\n   CustomMetric(CustomMetricDataFrame),\n   Psi(PsiDataFrame),\n   Spc(SpcDataFrame),\n}\n</code></pre> <p>The <code>ParquetDataFrame</code> enum is the primary interface for the data archive component. It allows for different types of data frames to be handled in a uniform way. Each variant of the enum corresponds to a specific type of data frame, such as <code>CustomMetric</code>, <code>Psi</code>, or <code>Spc</code>.</p> <p>It's primary methods for reading and writing data are:</p> <pre><code>pub async fn write_parquet(\n   &amp;self,\n   rpath: &amp;str,\n   records: ServerRecords,\n) -&gt; Result&lt;(), DataFrameError&gt; \n</code></pre> <pre><code>pub async fn get_binned_metrics(\n   &amp;self,\n   path: &amp;str,\n   bin: &amp;f64,\n   start_time: &amp;DateTime&lt;Utc&gt;,\n   end_time: &amp;DateTime&lt;Utc&gt;,\n   space: &amp;str,\n   name: &amp;str,\n   version: &amp;str,\n) -&gt; Result&lt;DataFrame, DataFrameError&gt;\n</code></pre> <ol> <li>Scouter Server DataArchiver: Upon startup, the Scouter server will create a <code>DataArchiver</code> instance and start a background worker that will run every hour. This worker will check for any expired data in the database and move it to long-term storage. The <code>DataArchiver</code> will use the <code>ParquetDataFrame</code> interface to read and write data.</li> </ol> <pre><code>pub async fn setup_background_data_archive_workers(\n    db_pool: &amp;Pool&lt;Postgres&gt;,\n    config: &amp;Arc&lt;ScouterServerConfig&gt;,\n    shutdown_rx: tokio::sync::watch::Receiver&lt;()&gt;,\n) -&gt; AnyhowResult&lt;()&gt; {\n    DataArchiver::start_workers(db_pool, shutdown_rx, config).await?;\n    info!(\"\u2705 Started data archive workers\");\n    Ok(())\n}\n</code></pre> <p>The primary method for the background worker is <code>archive_expired_data</code>, which will check for any expired data in the database and move it to long-term storage. It iterates over each drift type and processes records according to their trait implementations.</p> <pre><code>pub async fn archive_old_data(\n    db_pool: &amp;Pool&lt;Postgres&gt;,\n    config: &amp;Arc&lt;ScouterServerConfig&gt;,\n) -&gt; Result&lt;ArchiveRecord, ServerError&gt;\n</code></pre> <pre><code>async fn process_record_type(\n    db_pool: &amp;Pool&lt;Postgres&gt;,\n    record_type: &amp;RecordType,\n    config: &amp;Arc&lt;ScouterServerConfig&gt;,\n) -&gt; Result&lt;bool, ServerError&gt;\n</code></pre> <pre><code>async fn get_entities_to_archive(\n    db_pool: &amp;Pool&lt;Postgres&gt;,\n    record_type: &amp;RecordType,\n    retention_period: &amp;i32,\n) -&gt; Result&lt;Vec&lt;Entity&gt;, ServerError&gt;\n</code></pre> <pre><code>async fn get_data_to_archive(\n    tx: &amp;mut Transaction&lt;'_, Postgres&gt;,\n    record_type: &amp;RecordType,\n    entity: &amp;Entity,\n) -&gt; Result&lt;ServerRecords, ServerError&gt;\n</code></pre> <pre><code>async fn update_entities_to_archived(\n    tx: &amp;mut Transaction&lt;'_, Postgres&gt;,\n    record_type: &amp;RecordType,\n    entity: &amp;Entity,\n) -&gt; Result&lt;(), ServerError&gt;`\n</code></pre>"},{"location":"docs/specs/ts-component-data-archive/#dependencies","title":"Dependencies","text":"<ul> <li>Primary External Crates</li> <li><code>arrow-array</code></li> <li><code>datafusion</code></li> <li><code>object_store</code></li> <li><code>parquet</code></li> </ul>"},{"location":"docs/specs/ts-component-data-archive/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Asynchronous Processing</li> <li>Non-blocking</li> <li>Async database operations</li> </ol> <p>Version: 1.0 Last Updated: 2025-04-23 Component Owner: Steven Forrester</p>"},{"location":"docs/specs/ts-component-scouter-queue/","title":"Technical Component Specification: Scouter Queue","text":""},{"location":"docs/specs/ts-component-scouter-queue/#overview","title":"Overview","text":"<p>The Scouter Queue is the primary interface for sending real-time data to the Scouter server from a python application. The Scouter Queue is built to be a lightweight, high-performance and transient interface for publishing data so that it doesn't get in the way of the application. To achieve this the Scouter Queue leverages a channel system to send and receive messages, which are then passed to the background producer independent of the running python application.</p>"},{"location":"docs/specs/ts-component-scouter-queue/#component-architecture","title":"Component Architecture","text":""},{"location":"docs/specs/ts-component-scouter-queue/#how-it-works","title":"How it works","text":"<p>(1) Scouter Queue: The user creates a <code>ScouterQueue</code> by using the <code>from_path</code> operation which accepts a hashmap of paths to the queue files. The ScouterQueue will create a new queue for each path and start a background worker that will read from the queue and send the data to the Scouter server. The <code>from_path</code> operation also accepts a transport configuration that is used to setup the specific transport producer for the queue (kafka, rabbitmq, etc.).</p> <pre><code>#[pyclass]\npub struct ScouterQueue {\n    queues: HashMap&lt;String, Py&lt;QueueBus&gt;&gt;,\n    _shared_runtime: Arc&lt;tokio::runtime::Runtime&gt;,\n    completion_rxs: HashMap&lt;String, oneshot::Receiver&lt;()&gt;&gt;,\n    pub queue_state: Arc&lt;HashMap&lt;String, TaskState&gt;&gt;,\n}\n\n#[staticmethod]\n    #[pyo3(signature = (path, transport_config))]\n    pub fn from_path(\n        py: Python,\n        path: HashMap&lt;String, PathBuf&gt;,\n        transport_config: &amp;Bound&lt;'_, PyAny&gt;,\n    ) -&gt; Result&lt;Self, EventError&gt;\n</code></pre> <pre><code>class ScouterQueue:\n    \"\"\"Main queue class for Scouter. Publishes drift records to the configured transport\"\"\"\n\n    @staticmethod\n    def from_path(\n        path: Dict[str, Path],\n        transport_config: Union[KafkaConfig, RabbitMQConfig, HTTPConfig],\n    )\n</code></pre> <p>(2) For each <code>DriftProfile</code>, a spawned <code>event_handler</code> will be created that uses <code>Tokio::select</code> to keep track of received events (<code>Event enum</code>). Received events from the parent python thread are passed to the <code>event_handler</code>, which is then inserted into a <code>queue</code>. If the queue capacity has been reached, the events are published via the configured transport. In the case of <code>Psi</code> and <code>Custom</code> drift profiles, an additional <code>background_handler</code> is created that publishes events from the queue every 30 seconds. This is done in order to minimize any data loss if an app fails or to handle cases where an api may be receiving low amounts of traffic, which may cause the queue to have to wait awhile to fill up.</p> <p>(3) For every <code>DriftProfile</code> a <code>TaskState</code> will be created that keeps track of the <code>event_handler</code> and <code>background_handler</code> tasks.The <code>TaskState</code> is used in shutdown functions to cancel spawned tasks via a <code>Tokio</code> <code>CancellationToken</code>.</p> <p>The following is used to spawn the event handler:</p> <pre><code>#[allow(clippy::too_many_arguments)]\nasync fn spawn_queue_event_handler(\n    mut event_rx: UnboundedReceiver&lt;Event&gt;,\n    transport_config: TransportConfig,\n    drift_profile: DriftProfile,\n    runtime: Arc&lt;runtime::Runtime&gt;,\n    id: String,\n    mut task_state: TaskState,\n    cancellation_token: CancellationToken,\n) -&gt; Result&lt;(), EventError&gt;\n</code></pre> <p>For <code>Psi</code> and <code>Custom</code> profiles, the background polling task is spawned as follows:</p> <pre><code>pub trait BackgroundTask: Send + Sync + 'static {\n    type DataItem: QueueExt + Send + Sync + 'static;\n    type Processor: FeatureQueue + Send + Sync + 'static;\n\n    #[allow(clippy::too_many_arguments)]\n    fn start_background_task(\n        &amp;self,\n        data_queue: Arc&lt;ArrayQueue&lt;Self::DataItem&gt;&gt;,\n        processor: Arc&lt;Self::Processor&gt;,\n        mut producer: RustScouterProducer,\n        last_publish: Arc&lt;RwLock&lt;DateTime&lt;Utc&gt;&gt;&gt;,\n        runtime: Arc&lt;Runtime&gt;,\n        queue_capacity: usize,\n        identifier: String,\n        task_state: TaskState,\n        cancellation_token: CancellationToken,\n    ) -&gt; Result&lt;JoinHandle&lt;()&gt;, EventError&gt;\n}\n</code></pre> <p>(4) QueueBus: Everything discussed so far has focused on the Rust background tasks that run independent of the python runtime. So how do we bridge the gap and get events to rust from python. For every <code>DriftProfile</code>, a <code>QueueBus</code> is created that exposes an <code>insert</code> method to the user. This method will accept any of the allowed data types for monitoring (<code>Features</code>, <code>Metrics</code>, <code>LLMRecord</code>). The data types are extracted and published as an <code>Event</code> enum to the event channel, which is then read by the event receiver (<code>tokio::sync:mpsc</code>) embedded within the rust <code>event_handler</code>. This publishing happends asynchronously, which allows the user on the python side to continue accepting api requests without impacting latency. On the rust side, the event receiver will then process the event and add it to the background queue.</p> <pre><code>#[pyclass(name = \"Queue\")]\npub struct QueueBus {\n    pub task_state: TaskState,\n\n    #[pyo3(get)]\n    pub identifier: String,\n\n}\n</code></pre> <p>(5) Error Handling: Errors are logged and not returned to the user. This is to ensure that the spawned tasks do not block the main thread and can continue to process events. As a user, it's important to monitor these logs. </p> <p>(6) Queue Insert: After the <code>ScouterQueue</code> is created, the user can insert events into the queue by accessing the queue directly through its alias and calling the <code>insert</code> method. The insert method expects either a <code>Features</code> object, a <code>Metrics</code> object (for custom metrics) or an <code>LLMRecord</code> object (for llm as a judge workflows). Note - Scouter also provides a <code>FeatureMixin</code> class that can be used to convert a python object into a <code>Features</code> object. This is useful for converting a Pydantic BaseModel into a <code>Features</code> object. The <code>FeatureMixin</code> class is not required, but it is recommended for ease of use.</p> <pre><code>#[pyclass]\n#[derive(Clone, Debug, Serialize)]\npub struct Features {\n    #[pyo3(get)]\n    pub features: Vec&lt;Feature&gt;,\n\n    #[pyo3(get)]\n    pub entity_type: EntityType,\n}\n\n\n#[pyclass]\n#[derive(Clone, Serialize, Deserialize, Debug)]\npub enum Feature {\n    Int(IntFeature),\n    Float(FloatFeature),\n    String(StringFeature),\n}\n\n#[pymethods]\nimpl Feature {\n    #[staticmethod]\n    pub fn int(name: String, value: i64) -&gt; Self {\n        Feature::Int(IntFeature { name, value })\n    }\n\n    #[staticmethod]\n    pub fn float(name: String, value: f64) -&gt; Self {\n        Feature::Float(FloatFeature { name, value })\n    }\n\n    #[staticmethod]\n    pub fn string(name: String, value: String) -&gt; Self {\n        Feature::String(StringFeature { name, value })\n    }\n\n    pub fn __str__(&amp;self) -&gt; String {\n        PyHelperFuncs::__str__(self)\n    }\n}\n\n\n\n#[pyclass]\n#[derive(Clone, Serialize, Debug)]\npub struct Metric {\n    pub name: String,\n    pub value: f64,\n}\n\n#[pymethods]\nimpl Metric {\n    #[new]\n    pub fn new(name: String, value: Bound&lt;'_, PyAny&gt;) -&gt; Self {\n        let value = if value.is_instance_of::&lt;PyFloat&gt;() {\n            value.extract::&lt;f64&gt;().unwrap()\n        } else if value.is_instance_of::&lt;PyInt&gt;() {\n            value.extract::&lt;i64&gt;().unwrap() as f64\n        } else {\n            panic!(\n                \"Unsupported metric type: {}\",\n                value.get_type().name().unwrap()\n            );\n        };\n        let lowercase_name = name.to_lowercase();\n        Metric {\n            name: lowercase_name,\n            value,\n        }\n    }\n\n    pub fn __str__(&amp;self) -&gt; String {\n        PyHelperFuncs::__str__(self)\n    }\n}\n\n#[pyclass]\n#[derive(Clone, Serialize, Debug)]\npub struct Metrics {\n    #[pyo3(get)]\n    pub metrics: Vec&lt;Metric&gt;,\n\n    #[pyo3(get)]\n    pub entity_type: EntityType,\n}\n\n\n#[pyclass]\n#[derive(Clone, Serialize, Debug)]\npub struct LLMRecord {\n    pub uid: String,\n\n    pub space: String,\n\n    pub name: String,\n\n    pub version: String,\n\n    pub created_at: DateTime&lt;Utc&gt;,\n\n    pub context: Value,\n\n    pub score: Value,\n\n    pub prompt: Option&lt;Value&gt;,\n\n    #[pyo3(get)]\n    pub entity_type: EntityType,\n}\n\n#[pymethods]\nimpl LLMRecord {\n    #[new]\n    #[pyo3(signature = (\n        context,\n        prompt=None,\n    ))]\n\n    /// Creates a new LLMRecord instance.\n    /// The context is either a python dictionary or a pydantic basemodel.\n    pub fn new(\n        py: Python&lt;'_&gt;,\n        context: Bound&lt;'_, PyAny&gt;,\n        prompt: Option&lt;Bound&lt;'_, PyAny&gt;&gt;,\n    ) -&gt; Result&lt;Self, TypeError&gt; {\n        // check if context is a PyDict or PyObject(Pydantic model)\n        let context_val = if context.is_instance_of::&lt;PyDict&gt;() {\n            pyobject_to_json(&amp;context)?\n        } else if is_pydantic_model(py, &amp;context)? {\n            // Dump pydantic model to dictionary\n            let model = context.call_method0(\"model_dump\")?;\n\n            // Serialize the dictionary to JSON\n            pyobject_to_json(&amp;model)?\n        } else {\n            Err(TypeError::MustBeDictOrBaseModel)?\n        };\n\n        let prompt: Option&lt;Value&gt; = match prompt {\n            Some(p) =&gt; {\n                if p.is_instance_of::&lt;Prompt&gt;() {\n                    let prompt = p.extract::&lt;Prompt&gt;()?;\n                    Some(serde_json::to_value(prompt)?)\n                } else {\n                    Some(pyobject_to_json(&amp;p)?)\n                }\n            }\n            None =&gt; None,\n        };\n\n        Ok(LLMRecord {\n            uid: create_uuid7(),\n            created_at: Utc::now(),\n            space: String::new(),\n            name: String::new(),\n            version: String::new(),\n            context: context_val,\n            score: Value::Null,\n            prompt,\n            entity_type: EntityType::LLM,\n        })\n    }\n}\n</code></pre>"},{"location":"docs/specs/ts-component-scouter-queue/#python-example","title":"Python example","text":"<pre><code>class PredictRequest(BaseModel):\n    feature_1: float\n    feature_2: float\n    feature_3: float\n\n    def to_features(self) -&gt; Features:\n        return Features(\n            features=[\n                Feature.float(\"feature_1\", self.feature_1),\n                Feature.float(\"feature_2\", self.feature_2),\n                Feature.float(\"feature_3\", self.feature_3),\n            ]\n        )\n\nqueue = ScouterQueue.from_path(...)\nqueue[\"alias\"].insert(request.to_features())\n\n# or for custom metrics\n\nqueue[\"alias\"].insert(\n    Metrics(\n        [\n            Metric(\"mape\", 1.0), \n            Metric(\"mae\", 2.0)\n        ],\n    )\n)\n\n# or for LLMRecords\n\nqueue[\"alias\"].insert(\n    LLMRecord(\n        context={\n            \"input\": bound_prompt.message[0].unwrap(),\n            \"response\": response.result,\n        },\n    )\n)\n</code></pre> <p>Version: 1.0 Last Updated: 2025-08-25 Component Owner: Steven Forrester</p>"}]}